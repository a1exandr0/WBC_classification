{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten, Activation, BatchNormalization, Add, AveragePooling2D, Input, ZeroPadding2D, concatenate, GlobalAveragePooling2D, Lambda\n",
    "from keras.initializers import glorot_uniform, Constant\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, num_filters, filter_size, strides=1, padding=\"same\", activation=True, name=None, kernel_initializer=None, bias_initializer=None):\n",
    "    X = Conv2D(num_filters, filter_size, strides=strides, padding=padding, \n",
    "               kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)(X)\n",
    "    X = BatchNormalization(axis=3, scale=False)(X)\n",
    "    if activation:\n",
    "        X = Activation(\"relu\")(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(input_layer, kernel_init, bias_init, name=None):\n",
    "    X = conv2d(input_layer, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = conv2d(X, 32, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X = conv2d(X, 64, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X1 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "    X2 = conv2d(X, 96, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "    X1 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X1 = conv2d(X1, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X2, 64, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 64, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "    X1 = conv2d(X, 192, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "    X = concatenate([X1, X2], axis=3, name=name)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNet_A(X, kernel_init, bias_init, scaling_activation, scale=1, name=None):\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X1 = conv2d(X, 32, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X, 32, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 32, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X3 = conv2d(X, 32, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X3 = conv2d(X3, 48, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X3 = conv2d(X3, 64, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X_inception = concatenate([X1, X2, X3], axis=3)\n",
    "    \n",
    "    X_inception = conv2d(X_inception, 384, (1, 1), strides=1, padding=\"same\", activation=False, kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    final_layer = Lambda(lambda inputs: inputs[0] + inputs[1]*scale, name=name+\"_Scaling_Residual\")([X_shortcut, X_inception])\n",
    "\n",
    "    final_layer = Activation(\"relu\", name=name)(final_layer)\n",
    "    \n",
    "    return final_layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNet_B(X, kernel_init, bias_init, scaling_activation, scale=1, name=None):\n",
    "    X_shortcut = X\n",
    "    \n",
    "    \n",
    "    X1 = conv2d(X, 192, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X, 128, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 160, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 192, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X_inception = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "    X_inception = conv2d(X_inception, 1152, (1, 1), strides=1, padding=\"same\", activation=False, kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    final_layer = Lambda(lambda inputs: inputs[0] + inputs[1]*scale, name=name+\"_Scaling_Residual\")([X_shortcut, X_inception])\n",
    "\n",
    "    final_layer = Activation(\"relu\", name=name)(final_layer)\n",
    "\n",
    "    return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNet_C(X, kernel_init, bias_init, scaling_activation, scale=1, name=None):\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X1 = conv2d(X, 192, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X, 192, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 224, (1, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 256, (3, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X_inception = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "    X_inception = conv2d(X_inception, 2048, (1, 1), strides=1, padding=\"same\", activation=False, kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    final_layer = Lambda(lambda inputs: inputs[0] + inputs[1]*scale, name=name+\"_Scaling_Residual\")([X_shortcut, X_inception])\n",
    "\n",
    "    final_layer = Activation(\"relu\", name=name)(final_layer)\n",
    "    \n",
    "    return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduction_A(X, kernel_init, bias_init, name=None):\n",
    "    X1 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "    X2 = conv2d(X, 384, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X3 = conv2d(X, 256, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X3 = conv2d(X3, 256, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X3 = conv2d(X3, 384, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = concatenate([X1, X2, X3], axis=3, name=name)\n",
    "    \n",
    "    return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduction_B(X, kernel_init, bias_init, name=None):\n",
    "    X1 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "    X2 = conv2d(X, 256, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X2 = conv2d(X2, 384, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X3 = conv2d(X, 256, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X3 = conv2d(X3, 256, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = conv2d(X, 256, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = conv2d(X4, 256, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X4 = conv2d(X4, 256, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = concatenate([X1, X2, X3, X4], axis=3, name=name)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNet_V2(size=(299, 299, 3), N_classes=4):\n",
    "    input_layer = Input(shape=size)\n",
    "    kernel_init = glorot_uniform()\n",
    "    bias_init = None\n",
    "    \n",
    "    X = Stem(input_layer, kernel_init, bias_init, name=\"Stem\")\n",
    "    \n",
    "    X = InceptionResNet_A(X, kernel_init, bias_init, \"relu\", name=\"Block_A_1\", scale=.15)\n",
    "    X = InceptionResNet_A(X, kernel_init, bias_init, \"relu\", name=\"Block_A_2\", scale=.15)\n",
    "    X = InceptionResNet_A(X, kernel_init, bias_init, \"relu\", name=\"Block_A_3\", scale=.15)\n",
    "    X = InceptionResNet_A(X, kernel_init, bias_init, \"relu\", name=\"Block_A_4\", scale=.15)\n",
    "    X = InceptionResNet_A(X, kernel_init, bias_init, \"relu\", name=\"Block_A_5\", scale=.15)\n",
    "    \n",
    "    X = Reduction_A(X, kernel_init, bias_init, name=\"Reduction_block_A\")\n",
    "    \n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_1\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_2\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_3\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_4\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_5\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_6\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_7\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_8\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_9\", scale=.1)\n",
    "    X = InceptionResNet_B(X, kernel_init, bias_init, \"relu\", name=\"Block_B_10\", scale=.1)\n",
    "    \n",
    "    X = Reduction_B(X, kernel_init, bias_init, name=\"Reduction_block_B\")\n",
    "    \n",
    "    X = InceptionResNet_C(X, kernel_init, bias_init, \"relu\", name=\"Block_C_1\", scale=.2)\n",
    "    X = InceptionResNet_C(X, kernel_init, bias_init, \"relu\", name=\"Block_C_2\", scale=.2)\n",
    "    X = InceptionResNet_C(X, kernel_init, bias_init, \"relu\", name=\"Block_C_3\", scale=.2)\n",
    "    \n",
    "    X = GlobalAveragePooling2D(name=\"GlobalAvgPool\")(X)\n",
    "    \n",
    "    X = Dropout(.8)(X)\n",
    "    \n",
    "    X = Dense(N_classes, activation=\"softmax\", name=\"final_output\")(X)\n",
    "    \n",
    "    model = Model(input_layer, X, name=\"InceptionResNet_V2\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"InceptionResNet_V2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 149, 149, 32) 896         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 149, 149, 32) 96          conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 149, 149, 32) 0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 147, 147, 32) 9248        activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 147, 147, 32) 96          conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 147, 147, 32) 0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 147, 147, 64) 18496       activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 147, 147, 64) 192         conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 147, 147, 64) 0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 73, 73, 96)   55392       activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 73, 73, 96)   288         conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 73, 73, 64)   0           activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 73, 73, 96)   0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 73, 73, 160)  0           max_pooling2d_16[0][0]           \n",
      "                                                                 activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 73, 73, 64)   10304       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 73, 73, 64)   192         conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 73, 73, 64)   0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 73, 73, 64)   28736       activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 73, 73, 64)   192         conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 73, 73, 64)   0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 73, 73, 64)   10304       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 73, 73, 64)   28736       activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 73, 73, 64)   192         conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 73, 73, 64)   192         conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 73, 73, 64)   0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 73, 73, 64)   0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 71, 71, 96)   55392       activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 71, 71, 96)   55392       activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 71, 71, 96)   288         conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 71, 71, 96)   288         conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 71, 71, 96)   0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 71, 71, 96)   0           batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 71, 71, 192)  0           activation_421[0][0]             \n",
      "                                                                 activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 35, 35, 192)  331968      concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 35, 35, 192)  576         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 35, 35, 192)  0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 35, 35, 192)  0           concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stem (Concatenate)              (None, 35, 35, 384)  0           activation_426[0][0]             \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 35, 35, 32)   96          conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 35, 35, 32)   0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 35, 35, 48)   13872       activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 35, 35, 32)   96          conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 35, 35, 48)   144         conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 35, 35, 32)   0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 35, 35, 48)   0           batch_normalization_503[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 35, 35, 32)   9248        activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 35, 35, 64)   27712       activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 35, 35, 32)   96          conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 35, 35, 32)   96          conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 35, 35, 64)   192         conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 35, 35, 32)   0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 35, 35, 32)   0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 35, 35, 64)   0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 35, 35, 128)  0           activation_427[0][0]             \n",
      "                                                                 activation_429[0][0]             \n",
      "                                                                 activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 35, 35, 384)  49536       concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 35, 35, 384)  1152        conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_1_Scaling_Residual (Lam (None, 35, 35, 384)  0           Stem[0][0]                       \n",
      "                                                                 batch_normalization_505[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_1 (Activation)          (None, 35, 35, 384)  0           Block_A_1_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 35, 35, 32)   96          conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 35, 35, 32)   0           batch_normalization_509[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 35, 35, 48)   13872       activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 35, 35, 32)   96          conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 35, 35, 48)   144         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 35, 35, 32)   0           batch_normalization_507[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 35, 35, 48)   0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 35, 35, 32)   9248        activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 35, 35, 64)   27712       activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 35, 35, 32)   96          conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 35, 35, 32)   96          conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 35, 35, 64)   192         conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 35, 35, 32)   0           batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 35, 35, 32)   0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 35, 35, 64)   0           batch_normalization_511[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 35, 35, 128)  0           activation_433[0][0]             \n",
      "                                                                 activation_435[0][0]             \n",
      "                                                                 activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 35, 35, 384)  49536       concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 35, 35, 384)  1152        conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_2_Scaling_Residual (Lam (None, 35, 35, 384)  0           Block_A_1[0][0]                  \n",
      "                                                                 batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_2 (Activation)          (None, 35, 35, 384)  0           Block_A_2_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchN (None, 35, 35, 32)   96          conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 35, 35, 32)   0           batch_normalization_516[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 35, 35, 48)   13872       activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 35, 35, 32)   96          conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchN (None, 35, 35, 48)   144         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 35, 35, 32)   0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 35, 35, 48)   0           batch_normalization_517[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 35, 35, 32)   9248        activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 35, 35, 64)   27712       activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 35, 35, 32)   96          conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 35, 35, 32)   96          conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchN (None, 35, 35, 64)   192         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 35, 35, 32)   0           batch_normalization_513[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 35, 35, 32)   0           batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 35, 35, 64)   0           batch_normalization_518[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 35, 35, 128)  0           activation_439[0][0]             \n",
      "                                                                 activation_441[0][0]             \n",
      "                                                                 activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 35, 35, 384)  49536       concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchN (None, 35, 35, 384)  1152        conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_3_Scaling_Residual (Lam (None, 35, 35, 384)  0           Block_A_2[0][0]                  \n",
      "                                                                 batch_normalization_519[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_3 (Activation)          (None, 35, 35, 384)  0           Block_A_3_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchN (None, 35, 35, 32)   96          conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 35, 35, 32)   0           batch_normalization_523[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 35, 35, 48)   13872       activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchN (None, 35, 35, 32)   96          conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchN (None, 35, 35, 48)   144         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 35, 35, 32)   0           batch_normalization_521[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 35, 35, 48)   0           batch_normalization_524[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 35, 35, 32)   9248        activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 35, 35, 64)   27712       activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchN (None, 35, 35, 32)   96          conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchN (None, 35, 35, 32)   96          conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchN (None, 35, 35, 64)   192         conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 35, 35, 32)   0           batch_normalization_520[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 35, 35, 32)   0           batch_normalization_522[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 35, 35, 64)   0           batch_normalization_525[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 35, 35, 128)  0           activation_445[0][0]             \n",
      "                                                                 activation_447[0][0]             \n",
      "                                                                 activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 35, 35, 384)  49536       concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchN (None, 35, 35, 384)  1152        conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_4_Scaling_Residual (Lam (None, 35, 35, 384)  0           Block_A_3[0][0]                  \n",
      "                                                                 batch_normalization_526[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_4 (Activation)          (None, 35, 35, 384)  0           Block_A_4_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchN (None, 35, 35, 32)   96          conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 35, 35, 32)   0           batch_normalization_530[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 35, 35, 48)   13872       activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchN (None, 35, 35, 32)   96          conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchN (None, 35, 35, 48)   144         conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 35, 35, 32)   0           batch_normalization_528[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 35, 35, 48)   0           batch_normalization_531[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 35, 35, 32)   12320       Block_A_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 35, 35, 32)   9248        activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 35, 35, 64)   27712       activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchN (None, 35, 35, 32)   96          conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchN (None, 35, 35, 32)   96          conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchN (None, 35, 35, 64)   192         conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 35, 35, 32)   0           batch_normalization_527[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 35, 35, 32)   0           batch_normalization_529[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 35, 35, 64)   0           batch_normalization_532[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 35, 35, 128)  0           activation_451[0][0]             \n",
      "                                                                 activation_453[0][0]             \n",
      "                                                                 activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 35, 35, 384)  49536       concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchN (None, 35, 35, 384)  1152        conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_5_Scaling_Residual (Lam (None, 35, 35, 384)  0           Block_A_4[0][0]                  \n",
      "                                                                 batch_normalization_533[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_A_5 (Activation)          (None, 35, 35, 384)  0           Block_A_5_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 35, 35, 256)  98560       Block_A_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchN (None, 35, 35, 256)  768         conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 35, 35, 256)  0           batch_normalization_535[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 35, 35, 256)  590080      activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchN (None, 35, 35, 256)  768         conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 35, 35, 256)  0           batch_normalization_536[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 17, 17, 384)  1327488     Block_A_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 17, 17, 384)  885120      activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchN (None, 17, 17, 384)  1152        conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchN (None, 17, 17, 384)  1152        conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 17, 17, 384)  0           Block_A_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 17, 17, 384)  0           batch_normalization_534[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 17, 17, 384)  0           batch_normalization_537[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Reduction_block_A (Concatenate) (None, 17, 17, 1152) 0           max_pooling2d_18[0][0]           \n",
      "                                                                 activation_457[0][0]             \n",
      "                                                                 activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 17, 17, 128)  147584      Reduction_block_A[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 17, 17, 128)  384         conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 17, 17, 128)  0           batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 17, 17, 160)  143520      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 17, 17, 160)  480         conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 17, 17, 160)  0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 17, 17, 192)  221376      Reduction_block_A[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 17, 17, 192)  215232      activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchN (None, 17, 17, 192)  576         conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 17, 17, 192)  576         conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 17, 17, 192)  0           batch_normalization_538[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 17, 17, 192)  0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 17, 17, 384)  0           activation_461[0][0]             \n",
      "                                                                 activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 17, 17, 1152) 3456        conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_1_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Reduction_block_A[0][0]          \n",
      "                                                                 batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_1 (Activation)          (None, 17, 17, 1152) 0           Block_B_1_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 17, 17, 128)  384         conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 17, 17, 128)  0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 17, 17, 160)  143520      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchN (None, 17, 17, 160)  480         conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 17, 17, 160)  0           batch_normalization_545[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 17, 17, 192)  215232      activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 17, 17, 192)  576         conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 17, 17, 192)  576         conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 17, 17, 192)  0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 17, 17, 192)  0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 17, 17, 384)  0           activation_465[0][0]             \n",
      "                                                                 activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 17, 17, 1152) 3456        conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_2_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_1[0][0]                  \n",
      "                                                                 batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_2 (Activation)          (None, 17, 17, 1152) 0           Block_B_2_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 17, 17, 128)  384         conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, 17, 17, 128)  0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 17, 17, 160)  143520      activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_550 (BatchN (None, 17, 17, 160)  480         conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 17, 17, 160)  0           batch_normalization_550[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 17, 17, 192)  215232      activation_471[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 17, 17, 192)  576         conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_551 (BatchN (None, 17, 17, 192)  576         conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 17, 17, 192)  0           batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 17, 17, 192)  0           batch_normalization_551[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 17, 17, 384)  0           activation_469[0][0]             \n",
      "                                                                 activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_552 (BatchN (None, 17, 17, 1152) 3456        conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_3_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_2[0][0]                  \n",
      "                                                                 batch_normalization_552[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_3 (Activation)          (None, 17, 17, 1152) 0           Block_B_3_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_554 (BatchN (None, 17, 17, 128)  384         conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 17, 17, 128)  0           batch_normalization_554[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 17, 17, 160)  143520      activation_474[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_555 (BatchN (None, 17, 17, 160)  480         conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 17, 17, 160)  0           batch_normalization_555[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 17, 17, 192)  215232      activation_475[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_553 (BatchN (None, 17, 17, 192)  576         conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_556 (BatchN (None, 17, 17, 192)  576         conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 17, 17, 192)  0           batch_normalization_553[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 17, 17, 192)  0           batch_normalization_556[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 17, 17, 384)  0           activation_473[0][0]             \n",
      "                                                                 activation_476[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_557 (BatchN (None, 17, 17, 1152) 3456        conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_4_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_3[0][0]                  \n",
      "                                                                 batch_normalization_557[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_4 (Activation)          (None, 17, 17, 1152) 0           Block_B_4_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_559 (BatchN (None, 17, 17, 128)  384         conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 17, 17, 128)  0           batch_normalization_559[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 17, 17, 160)  143520      activation_478[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_560 (BatchN (None, 17, 17, 160)  480         conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 17, 17, 160)  0           batch_normalization_560[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 17, 17, 192)  215232      activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_558 (BatchN (None, 17, 17, 192)  576         conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_561 (BatchN (None, 17, 17, 192)  576         conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 17, 17, 192)  0           batch_normalization_558[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 17, 17, 192)  0           batch_normalization_561[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 17, 17, 384)  0           activation_477[0][0]             \n",
      "                                                                 activation_480[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_562 (BatchN (None, 17, 17, 1152) 3456        conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_5_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_4[0][0]                  \n",
      "                                                                 batch_normalization_562[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_5 (Activation)          (None, 17, 17, 1152) 0           Block_B_5_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 17, 17, 128)  384         conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 17, 17, 128)  0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 17, 17, 160)  143520      activation_482[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchN (None, 17, 17, 160)  480         conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 17, 17, 160)  0           batch_normalization_565[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 17, 17, 192)  215232      activation_483[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_563 (BatchN (None, 17, 17, 192)  576         conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchN (None, 17, 17, 192)  576         conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 17, 17, 192)  0           batch_normalization_563[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 17, 17, 192)  0           batch_normalization_566[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 17, 17, 384)  0           activation_481[0][0]             \n",
      "                                                                 activation_484[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 17, 17, 1152) 3456        conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_6_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_5[0][0]                  \n",
      "                                                                 batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_6 (Activation)          (None, 17, 17, 1152) 0           Block_B_6_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 17, 17, 128)  384         conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 17, 17, 128)  0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 17, 17, 160)  143520      activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 17, 17, 160)  480         conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 17, 17, 160)  0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 17, 17, 192)  215232      activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 17, 17, 192)  576         conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 17, 17, 192)  576         conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 17, 17, 192)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 17, 17, 192)  0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 17, 17, 384)  0           activation_485[0][0]             \n",
      "                                                                 activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 17, 17, 1152) 3456        conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_7_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_6[0][0]                  \n",
      "                                                                 batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_7 (Activation)          (None, 17, 17, 1152) 0           Block_B_7_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 17, 17, 128)  384         conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 17, 17, 128)  0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 17, 17, 160)  143520      activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 17, 17, 160)  480         conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 17, 17, 160)  0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 17, 17, 192)  215232      activation_491[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 17, 17, 192)  576         conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 17, 17, 192)  576         conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 17, 17, 192)  0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 17, 17, 192)  0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 17, 17, 384)  0           activation_489[0][0]             \n",
      "                                                                 activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 17, 17, 1152) 3456        conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_8_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_7[0][0]                  \n",
      "                                                                 batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_8 (Activation)          (None, 17, 17, 1152) 0           Block_B_8_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 17, 17, 128)  384         conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, 17, 17, 128)  0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 17, 17, 160)  143520      activation_494[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 17, 17, 160)  480         conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 17, 17, 160)  0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 17, 17, 192)  215232      activation_495[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 17, 17, 192)  576         conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 17, 17, 192)  576         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, 17, 17, 192)  0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 17, 17, 192)  0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 17, 17, 384)  0           activation_493[0][0]             \n",
      "                                                                 activation_496[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 17, 17, 1152) 3456        conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_9_Scaling_Residual (Lam (None, 17, 17, 1152) 0           Block_B_8[0][0]                  \n",
      "                                                                 batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_9 (Activation)          (None, 17, 17, 1152) 0           Block_B_9_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 17, 17, 128)  147584      Block_B_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 17, 17, 128)  384         conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, 17, 17, 128)  0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 17, 17, 160)  143520      activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 17, 17, 160)  480         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, 17, 17, 160)  0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 17, 17, 192)  221376      Block_B_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 17, 17, 192)  215232      activation_499[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 17, 17, 192)  576         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 17, 17, 192)  576         conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, 17, 17, 192)  0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 17, 17, 192)  0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 17, 17, 384)  0           activation_497[0][0]             \n",
      "                                                                 activation_500[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 17, 17, 1152) 443520      concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 17, 17, 1152) 3456        conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_10_Scaling_Residual (La (None, 17, 17, 1152) 0           Block_B_9[0][0]                  \n",
      "                                                                 batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_B_10 (Activation)         (None, 17, 17, 1152) 0           Block_B_10_Scaling_Residual[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 17, 17, 256)  295168      Block_B_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 17, 17, 256)  768         conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 17, 17, 256)  0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 17, 17, 256)  295168      Block_B_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 17, 17, 256)  295168      Block_B_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 17, 17, 256)  590080      activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 17, 17, 256)  768         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 17, 17, 256)  768         conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 17, 17, 256)  768         conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 17, 17, 256)  0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_503 (Activation)     (None, 17, 17, 256)  0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 17, 17, 256)  0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 8, 8, 384)    885120      activation_501[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 8, 8, 256)    590080      activation_503[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 8, 8, 256)    590080      activation_506[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 8, 8, 384)    1152        conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 8, 8, 256)    768         conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 8, 8, 256)    768         conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 8, 8, 1152)   0           Block_B_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_502 (Activation)     (None, 8, 8, 384)    0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_504 (Activation)     (None, 8, 8, 256)    0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 8, 8, 256)    0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Reduction_block_B (Concatenate) (None, 8, 8, 2048)   0           max_pooling2d_19[0][0]           \n",
      "                                                                 activation_502[0][0]             \n",
      "                                                                 activation_504[0][0]             \n",
      "                                                                 activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 8, 8, 192)    393408      Reduction_block_B[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 8, 8, 192)    576         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 8, 8, 192)    0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 8, 8, 224)    129248      activation_509[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 8, 8, 224)    672         conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 8, 8, 224)    0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 8, 8, 192)    393408      Reduction_block_B[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 8, 8, 256)    172288      activation_510[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 8, 8, 192)    576         conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 8, 8, 256)    768         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 8, 8, 192)    0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 8, 8, 256)    0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 8, 8, 448)    0           activation_508[0][0]             \n",
      "                                                                 activation_511[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 8, 8, 2048)   919552      concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 8, 8, 2048)   6144        conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_1_Scaling_Residual (Lam (None, 8, 8, 2048)   0           Reduction_block_B[0][0]          \n",
      "                                                                 batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_1 (Activation)          (None, 8, 8, 2048)   0           Block_C_1_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 8, 8, 192)    393408      Block_C_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 8, 8, 192)    576         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_513 (Activation)     (None, 8, 8, 192)    0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 8, 8, 224)    129248      activation_513[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 8, 8, 224)    672         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_514 (Activation)     (None, 8, 8, 224)    0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 8, 8, 192)    393408      Block_C_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 8, 8, 256)    172288      activation_514[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 8, 8, 192)    576         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 8, 8, 256)    768         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 8, 8, 192)    0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_515 (Activation)     (None, 8, 8, 256)    0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 8, 8, 448)    0           activation_512[0][0]             \n",
      "                                                                 activation_515[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 8, 8, 2048)   919552      concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 8, 8, 2048)   6144        conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_2_Scaling_Residual (Lam (None, 8, 8, 2048)   0           Block_C_1[0][0]                  \n",
      "                                                                 batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_2 (Activation)          (None, 8, 8, 2048)   0           Block_C_2_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 8, 8, 192)    393408      Block_C_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 8, 8, 192)    576         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_517 (Activation)     (None, 8, 8, 192)    0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 8, 8, 224)    129248      activation_517[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 8, 8, 224)    672         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_518 (Activation)     (None, 8, 8, 224)    0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 8, 8, 192)    393408      Block_C_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 8, 8, 256)    172288      activation_518[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 8, 8, 192)    576         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 8, 8, 256)    768         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_516 (Activation)     (None, 8, 8, 192)    0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_519 (Activation)     (None, 8, 8, 256)    0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 8, 8, 448)    0           activation_516[0][0]             \n",
      "                                                                 activation_519[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 8, 8, 2048)   919552      concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 8, 8, 2048)   6144        conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_3_Scaling_Residual (Lam (None, 8, 8, 2048)   0           Block_C_2[0][0]                  \n",
      "                                                                 batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_C_3 (Activation)          (None, 8, 8, 2048)   0           Block_C_3_Scaling_Residual[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "GlobalAvgPool (GlobalAveragePoo (None, 2048)         0           Block_C_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           GlobalAvgPool[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 5)            10245       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,582,373\n",
      "Trainable params: 25,514,053\n",
      "Non-trainable params: 68,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = InceptionResNet_V2(size=(299, 299, 3), N_classes=5)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lrate = 0.01\n",
    "\n",
    "import math\n",
    "def decay(epoch, steps=100):\n",
    "    init_rate = .01\n",
    "    drop = .96\n",
    "    epochs_drop = 2\n",
    "    lrate = init_rate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "RMS = RMSprop(lr=initial_lrate)\n",
    "\n",
    "scheduler = LearningRateScheduler(decay, verbose=True)\n",
    "\n",
    "nn.compile(loss=[\"categorical_crossentropy\"], optimizer=RMS, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = image.ImageDataGenerator(featurewise_center=1, featurewise_std_normalization=1, zoom_range=.15, vertical_flip=True, horizontal_flip=True, brightness_range=[.15, 1], rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 = image.ImageDataGenerator(featurewise_center=1, featurewise_std_normalization=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 975 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train = gen1.flow_from_directory(\"SelfCutData/SelfCutData/\", batch_size=20, target_size=(299, 299), shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 235 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test = gen2.flow_from_directory(\"SelfCutData/Test/\", batch_size=20, target_size=(299, 299), shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 49 steps, validate for 12 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 52s 1s/step - loss: 7.9688 - accuracy: 0.2051 - val_loss: 2545451925.3333 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0096.\n",
      "Epoch 2/150\n",
      "49/49 [==============================] - 33s 672ms/step - loss: 5.1295 - accuracy: 0.2308 - val_loss: 5390452096.0000 - val_accuracy: 0.1702\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0096.\n",
      "Epoch 3/150\n",
      "49/49 [==============================] - 34s 687ms/step - loss: 4.3619 - accuracy: 0.2185 - val_loss: 20092300.1667 - val_accuracy: 0.1702\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.009216.\n",
      "Epoch 4/150\n",
      "49/49 [==============================] - 33s 674ms/step - loss: 4.6874 - accuracy: 0.2410 - val_loss: 12510541.3333 - val_accuracy: 0.1702\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.009216.\n",
      "Epoch 5/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 3.5850 - accuracy: 0.2215 - val_loss: 933.2488 - val_accuracy: 0.1915\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
      "Epoch 6/150\n",
      "49/49 [==============================] - 33s 674ms/step - loss: 3.9149 - accuracy: 0.2338 - val_loss: 1797.7223 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
      "Epoch 7/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 4.0503 - accuracy: 0.2226 - val_loss: 165.9573 - val_accuracy: 0.1915\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
      "Epoch 8/150\n",
      "49/49 [==============================] - 33s 675ms/step - loss: 3.1092 - accuracy: 0.2308 - val_loss: 18.8783 - val_accuracy: 0.2340\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
      "Epoch 9/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 3.0027 - accuracy: 0.2185 - val_loss: 566.1598 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.008153726976.\n",
      "Epoch 10/150\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 3.4824 - accuracy: 0.1938 - val_loss: 1.6095 - val_accuracy: 0.2340\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.008153726976.\n",
      "Epoch 11/150\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 3.2930 - accuracy: 0.2113 - val_loss: 1.6600 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
      "Epoch 12/150\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 2.8083 - accuracy: 0.1990 - val_loss: 1.6173 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
      "Epoch 13/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.8586 - accuracy: 0.2041 - val_loss: 1.6244 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
      "Epoch 14/150\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 2.6585 - accuracy: 0.1959 - val_loss: 31.8427 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
      "Epoch 15/150\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 2.5043 - accuracy: 0.2144 - val_loss: 19.9366 - val_accuracy: 0.1915\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
      "Epoch 16/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.4488 - accuracy: 0.2338 - val_loss: 64.8561 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
      "Epoch 17/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.5277 - accuracy: 0.2185 - val_loss: 2.2899 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
      "Epoch 18/150\n",
      "49/49 [==============================] - 34s 694ms/step - loss: 2.6726 - accuracy: 0.2144 - val_loss: 105.8011 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
      "Epoch 19/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.4043 - accuracy: 0.2246 - val_loss: 1.7928 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
      "Epoch 20/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.2662 - accuracy: 0.2144 - val_loss: 1.6428 - val_accuracy: 0.2426\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
      "Epoch 21/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 2.3836 - accuracy: 0.2215 - val_loss: 6.3566 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
      "Epoch 22/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.3624 - accuracy: 0.2349 - val_loss: 8.3846 - val_accuracy: 0.2298\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
      "Epoch 23/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 2.1892 - accuracy: 0.2297 - val_loss: 1.6852 - val_accuracy: 0.1319\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
      "Epoch 24/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.2119 - accuracy: 0.2390 - val_loss: 1.6908 - val_accuracy: 0.1915\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
      "Epoch 25/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.9711 - accuracy: 0.2523 - val_loss: 1.6305 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
      "Epoch 26/150\n",
      "49/49 [==============================] - 33s 675ms/step - loss: 2.0612 - accuracy: 0.2790 - val_loss: 1.6661 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
      "Epoch 27/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.6879 - accuracy: 0.3313 - val_loss: 1.7269 - val_accuracy: 0.1915\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
      "Epoch 28/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.0354 - accuracy: 0.2400 - val_loss: 1.6821 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
      "Epoch 29/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.8227 - accuracy: 0.2636 - val_loss: 1.3802 - val_accuracy: 0.3745\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
      "Epoch 30/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.5538 - accuracy: 0.3426 - val_loss: 1.2572 - val_accuracy: 0.3660\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
      "Epoch 31/150\n",
      "49/49 [==============================] - 34s 688ms/step - loss: 1.4349 - accuracy: 0.4318 - val_loss: 1.2662 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
      "Epoch 32/150\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.4119 - accuracy: 0.4349 - val_loss: 1.5944 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
      "Epoch 33/150\n",
      "49/49 [==============================] - 33s 675ms/step - loss: 1.3998 - accuracy: 0.4123 - val_loss: 1.3878 - val_accuracy: 0.3617\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
      "Epoch 34/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 1.3441 - accuracy: 0.4800 - val_loss: 1.2287 - val_accuracy: 0.3617\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
      "Epoch 35/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.2618 - accuracy: 0.4903 - val_loss: 1.3449 - val_accuracy: 0.3277\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
      "Epoch 36/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.3154 - accuracy: 0.4738 - val_loss: 22.0803 - val_accuracy: 0.1702\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
      "Epoch 37/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.1029 - accuracy: 0.5292 - val_loss: 2.4853 - val_accuracy: 0.3872\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
      "Epoch 38/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.1267 - accuracy: 0.5292 - val_loss: 1.4719 - val_accuracy: 0.3617\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
      "Epoch 39/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 1.1068 - accuracy: 0.5508 - val_loss: 2.3911 - val_accuracy: 0.3064\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.004420024338794074.\n",
      "Epoch 40/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.0826 - accuracy: 0.5651 - val_loss: 2.5986 - val_accuracy: 0.3787\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.004420024338794074.\n",
      "Epoch 41/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.0997 - accuracy: 0.5641 - val_loss: 3.8395 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.004243223365242311.\n",
      "Epoch 42/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 1.0232 - accuracy: 0.6082 - val_loss: 1.5263 - val_accuracy: 0.3745\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.004243223365242311.\n",
      "Epoch 43/150\n",
      "49/49 [==============================] - 35s 707ms/step - loss: 1.0842 - accuracy: 0.5918 - val_loss: 1.3505 - val_accuracy: 0.4468\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0040734944306326185.\n",
      "Epoch 44/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.9618 - accuracy: 0.6277 - val_loss: 1.7099 - val_accuracy: 0.3319\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0040734944306326185.\n",
      "Epoch 45/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.9585 - accuracy: 0.6308 - val_loss: 2.1627 - val_accuracy: 0.3915\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.003910554653407314.\n",
      "Epoch 46/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 1.0279 - accuracy: 0.6092 - val_loss: 1.9591 - val_accuracy: 0.2894\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.003910554653407314.\n",
      "Epoch 47/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.9446 - accuracy: 0.6277 - val_loss: 7.0394 - val_accuracy: 0.3574\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.003754132467271021.\n",
      "Epoch 48/150\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.9077 - accuracy: 0.6441 - val_loss: 2.1803 - val_accuracy: 0.4213\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.003754132467271021.\n",
      "Epoch 49/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.9380 - accuracy: 0.6338 - val_loss: 1.2900 - val_accuracy: 0.5574\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0036039671685801802.\n",
      "Epoch 50/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.0699 - accuracy: 0.6379 - val_loss: 1.6716 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0036039671685801802.\n",
      "Epoch 51/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.9046 - accuracy: 0.6574 - val_loss: 1.7288 - val_accuracy: 0.3404\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.003459808481836972.\n",
      "Epoch 52/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.8724 - accuracy: 0.6821 - val_loss: 1.2929 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.003459808481836972.\n",
      "Epoch 53/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.8230 - accuracy: 0.7036 - val_loss: 1.5572 - val_accuracy: 0.4766\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0033214161425634938.\n",
      "Epoch 54/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.8454 - accuracy: 0.7077 - val_loss: 1.3348 - val_accuracy: 0.5277\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0033214161425634938.\n",
      "Epoch 55/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.7964 - accuracy: 0.7323 - val_loss: 2.3761 - val_accuracy: 0.4979\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.003188559496860954.\n",
      "Epoch 56/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.7595 - accuracy: 0.7395 - val_loss: 1.4547 - val_accuracy: 0.4851\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.003188559496860954.\n",
      "Epoch 57/150\n",
      "49/49 [==============================] - 34s 688ms/step - loss: 0.7419 - accuracy: 0.7323 - val_loss: 2.3786 - val_accuracy: 0.3787\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.003061017116986515.\n",
      "Epoch 58/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.7039 - accuracy: 0.7590 - val_loss: 3.7512 - val_accuracy: 0.3915\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.003061017116986515.\n",
      "Epoch 59/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.7860 - accuracy: 0.7754 - val_loss: 1.0985 - val_accuracy: 0.5830\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0029385764323070548.\n",
      "Epoch 60/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.7120 - accuracy: 0.7682 - val_loss: 1.1910 - val_accuracy: 0.4766\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0029385764323070548.\n",
      "Epoch 61/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.5972 - accuracy: 0.7928 - val_loss: 2.0472 - val_accuracy: 0.3660\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.002821033375014773.\n",
      "Epoch 62/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.6229 - accuracy: 0.7990 - val_loss: 1.3486 - val_accuracy: 0.4766\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.002821033375014773.\n",
      "Epoch 63/150\n",
      "49/49 [==============================] - 33s 675ms/step - loss: 0.5412 - accuracy: 0.8154 - val_loss: 1.8304 - val_accuracy: 0.3872\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.002708192040014181.\n",
      "Epoch 64/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.6087 - accuracy: 0.8144 - val_loss: 2.2130 - val_accuracy: 0.4383\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.002708192040014181.\n",
      "Epoch 65/150\n",
      "49/49 [==============================] - 35s 724ms/step - loss: 0.5430 - accuracy: 0.8154 - val_loss: 1.6090 - val_accuracy: 0.5319\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.002599864358413614.\n",
      "Epoch 66/150\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.5451 - accuracy: 0.8267 - val_loss: 1.2647 - val_accuracy: 0.5362\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.002599864358413614.\n",
      "Epoch 67/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.5528 - accuracy: 0.8256 - val_loss: 2.6159 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0024958697840770693.\n",
      "Epoch 68/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.6528 - accuracy: 0.8010 - val_loss: 1.4031 - val_accuracy: 0.5362\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0024958697840770693.\n",
      "Epoch 69/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.5496 - accuracy: 0.8297 - val_loss: 5.3305 - val_accuracy: 0.4043\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0023960349927139865.\n",
      "Epoch 70/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.4917 - accuracy: 0.8492 - val_loss: 1.8058 - val_accuracy: 0.4681\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0023960349927139865.\n",
      "Epoch 71/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.5202 - accuracy: 0.8431 - val_loss: 1.0958 - val_accuracy: 0.5447\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0023001935930054267.\n",
      "Epoch 72/150\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.5045 - accuracy: 0.8615 - val_loss: 0.8127 - val_accuracy: 0.6723\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0023001935930054267.\n",
      "Epoch 73/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 33s 676ms/step - loss: 0.4576 - accuracy: 0.8482 - val_loss: 1.7290 - val_accuracy: 0.4979\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0022081858492852095.\n",
      "Epoch 74/150\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 0.4215 - accuracy: 0.8533 - val_loss: 0.9658 - val_accuracy: 0.6468\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0022081858492852095.\n",
      "Epoch 75/150\n",
      "43/49 [=========================>....] - ETA: 3s - loss: 0.4456 - accuracy: 0.8526"
     ]
    }
   ],
   "source": [
    "hist1 = nn.fit_generator(train, validation_data=test, epochs=150, verbose=1, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('InceptionResNet_v2_scaled.h5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = image.ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "generator1 = image.ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 975 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "Train = gen1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/SelfCutData/\", target_size=(299, 299), shuffle=True, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 235 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "Test = generator1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/Test/\", target_size=(299, 299), shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 49 steps, validate for 24 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 55s 1s/step - loss: 4.4093 - accuracy: 0.3169 - val_loss: 3252880213.3333 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0096.\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 33s 675ms/step - loss: 2.6396 - accuracy: 0.3590 - val_loss: 7405578.2292 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0096.\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 33s 676ms/step - loss: 2.4932 - accuracy: 0.3744 - val_loss: 1396923.4870 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.009216.\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.5774 - accuracy: 0.3785 - val_loss: 5271.6171 - val_accuracy: 0.2213\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.009216.\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.3259 - accuracy: 0.4185 - val_loss: 40000.8094 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 2.1925 - accuracy: 0.4533 - val_loss: 6.8744 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.6893 - accuracy: 0.4738 - val_loss: 1.4117 - val_accuracy: 0.3617\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 2.2223 - accuracy: 0.5262 - val_loss: 15.9188 - val_accuracy: 0.2936\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 2.2626 - accuracy: 0.5077 - val_loss: 69.6984 - val_accuracy: 0.2596\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.008153726976.\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.2742 - accuracy: 0.5774 - val_loss: 3.9094 - val_accuracy: 0.1787\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.008153726976.\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.3960 - accuracy: 0.6513 - val_loss: 4.1054 - val_accuracy: 0.2213\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.1001 - accuracy: 0.6903 - val_loss: 4.2727 - val_accuracy: 0.2766\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.9333 - accuracy: 0.7138 - val_loss: 1.9014 - val_accuracy: 0.4596\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 1.0629 - accuracy: 0.7395 - val_loss: 3.5465 - val_accuracy: 0.2723\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.7578 - accuracy: 0.7744 - val_loss: 2.9103 - val_accuracy: 0.5872\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 1.6848 - accuracy: 0.6933 - val_loss: 3.9398 - val_accuracy: 0.3702\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 1.0222 - accuracy: 0.7323 - val_loss: 1.7429 - val_accuracy: 0.4936\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.6823 - accuracy: 0.7856 - val_loss: 3.9255 - val_accuracy: 0.3574\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.7791 - accuracy: 0.8062 - val_loss: 1.1829 - val_accuracy: 0.5872\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.6832 - accuracy: 0.8133 - val_loss: 51.3781 - val_accuracy: 0.3957\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
      "Epoch 21/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.5730 - accuracy: 0.8297 - val_loss: 1.0586 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
      "Epoch 22/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.8169 - accuracy: 0.7990 - val_loss: 1.6960 - val_accuracy: 0.5915\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
      "Epoch 23/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.5059 - accuracy: 0.8513 - val_loss: 1.6946 - val_accuracy: 0.5787\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
      "Epoch 24/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.5540 - accuracy: 0.8297 - val_loss: 7.0214 - val_accuracy: 0.7149\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
      "Epoch 25/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.5560 - accuracy: 0.8615 - val_loss: 2.0036 - val_accuracy: 0.5574\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
      "Epoch 26/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.6748 - accuracy: 0.8533 - val_loss: 0.5217 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
      "Epoch 27/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.8267 - accuracy: 0.8472 - val_loss: 1.2564 - val_accuracy: 0.7064\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
      "Epoch 28/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.3993 - accuracy: 0.8759 - val_loss: 1.4608 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
      "Epoch 29/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.4986 - accuracy: 0.8790 - val_loss: 5.7544 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
      "Epoch 30/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.3533 - accuracy: 0.8913 - val_loss: 0.7050 - val_accuracy: 0.8043\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
      "Epoch 31/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.7407 - accuracy: 0.8441 - val_loss: 2.3937 - val_accuracy: 0.5745\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
      "Epoch 32/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.3795 - accuracy: 0.8862 - val_loss: 1.5450 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
      "Epoch 33/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.4336 - accuracy: 0.8862 - val_loss: 2.0219 - val_accuracy: 0.5447\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
      "Epoch 34/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.3418 - accuracy: 0.9026 - val_loss: 1.5652 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
      "Epoch 35/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.3796 - accuracy: 0.8974 - val_loss: 1.6498 - val_accuracy: 0.6894\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
      "Epoch 36/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.3649 - accuracy: 0.8944 - val_loss: 1.4928 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
      "Epoch 37/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.3405 - accuracy: 0.8985 - val_loss: 10.6990 - val_accuracy: 0.5319\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
      "Epoch 38/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.3386 - accuracy: 0.9015 - val_loss: 1.0068 - val_accuracy: 0.7234\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
      "Epoch 39/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.3223 - accuracy: 0.9179 - val_loss: 2.1836 - val_accuracy: 0.5617\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.004420024338794074.\n",
      "Epoch 40/100\n",
      "49/49 [==============================] - 34s 689ms/step - loss: 0.3641 - accuracy: 0.9087 - val_loss: 1.0397 - val_accuracy: 0.7787\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.004420024338794074.\n",
      "Epoch 41/100\n",
      "49/49 [==============================] - 33s 683ms/step - loss: 0.2310 - accuracy: 0.9231 - val_loss: 0.7550 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.004243223365242311.\n",
      "Epoch 42/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.2891 - accuracy: 0.9231 - val_loss: 1.2395 - val_accuracy: 0.7532\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.004243223365242311.\n",
      "Epoch 43/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.3816 - accuracy: 0.9169 - val_loss: 2.8437 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0040734944306326185.\n",
      "Epoch 44/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.3258 - accuracy: 0.9087 - val_loss: 2.8687 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0040734944306326185.\n",
      "Epoch 45/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2697 - accuracy: 0.9272 - val_loss: 2.4912 - val_accuracy: 0.6681\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.003910554653407314.\n",
      "Epoch 46/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2052 - accuracy: 0.9333 - val_loss: 1.0863 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.003910554653407314.\n",
      "Epoch 47/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.4358 - accuracy: 0.9221 - val_loss: 1.0045 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.003754132467271021.\n",
      "Epoch 48/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2142 - accuracy: 0.9303 - val_loss: 2.5405 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.003754132467271021.\n",
      "Epoch 49/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.3419 - accuracy: 0.9395 - val_loss: 0.6799 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0036039671685801802.\n",
      "Epoch 50/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.1560 - accuracy: 0.9426 - val_loss: 2.5761 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0036039671685801802.\n",
      "Epoch 51/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2859 - accuracy: 0.9323 - val_loss: 2.2677 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.003459808481836972.\n",
      "Epoch 52/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2279 - accuracy: 0.9323 - val_loss: 2.1432 - val_accuracy: 0.7149\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.003459808481836972.\n",
      "Epoch 53/100\n",
      "49/49 [==============================] - 33s 677ms/step - loss: 0.1907 - accuracy: 0.9374 - val_loss: 0.6520 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0033214161425634938.\n",
      "Epoch 54/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.1699 - accuracy: 0.9538 - val_loss: 0.6770 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0033214161425634938.\n",
      "Epoch 55/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.2023 - accuracy: 0.9436 - val_loss: 0.9856 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.003188559496860954.\n",
      "Epoch 56/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1532 - accuracy: 0.9456 - val_loss: 0.4107 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.003188559496860954.\n",
      "Epoch 57/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1676 - accuracy: 0.9508 - val_loss: 1.1388 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.003061017116986515.\n",
      "Epoch 58/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.1934 - accuracy: 0.9518 - val_loss: 0.3933 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.003061017116986515.\n",
      "Epoch 59/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1011 - accuracy: 0.9682 - val_loss: 0.7579 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0029385764323070548.\n",
      "Epoch 60/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1412 - accuracy: 0.9579 - val_loss: 1.4134 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0029385764323070548.\n",
      "Epoch 61/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.1654 - accuracy: 0.9579 - val_loss: 2.1076 - val_accuracy: 0.6468\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.002821033375014773.\n",
      "Epoch 62/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1445 - accuracy: 0.9549 - val_loss: 1.3847 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.002821033375014773.\n",
      "Epoch 63/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1982 - accuracy: 0.9579 - val_loss: 0.4411 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.002708192040014181.\n",
      "Epoch 64/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.2495 - accuracy: 0.9641 - val_loss: 0.9309 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.002708192040014181.\n",
      "Epoch 65/100\n",
      "49/49 [==============================] - 33s 682ms/step - loss: 0.1408 - accuracy: 0.9579 - val_loss: 1.1527 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.002599864358413614.\n",
      "Epoch 66/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.1038 - accuracy: 0.9692 - val_loss: 0.8331 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.002599864358413614.\n",
      "Epoch 67/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.0929 - accuracy: 0.9744 - val_loss: 1.0225 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0024958697840770693.\n",
      "Epoch 68/100\n",
      "49/49 [==============================] - 34s 695ms/step - loss: 0.1338 - accuracy: 0.9631 - val_loss: 0.2814 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0024958697840770693.\n",
      "Epoch 69/100\n",
      "49/49 [==============================] - 34s 692ms/step - loss: 0.0997 - accuracy: 0.9631 - val_loss: 0.4826 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0023960349927139865.\n",
      "Epoch 70/100\n",
      "49/49 [==============================] - 33s 683ms/step - loss: 0.0920 - accuracy: 0.9682 - val_loss: 0.5957 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0023960349927139865.\n",
      "Epoch 71/100\n",
      "49/49 [==============================] - 34s 689ms/step - loss: 0.0883 - accuracy: 0.9682 - val_loss: 0.4940 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0023001935930054267.\n",
      "Epoch 72/100\n",
      "49/49 [==============================] - 34s 688ms/step - loss: 0.0893 - accuracy: 0.9682 - val_loss: 0.3993 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.0023001935930054267.\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 34s 685ms/step - loss: 0.0960 - accuracy: 0.9733 - val_loss: 0.3477 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.0022081858492852095.\n",
      "Epoch 74/100\n",
      "49/49 [==============================] - 33s 678ms/step - loss: 0.0611 - accuracy: 0.9774 - val_loss: 0.6744 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.0022081858492852095.\n",
      "Epoch 75/100\n",
      "49/49 [==============================] - 33s 679ms/step - loss: 0.0745 - accuracy: 0.9815 - val_loss: 0.9414 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0021198584153138017.\n",
      "Epoch 76/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 1.2824 - val_accuracy: 0.7787\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0021198584153138017.\n",
      "Epoch 77/100\n",
      "49/49 [==============================] - 34s 690ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 1.2493 - val_accuracy: 0.7872\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.002035064078701249.\n",
      "Epoch 78/100\n",
      "49/49 [==============================] - 35s 711ms/step - loss: 0.1384 - accuracy: 0.9641 - val_loss: 1.4001 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.002035064078701249.\n",
      "Epoch 79/100\n",
      "49/49 [==============================] - 34s 695ms/step - loss: 0.0559 - accuracy: 0.9815 - val_loss: 1.3434 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0019536615155531993.\n",
      "Epoch 80/100\n",
      "49/49 [==============================] - 34s 696ms/step - loss: 0.0723 - accuracy: 0.9744 - val_loss: 0.6578 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0019536615155531993.\n",
      "Epoch 81/100\n",
      "49/49 [==============================] - 34s 690ms/step - loss: 0.0538 - accuracy: 0.9846 - val_loss: 0.3295 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0018755150549310713.\n",
      "Epoch 82/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.3587 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0018755150549310713.\n",
      "Epoch 83/100\n",
      "49/49 [==============================] - 33s 682ms/step - loss: 0.0833 - accuracy: 0.9867 - val_loss: 0.5475 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0018004944527338282.\n",
      "Epoch 84/100\n",
      "49/49 [==============================] - 34s 684ms/step - loss: 0.0910 - accuracy: 0.9733 - val_loss: 0.4583 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.0018004944527338282.\n",
      "Epoch 85/100\n",
      "49/49 [==============================] - 34s 700ms/step - loss: 0.0429 - accuracy: 0.9815 - val_loss: 0.7022 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.001728474674624475.\n",
      "Epoch 86/100\n",
      "49/49 [==============================] - 34s 692ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.3316 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.001728474674624475.\n",
      "Epoch 87/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 0.0706 - accuracy: 0.9836 - val_loss: 0.9162 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.001659335687639496.\n",
      "Epoch 88/100\n",
      "49/49 [==============================] - 34s 685ms/step - loss: 0.0842 - accuracy: 0.9795 - val_loss: 0.4669 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.001659335687639496.\n",
      "Epoch 89/100\n",
      "49/49 [==============================] - 33s 683ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.7011 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.001592962260133916.\n",
      "Epoch 90/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 0.0406 - accuracy: 0.9846 - val_loss: 0.4377 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.001592962260133916.\n",
      "Epoch 91/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.4098 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.0015292437697285593.\n",
      "Epoch 92/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 0.1762 - accuracy: 0.9795 - val_loss: 0.4709 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0015292437697285593.\n",
      "Epoch 93/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0317 - accuracy: 0.9867 - val_loss: 0.5756 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.001468074018939417.\n",
      "Epoch 94/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0514 - accuracy: 0.9867 - val_loss: 0.2710 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.001468074018939417.\n",
      "Epoch 95/100\n",
      "49/49 [==============================] - 33s 680ms/step - loss: 0.0305 - accuracy: 0.9867 - val_loss: 0.6966 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.0014093510581818403.\n",
      "Epoch 96/100\n",
      "49/49 [==============================] - 33s 682ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.3383 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.0014093510581818403.\n",
      "Epoch 97/100\n",
      "49/49 [==============================] - 34s 691ms/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 0.7731 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.0013529770158545666.\n",
      "Epoch 98/100\n",
      "49/49 [==============================] - 33s 682ms/step - loss: 0.0290 - accuracy: 0.9949 - val_loss: 0.7930 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.0013529770158545666.\n",
      "Epoch 99/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 0.0287 - accuracy: 0.9877 - val_loss: 0.5933 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.0012988579352203838.\n",
      "Epoch 100/100\n",
      "49/49 [==============================] - 33s 681ms/step - loss: 0.0336 - accuracy: 0.9856 - val_loss: 0.8552 - val_accuracy: 0.8809\n"
     ]
    }
   ],
   "source": [
    "hist = nn.fit_generator(Train, validation_data=Test, epochs = 100, verbose = 1, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplewise normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history['accuracy'], label='accuracy (testing data)')\n",
    "plt.plot(hist1.history['val_accuracy'], label='accuracy (validation data)')\n",
    "plt.title('Accuracy/epoch plot')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale by 1./255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXhU1f2435OZSTJZyEIAgYQdkX1fBEUQxQU3cEW0gIorFr/WamtptUVb26qtFpUfWsQFtYqKaF2KIKAIIhGQfQtLwpqVkGSS2c7vjzN35s5ktoQZ1vs+T56Zucu5597JnM/5rEdIKTEwMDAwOHtJONkdMDAwMDA4uRiCwMDAwOAsxxAEBgYGBmc5hiAwMDAwOMsxBIGBgYHBWY4hCAwMDAzOcgxBYGBwGiKEaCeEkEIIc4zak0KITrFoy+D0wxAEBnFHCLFUCFEuhEg62X2JJUKIVkKIopPdjxOJEGKSEOK7k90Pg9hiCAKDuCKEaAdcCEjgmhN87ZjMlsNwJfBlnK9hYBB3DEFgEG9+AawC5gIT9TuEEFYhxHNCiL1CiKNCiO+EEFbPvguEEN8LISqEEIVCiEme7UuFEHfp2vCboXpMHA8IIXYAOzzbXvC0USmEyBdCXKg73iSEeFwIsUsIccyzP08I8ZIQ4rmA/n4qhHhIt+lK4HPPvlZCiA+FEMVCiN1CiF/qzntSCDFfCPEfzzV+EkL01u3v6rmvCiHEJiHENbp9IZ+RhwlCiH1CiBIhxO9CfQlCiLlCiFlCiEWePiwTQrQNcWyGEOJNz73sFUJMF0IkCCG6ArOA84UQVUKIilDXMzjNkFIaf8Zf3P6AncD9QH/AAbTQ7XsJWAq0BkzAUCAJaAMcA8YDFqAp0MdzzlLgLl0bk4DvdJ8lsAjIBqyebbd52jADvwIOAcmefb8GNgBdAAH09hw7CDgAJHiOywFqtP57+lUCpKMmVPnAH4BEoANQAFzmOfZJz73f4DnvEWC3573F84we95x7sefeu0R4Ru089/oqYPX0uw7oGuJ7mOtpd7jn/BeCPLdOnvdvAp947q0dsB24M9jzNv7OjL+T3gHj78z9Ay7wDIA5ns9bgf/zvE8AbEDvIOf9Fvg4RJvRCIKLI/SrXLsusA24NsRxW4BLPe+nAp/r9o0CFnveDwb2BbmH1z3vnwRW6fYlAAdRJrMLUYIpQbf/Xc854Z6RJghyddtWA7eEuJe5wHu6z2mAC8jTPbdOHmFTB3TTHXsPsDTY8zb+zow/wzRkEE8mAv+TUpZ4Pr+DzzyUAyQDu4Kclxdie7QU6j8IIX4lhNjiMa1UABme60e61hsobQLP61u6fV6zENAWaOUx7VR4rvE40CJYn6SUbqAIaOX5K/Rs09iL0gDCPSONQ7r3NagBPhT6PlQBZZ7r68lBaSZ7g/TH4Awl3s40g7MUjx37JsAkhNAGqyQg02Mf3wDUAh2B9QGnF6JMM8GoBlJ0n88Jcoy3pK7HH/AYaga/SUrpFkKUo8xA2rU6AhuDtPM2sNHT367AAt2+K4GxujZ2Syk7h+gzKIGj9SkByEWZngDyhBAJOmHQBmWOKSH0M2oM+j6kocxnBwKOKUFpcW2Bzbr+7Pe8N8oVn4EYGoFBvLgOZXroBvTx/HUFvgV+4Rn05gDPexytJiHE+Z4Q03nAJUKIm4QQZiFEUyFEH0+764BxQogUT9z7nRH6kQ44gWLALIT4A9BEt/81YIYQorNQ9BJCNAWQUhYBP6I0gQ+llDYAIUR7IElKudXTxmqgUgjxmMe5axJC9BBCDNRdp78QYpwnkukhlPllFfADSrg9KoSwCCFGAFejzDjhnlFjuNLjhE8EZgA/SCn9tCcppQt4H3haCJHucSg/jBKKAIeBXE8bBmcIhiAwiBcTUTbyfVLKQ9ofMBMV6WJGOU03oAbbMuCvKFv5PtSM+1ee7etQzlCAfwB21ID0BkpohOMr4AvUDHsvaoatH/yeRw18/wMqgX+jnK8abwA98TcLjcFnFtIGz6tRwm43alb9GsoEpfEJcDPKP3E7ME5K6ZBS2lFhtVd4znsZJSg1IRP0GUW451C8Azzhaac/MCHEcQ+ihFMB8J3nvDmefUuATcAhIURJ8NMNTjeElIamZ2AQCiHEcNRsuJ1muhFCfA7MlFJ+HvZkXxtPoiJybot0bLwQQswFiqSU009WHwxOXQyNwMAgBEIICzANeC3AmbsU+OakdMrAIA4YgsDAIAie5KkKoCXwT/0+KeXfNH+BgcGZgGEaMjAwMDjLMTQCAwMDg7Oc0y6PICcnR7Zr1+5kd8PAwMDgtCI/P79EStks2L7TThC0a9eONWvWnOxuGBgYGJxWCCH2htpnmIYMDAwMznIMQWBgYGBwlmMIAgMDA4OznLj5CIQQc4CrgCNSyh5B9gtUTfQrUVUTJ0kpf2rMtRwOB0VFRdTW1h5Plw0MYkpycjK5ublYLJaT3RUDg7DE01k8F1VX5s0Q+68AOnv+BgOveF4bTFFREenp6bRr1w4lXwwMTi5SSkpLSykqKqJ9+/YnuzsGBmGJm2lISrkcVdwqFNcCb0rFKlR54paNuVZtbS1NmzY1hIDBKYMQgqZNmxpaqsFpwcn0EbTGvwpkEcex+IUhBAxONYz/SYPThZMpCIL9SoLWuxBC3C2EWCOEWFNcXBznbhkYGBjEl5KqOt74fg8/F1VwKpT5OZmCoAjdikn4r9jkh5RytpRygJRyQLNmQRPjDGLADTfcQEFBAQB//vOfG93O3LlzOXDA91XeddddbN68OcwZjePJJ5/k2WefDXvMggULorr2zJkzef3112PVNYM4YrO7eG/1PmrszuNuK9QgHM3gLKVk5a5SPl5bhNPl9tuu4XS5WV9Y4d1f63Dx1so9XPzsUp5YuIlrZq5g5LNLueGV77lp1kr+8MlGPswv4vlF27nrjR/5eG0RAHVOFzOX7CB/b/lx3G1oTmZm8UJgqhDiPZST+KiU8uBJ7M9pgdPpxGyO/de2adMmXC4XHTp0AJQgePzxxxvV1ty5c+nRowetWqnlcF977bWY9bOhLFiwgKuuuopu3bqFPe6OO+5g2LBhTJ48+QT1zKCx/HPxdv7fsgJWFZTyj5v7+JngVuws4d3V+/huZwnX98vl8Su7kiBgfdFRth2q5HBlHRed24zeeZnsr7Ax+fXVdG6Rzgs398FsUvNim93F5LmrOXi0lnsv6kifvEzW7CnD5nAxoF02TZIt/LinjA/WFPLTvgoA5q3ax93DO/D2D/vYUFTBC7f0ZXCHbKa+s5ZFmw+Tk5bIgLbZrNhVwrFaJ0M7NuXRy89jy8FKvt58mFqnC7vTzfz8It5cuZcEAc3Sk/h6yxH+t+kwWw8dY3dJNfePcNG/bVbMn2k8w0ffBUYAOUKIItTKSBYAKeUs1ApPVwI7UeGjp/Uv8LrrrqOwsJDa2lqmTZvG3XffDcCXX37J448/jsvlIicnh8WLF1NVVcWDDz7ImjVrEELwxBNPcP3115OWlkZVVRUA8+fP57PPPmPu3LlMmjSJ7Oxs1q5dS79+/bj55pt56KGHsNlsWK1WXn/9dbp06YLL5eKxxx7jq6++QgjBlClT6NatGzNnzuTjjz8GYNGiRbzyyit89NFHfv2fN28e1157LQC/+c1vsNls9OnTh+7duzNv3jzefvttXnzxRex2O4MHD+bll18G4M477/Texx133EFeXh5r1qxhwoQJWK1WVq5cyRVXXMGzzz7LgAEDSEtLY9q0aXz22WdYrVY++eQTWrRowa5du5gwYQIul4srrriC559/3vss9Dz99NO8+eab5OXl0axZM/r37w/Aq6++yuzZs7Hb7XTq1Im33nqLdevWsXDhQpYtW8ZTTz3Fhx9+yJIlS+odl5KSQkpKCu3atWP16tUMGhRquWSDxnDoaC0FJVW0yrDSOsuKxeQzRDhdbsymBKSU7CurobrORbdWvpVEXW6JKcE30O8qrmLOd7tpnWllwboDDO7QlPGD2gDwzdYjTJ77I5kpFnq2zuDf3+1m++Fj2Owu1uhm0i8s3sE9wzvwyboDlFbXsf1wFSkWE3+7oRdOt+S+efn8sLuMLi3S+e1HG0LeV26WlRnX9SDFYuKJhZu4+618ctISyUpNZPLcHznvnHQ2Hajknos6sK+0hvy95VzarQXX98tlaEcV3NInL9PbfwCHy01BcTWtMpNJSTQzc8lOXli8nbZNU3njjkFcdG58LCJxEwRSyvER9kvggVhf94+fbmLzgcqYttmtVROeuLp72GPmzJlDdnY2NpuNgQMHcv311+N2u5kyZQrLly+nffv2lJWpIKoZM2aQkZHBhg3qn6y8PLK6t337dr7++mtMJhOVlZUsX74cs9nM119/zeOPP86HH37I7Nmz2b17N2vXrsVsNlNWVkZWVhYPPPAAxcXFNGvWjNdffz3orHfFihWMH6++smeeeYaZM2eybt06ALZs2cJ//vMfVqxYgcVi4f7772fevHl0796d/fv3s3GjWve9oqKCzMxMZs6c6R34A6murmbIkCE8/fTTPProo7z66qtMnz6dadOmMW3aNMaPH8+sWbOCPoP8/Hzee+891q5di9PppF+/fl5BMG7cOKZMmQLA9OnT+fe//82DDz7INddcw1VXXcUNN9wAQGZmZtDjAAYMGMC3335rCIIAAgfjnUeOkZ2aRHZq8GWLl2w9zI7DVQxol8XKXaXM/GYntQ5lGsnNsvLaxAHkZaXwq/fX8+WmQ+SkJSKEoPhYHQDjB+Ux5cIOPLdoO0u2HOG3V57H7UPaAvDkwk0kW0x8/MBQfvX+ep5YuIm22Sn0zstk+oKNdGqexmcPXkCyxcTbq/byxMJNtEhP4k/Xdmdkl+akJpl5cuEmXl66i8wUCx/cM5RFWw7z4uId5O8rx+lSAunPY3syflAe3+8q5XBlLQPbZZNsMfHjnjKqap0MaJdF+5xUrzYyqH02G/YfZWSX5rikZNq7a1my7Qh/vb4nNw9sE/Q5BcNiSqDLOenez9Mu6cyNA3JpmpZIktnUsC+uAZx2RedOVV588UXvrLuwsJAdO3ZQXFzM8OHDvXHk2dnZAHz99de899573nOzsiKrejfeeCMmk/pHOHr0KBMnTmTHjh0IIXA4HN527733Xq/pSLve7bffzttvv83kyZNZuXIlb75ZP7Xj4MGDhPK/LF68mPz8fAYOVGux22w2mjdvztVXX01BQQEPPvggY8aMYfTo0RHvIzExkauuugqA/v37s2jRIgBWrlzJggULALj11lt55JFH6p377bffMnbsWFJSUgC45pprvPs2btzI9OnTqaiooKqqissuuyzo9cMd17x5c7Zu3Rr0vLOVvaXV3DBrJeMH5vHw6C5sPVTJNf9aQROrmb/f2JtOzdL4fMNBmqUncXXvVrzzwz6eWLjJr40xPVty08A8DlbY+MfX27n+5e9pnWVl55EqfnF+W+xON3anm35tsygsr2H28gLeXV1IkjmB81o24Q+fbOLjtfsprbKzr6yGP1zVjebpyfzz5j7cMnsVv5izmn5tsjhw1Mb8e88n2aJ+J7cNacslXVuQnZpIotmnhbxwSx/G9m1Nu5xU2uek0qN1E1ISTazZoyZkD4zs6B28h3XK8buXK3sGj3DPy04hLzvF+/nVXwygpKqO5k2Sj/s7aJVpjXzQcXLGCYJIM/d4sHTpUr7++mtWrlxJSkoKI0aMoLa2Fill0BDCUNv12wLjz1NTU73vf//73zNy5Eg+/vhj9uzZw4gRI8K2O3nyZK6++mqSk5O58cYbg/oYrFZryJh3KSUTJ07kL3/5S71969ev56uvvuKll17i/fffZ86cOUFa8GGxWLx9NJlMOJ0Nc/iFCsmcNGkSCxYsoHfv3sydO5elS5c2+Lja2lqs1vj/6E4E+XvLmLWsgL/f0IvMlOAz92ActTmY891uRnRpRteWTXjgnZ8oPlbHi0t20q1VBi8s3kETq5mmqUlMfv1Hv3P/8sVWio/VMbpbC/54bXfWF1bQNC2Jge2yvceM6NKcO9/4kb2lNcyZNJARXZrX68Pwzs34YuNB7r6wI7lZVl7/fg/zVu3lvHPSmTK8A7d6TClN05L48P6hTH1nLcu3F3P7kLb0b5vt19Y5GfUHYiEEI89r7vf53os6wkVRP6aIJCSImAiBE4VRaygGHD16lKysLFJSUti6dSurVq0C4Pzzz2fZsmXs3r0bwGsaGj16NDNnzvSer5mGWrRowZYtW3C73V7tItT1WrdWKRdz5871bh89ejSzZs3yDq7a9Vq1akWrVq146qmnmDRpUtA2u3btys6dO72fLRaLV9MYNWoU8+fP58iRI9529+7dS0lJCW63m+uvv54ZM2bw00+qQkh6ejrHjh2L4sn5GDJkCB9++CGAn7akZ/jw4Xz88cfYbDaOHTvGp59+6t137NgxWrZsicPhYN68ed7tgX0JdRwo81uPHvWqoZx2OF1ufvvRBhZtPsyfP9/it6+kqo6n/7uZ938sZG9ptd++NXvKuPKFb3lh8Q7GvfI91720go37K3np1n50a9mE++bls+VgJc+M68UnU4fxyOhz+fVlXfj20ZHMmTSA9jmp3DQgl5cm9KNlhpXLe7T0EwKgBuYFDwxjxW8uDioEQM3Cn7quJ22appCQILjzgvYseWQEs38xgNuHtPUzUzVJtjBn4gBm396f343pGqMnePZxxmkEJ4PLL7+cWbNm0atXL7p06cKQIUMAaNasGbNnz2bcuHG43W6aN2/OokWLmD59Og888AA9evTAZDLxxBNPMG7cOJ555hmuuuoq8vLy6NGjR1BnKcCjjz7KxIkTef7557n44ou92++66y62b99Or169sFgsTJkyhalTpwIwYcIEiouLQ0bPjBkzhqVLl3LJJZcAcPfdd9OrVy/69evHvHnzeOqppxg9ejRutxuLxcJLL72E1Wpl8uTJuN3K/qtpDJMmTeLee+/1Oouj4Z///Ce33XYbzz33HGPGjCEjI6PeMZqjvE+fPrRt25YLL7zQu2/GjBkMHjyYtm3b0rNnT+/gf8sttzBlyhRefPFF5s+fH/I4UH6SJ554Iqr+nmocqaxl2+FjXNAph/n5RWw/XEW/Npm8v6aI6/q2ZmjHHOqcLu5+c4030gWgW8smXHxec1YVlLJmbzltslN4567BLNl6hNe/38M9wzswpldLurdqwrUvreCqXi25pFsLAKZe3NnbTl52Chef1yKqvlpMCWRYYzcHNZsSGN39nJi1dzZy2q1ZPGDAABm4MM2WLVvo2tWYDYRj6tSp9O3blzvvvDPofpvNxsiRI1mxYoXXF3EiqampwWq1IoTgvffe49133+WTTz45Yddfu3Ytzz//PG+99VZM243l/+bmA5W8smwXNruLF8f3ISXRjNPl5o2Ve/nHou1U1TkZ3D6b3SXV5GZZmXfXEC5/YTluKXlgRCdWFpTyyboDzLy1L11apPPtjhI+Wbef9UVH6dQ8jbF9W/OL89uSnqyK5FXWOkhPMnvNcTa7i2RLgpExfZoihMiXUtaP4MDQCM4K+vfvT2pqKs8991zIY6xWK3/84x/Zv38/bdpEH+UQK/Lz85k6dSpSSjIzMyP6GmJNSUkJM2bMOGHXW19YQcuMZD87clm1nfy95TRLT6JPXiYAP+0r56tNh/ihoIx1hRWkJZmpsTu57+2f+MPV3fjV++tZV1jBiC7NuLBzM/61ZAcVNQ5eua0f1kQTz97Ym/vn/cRvPGGQD13Smat6qfyOzi3SueOC9hy1OWiSbK43wDdJ9q+aak088RMEgxODoREYGBwnUkoqbQ4spgSSE00kCIGUErvTzcbNW8hr38lvwN95pIorXlhOywwrnzwwDLNJMPWdtSzb7iufMqRDNgLByoJSLCZBr9xMLj6vObcNbssXGw/ym482IASkJZn589ieXNWrJUIIyqvt7C6tpl+bLL/+7SquprC8hos6NyMhwZjRn40YGoGBQRypqnOyt6wGgAQhSBAgJbikpKzazl3/XM6zN/ZmVNcWSCn546ebSDKbOFRZy71v51PrdLNp/1F+OaozF3TK4eeiCmYvL0AC08d0ZfygNqQm+X6qtwxqQ63DxXc7S3nymm7kZvnCFrNSVUKTHiEEnZqn0al52gl5HganH4YgMDA4To7aHCQIQW6WFZvDhVuqiopJlgTcZYm0zLBy5xtrGNOzJb3zMvh2RwlPXN2NDKuFh99fT6IpgZcn9PM6PAe1z+aOYSr3JNTsfdKw9kwaZqxzYBAbDEFgYBAlLrekstZBRrLFO0Ars5CTJskWMlMSyQw454gnC3bmkp28vmIP/91wkC4t0rl9SFvMpgQShKB1lrVemKVhvjE4kRiCwOCsp6zaTvGxOlo0SSLDasElJW63JFGX0i+lpLCshspaB6WJZto2TcFiSqCqzonT7SYjJfRPKcls4leju3DXBR348KciLuyc4y1wdl3fRi/BYWAQM4yEMgMv+jLUDaVdu3aUlJQAMHTo0KDHTJo0ifnz54dt50SVsNb3t7Sqjjqni31lNWw7dIzNByrZeugYv/n9H3F7gikOVdZSWesgKyWRWoeLXUeqqLE7OWpzcPf463DWBM/50JORYuGOC9rTuUV6xGMNDE4khiA4zWhoSYZoCSxDfTx8//33jT43UBC89tprEUtIN5QauxMtWK7W4cLmcNEyI5lWmVaSLSZaNEkmOzWRF5//O9sOHWPLwUqKj9XRNDWR3CwrHZqlIoFdR6qpqHFw0y23MmvWKzHto4HBicQQBDHiuuuuo3///nTv3p3Zs2d7t3/55Zf069eP3r17M2rUKACqqqqYPHkyPXv2pFevXt7SCmlpvqiO+fPne8tBTJo0iYcffpiRI0fy2GOPsXr1aoYOHUrfvn0ZOnQo27ZtA8DlcvHII4942/3Xv/7F4sWLGTt2rLfdRYsWMW7cuHr915ehfuWVV3j00Ue9++bOneut0BnqPvVo9yGlZOrUqXTr1o0xY8Z4S1QA/OlPf2LgwIH06NGDu+++Gykl8+fP95aw7tOnDzabjREjRqCFC7/77rv07NmTHj168Nhjj/ld73e/+x29e/dmyJAhHD58uF6fSktLGT16ND179WHiHVNwuFzYPDP6h+6cwGUjhnHR4H7876N5tGiSzMy//om6WhvXX3oBj/9yCi0zrNw/+VYGDBjAwL69WfrJOzSxmnFLyfVjr+Pdd98N+iwMDE4LpJSn1V///v1lIJs3b/Z9+PwxKedcGdu/zx+rd81ASktLpZRS1tTUyO7du8uSkhJ55MgRmZubKwsKCvyOefTRR+W0adO855aVlUkppUxNTfVu++CDD+TEiROllFJOnDhRjhkzRjqdTimllEePHpUOh0NKKeWiRYvkuHHjpJRSvvzyy3LcuHHefaWlpdLtdssuXbrII0eOSCmlHD9+vFy4cGG9/g8fPlz+/PPPUkopjxw5Ijt27Ojdd/nll8tvv/025H1KKWXbtm1lcXGx3318+OGH8pJLLpFOp1Pu379fZmRkyA8++MCvHSmlvO2227x9uuiii+SPP/7o3ad93r9/v8zLy5NHjhyRDodDjhw5Un788cdSSikB7/m//vWv5YwZM+rd39SpU+XDv5ku1xeWyznvzJeAXL15t9x6sFKu2bY36D3pv49g915cXCxrHeo76dSpk/c8PX7/mwYGJxFgjQwxrhoaQYx48cUXvTNSrQz1qlWrQpahfuAB31IMjSlDfeONN9KjRw/+7//+j02bNnnbDSxDLYTwlqGuqKjwLhQTiL4MdbNmzejQoQOrVq2itLSUbdu2MWzYsJD3GYrly5czfvx4TCYTrVq18quL9M033zB48GB69uzJkiVLvPcQih9//JERI0bQrFkzzGYzEyZMYPny5UD90tYFBbupqnNid7q8ywYuXbacUVddT4smyUy6ZRyZWVnUOFzUOV38Z+7sqO4p8N537tzprRHfvHlzP5OWgcHpxJkXNXTFMyf8kmdiGeqbb76Z999/n/POO4+xY8cihAh5n+EI1p/a2lruv/9+1qxZQ15eHk8++WTEdrQBXY/L7cblKYKnXUckJFBeXUtBsXLemhMSaGI143C5SUu20Dw9CSEEArBaTKxZ+R0rli2NeE+R7v1MKmFtcPZhaAQx4EwsQz1u3DgWLFjAu+++y8033xz2PkMxfPhw3nvvPVwuFwcPHuSbb74BfEIuJyeHqqoqv0iiUCWsBw8ezLJlyygpKcHlcjHvnXfo2GsQBSX+pZRr6ly43ZJzMpJpnWUlNclEeY2DAUOGsfS/HyGE4IsvvqC8vJzcLCsp1JGdHfye9KW4w927lJJDhw7Rrl27sM/DwOBUxRAEMeDyyy/H6XTSq1cvfv/73wctQ927d2/vgDp9+nTKy8vp0aMHvXv39g6QWhnqiy++mJYtg6+EBKoM9W9/+1uGDRuGy+Xybr/rrrto06YNvXr1onfv3rzzzjvefRMmTCAvLy9iGWqNrKwsunXrxt69e71LN4a6z1CMHTuWzp0707NnT+677z4uukit/KEtF9mzZ0+uu+4678pn4CthrTmLNVq2bMlf/vIXRo4cSe/evencrRcjLxuDze5C0xWklBytdWBKEDRLS6JpahJtm6bSrWU6zz0zg++++5Z+/frxv//9jzZt2pBoNjH2mqtC3pNWinvChAlh7z0/P58hQ4YE1bQMDE4HjKJzZwmnehlqgOo6JymJpnrmJLeUCHxmpvIaO4VlNbTKtFJjd3G0xkFuthWXS3LgqI022SkNWpXreJk2bRrXXHONNypMj/G/aXCqEK7onKERnAX079+fn3/+mdtuuy3kMfoy1CcDm93FruIqSqvt3m1SSkqr6th8oNK73S0lBytqSUk00zQ1kVaZyVhMgsKyGg4ctZFkNpFhtYS6TFzo0aNHUCFgYHC6YOiyZwH5+flRHRdqwfcTQY1D+TUqauzkpCUhpWRfWQ1HbQ6EEJRW2WmamsixWlXSITddLWJjFoLOLdKpdbhwuNxYLfU1ingzZcqUE3o9A4NYc8YIglARMwanJi63myPH6mienoQpIQGbXfk6auwule1rd3HU5mJ0vC4AACAASURBVKBFEzXjLyq3UWN3UV5tx2JKID3Z969rShB+ZZpPFU43s6vB2csZYRpKTk6mtLTU+OGdRpRWqUJvFTUqKkctg2hCoHwAh4/VYrWYaJ6eRIY1kQQhKD5Wx7FaJ5kpllNe6EspKS0tJTk5OfLBBgYnmVNvGtUIcnNzKSoqori4OPLBBicdKSWHKutUWeeDJrJTLRw4Wktakor3P7zPjQRy0hLZWuZJoqu2c9CjNcgmSVQcOPXnMMnJyeTm5p7sbhgYROSMEAQWi8WbvWtw6rNg7X4eWrCO9jmplFTV8cYdg7jrze95eUI/anHx8Ifr6dsmk4/u6+ud+a/cVcqUV1fRJy+TBQ/0O8l3YGBwZnHqT6sMzgiq6py8u3ofa/eVM2fFbjo0S+XhS8/lWK2Tt1ftBaBn6wwu73EOl3RtzhNXd/cz/wxun83Yvq2ZNqrzyboFg7ORg+thb+Or6Z4unBEagcGpjcstmfrOTyzd5jPdzbi2Oxd2ziFBwCfrDpCZYiE3S0UCvTZxYL02EhIE/7i5z4nstkFjKcqH6mLoPBoSTvO55v+mQ8U+mLY+Nu057fDze9DzJrCcOv4jQxAYxJ1nvtjC0m3FTB/TlVaZVvaW1nDjgDySLSZ65WayrrCCnq0zTnkHsEGUfHwPlO6AFj1g9AzoeHHkc05VSndB5X6orYTkJsff3s5FsPBBKNmhns0pwmkurg1Odb7efJhXv93NpKHtuOvCDlzZsyX3jehIskU5gYefqyqe9srNOJndNIgVxw4pIXDeVeCwwds3wOZPTtz1t30B9urIx0WDw6aEAMCRLbFps1itHcLKmVD4Y3TnbP+f77w4YQgCg7ghpeRf3+ykbdMUpo8JXmZh1HnNARgQsHi7wWnKnu/U6/BH4J5lkDsAPpgMWz6N/7X358O7t8TuWmW7fe8Pb4hNm6U7IaUpNGkNC+4DR/iqu+z/Cd65EV4aDPPvjJtAMASBQdxYvbuM9YUVTLmwg3ex9kB652XyzSMjGOHRDAxOc/Z8B0lN4JxekJQOt30Izc6Db/4c/2vvWKRe7ZHXj46KMt363YfDr5cREqcddn7t+1yyHZp3gzHPK80pktBa9ldIzoRhv1Tazrp5jetHBAxBYBA3/t/yApqmJnJD//Cx9O1zUg3/wJnCnu+g7VBI8BQuTEqHvEHKeRxvNEHgtIc/LlrKdqnXFj3g0MbGtZE/F96+Hg7+DFIq30BOZ+h0idIMdi6qf86eFVBVrLSB7V/C0Klw6Z/goQ1wwf81+nbCYTiLDY6LguIqfthdxk0D8jAlqMF8X2kNy3cUs2TrEX516blef4DBGY7mH+g/0X97SjbYytVAGC+BX12qTEMArrrIxx/eDImpkNU29DFlBWqwbjsU1r0DbrcvCqpiH9QehXN6hr/Ojq/Ua+EPkN4Saisg51zVTsdRSlvQt3toI8y9EiwpkH6O0gYG3aP2pTaNfF+NxBAEBsfFbz7awOrdZSzZeoSHLz2Xv3+1jSVb1SL1bZumcPv5YX5oBmcWmn+g3QX+263Z4HZCXSUkxykoYNcS0FamiKQROO0w53JlQuozHkZOhyZB1v8o3QXZHZRGYK+Cir1gsSoz17p5IEwwbR00aRX8Og6b75kUroYW3dX7pp5cmM6Xwob34cBayO2vtm36GEQCdLlCvR/1RGyilSJgCAKDRvPTvnJW7y7jws45LN5ymEWbD5OaaOLXl3Xhkq4t6Nw8jYQEw+Rz1qD3D+hJ8QQC1JTFTxDsXKRm77aKyBrBvpVQd1TNyH/+QA34k79Q2kpFISSYlWAo262EWose6ryD6+C7f6gIot7jYf278N0/4cq/Bb/Onu/AWQspOVC02icgczqp146jAKH6nttfaUybF6jjbpij/Ajxel4BGD4Cg0Yze1kBGVYLs27rz9zJg5g0tB1LHhnBAyM70eWcdEMInK6U7ACXI/Jx5XuVLRtg3w+w4QNoP9znH9CwegSBrez4+iUlHAoSveN2w87FamA1J4EzgiDYuQgSLHDTG3DZ00ow7F6uBNVro1TkkcMGlUVKI2jeFRDw1XSVaXz9a3DtTOhzq/IBVB4Ifp0di8BshcH3QPkelaFsToaMPLU/tSm07u/zbRzepKKKul2nPlsz42dKC8AQBAaNoqC4iq82H+L2IW1JTTIz/NxmPHlNd1o0OXWyJQ0awdEiFaq4aUH442wV8P8uhH/2gIW/hLfHQVoLuPLZ+sd6NYLyhvXF5VRCSeO7f8CsC9RgrGd/PtSUqExmUyK4IpiGdnwNbc9Xjuy+t0N6K1j6DHz5G6g6rGb+2v037QiJKeq1sgi6j4Nu16p9F/4KpEtpBcHYuQjaXwjtLlSftyyE7I7+grLzpar/1aU+s1DXa6J/RjHCEAQGYSkormLtvvo/4JlLdmIxJTBxaLsT36mzkboqNWONN0Vr1OBWdSj8cateUc7SzpfC2reUEJj03+C2dmuWem2IRuC0wwcTYeYA+H6mMscs/YvaF5jctXmBEgDnjq6vEVQUgtu3rjdHi6B4C3S6VH22JMOFD8O+7+Hn/8CQ+9Us/pun1f7sDuq19QBIbQZX/t3XVlY76HUL/PSG0iD0lO5SzuZOl0KrPsrc5KjxmYU0ulwBSHh1JKx9W5mF0k58KHVcBYEQ4nIhxDYhxE4hxG+C7M8QQnwqhFgvhNgkhJgcz/4YNIxth44x9uXvGfvy99w0ayWrd6sfcv7eMj5au587hrWnWXrSSe7lWcJXv4V3bo7/dQ6uU691x0IfY6tQguC8q+Dmt1VY493fBBcC4DMNRSvInHaYPxm2fqb8Df/7Hbx5nZrBiwT/+H4pVeZyx4uVPd2U5NMInHXw0iBYprPha2aYzqN92/rersw1LXrCJX+EHtfD0UK1TxMEY56F+1ZCao5/X7terfwARf7rqLNmjuc6lyoHs+Y3yTnX/7iWvWHCh0prqjoEPW+M7hnFmLgJAiGECXgJuALoBowXQnQLOOwBYLOUsjcwAnhOCHHiVh03CElhWQ2/mPMDSeYEHr28C/vKarhl9krmfLebJxZu4pwmyTx4cafIDZ2t1JQp23VDqasKXiKhbLcKz4w3B9b6+hGKH2YpZ+tFj6nPGbnhnZrWTEBE1gjcLsh/A2b2V0Lgir/BlCXKZl51SM3GM3LVbFtjf74atDW7ullnGrJXq1l4/lyfz2Pn12rQb9bF14YlGe5eBnd+pc7vP0ltT2nq6TtKCAWbqbcZooSTFh0EKkJo1cuqnWxPefy8Qeq1aZDquZ0vgSnfwP2rlFA6CcRTIxgE7JRSFkgp7cB7wLUBx0ggXahsojSgDHDGsU8GUfLbjzZgs7t4687B3D+iE4t/dREXn9eCP322mY37K3l8TNdTcnnIU4K6Y/CP7spk0VA+mKhKMgRSUwpOW/3tsURKOKBpBJXBj9n7Pax4QWkDLXsFPyaQBJMSFJE0gvzX4dNfKhPMbR8pJ6vJoiJoHlitZurZHf01gk0fK8dvlyvUZ5PONKQJhKpDsP0rFfu/c7GapQc6YVObqrwCUGUxWvSEZsHLovhhzVSzfU0QOGyw4H5VQuJSXVG5tsPUqxZCGogQyil9khIr4/lLbg0U6j4XAYMDjpkJLAQOAOnAzVLKRkyjDGJJrcPF6t1lTBrWji7npAOQmmTm/93enxcW76D4WB1X9wphBjBQlSodNSruvKFUHVbRI9Ul/maImtLIdWmOl4q9KuEJgpdp2Pu9KiKXkatCGxtCSnZkjeDAOiUE7lrsPyAmmHwz+OwOsHG+ElrgMwtpM3eTRWca0j2vNXOU7yPBBMMeCt8PIeA23TUi0e4CWP2q+n6+/5dKqrv9Y//4/65Xwz3L4Zwe0bV5gomnRhBMtAU+2cuAdUAroA8wUwhRL3tCCHG3EGKNEGKNsRxl/Plpbzl2l5shHfwLwZkSBA9fei5/GdfTKAkRDm0gCmdeCXmuA6RbRZhoSOkRBDWx6V8oNG3AlFTfRyAl/Oc2lTw18VNIb9Gwtq3ZkTWCsgI14w/3v9W0o3JS15Qpf8bRQuh+nW+/3lmsveacC7sWQ8FSVaohXDaxRvo5oX0egbS7UOUu7Fqiqop2GVO/9LYQyh9wihJPQVAE5Ok+56Jm/nomAx9JxU5gN3BeYENSytlSygFSygHNmhnFyeLNqoJSEgQMNCqCNg63x7rZmOJnmi1bH75Ze1S1KV3h4/sjxc9H4uA6Fd3Sqm99IVZdooTRwLvUINlQotEIygrUQB8OzXlbVgC7v1XvO47y7deHj2oawcC7lB2//XAYcEfD+x4JzU/w2UPqu7ro0dhfI87EUxD8CHQWQrT3OIBvQZmB9OwDRgEIIVoAXYACDE4qKwtK6dk6g/Rky8nuyunJ8WoEAHu+VYMvqAFYIzBMEZST9aN7lF+iMQ5qjQPrVGXM1Jz6GoFWlz9UOYVIWLPD5xHYq+HYQZ9zNRTZHkFRtkvZ5XPO9ddOgmkETTvC5C/hxjfiY4PX/ARVh6HLlSpc9DQjboJASukEpgJfAVuA96WUm4QQ9woh7vUcNgMYKoTYACwGHpNSlsSrTwaRsdldrCusYEiH+BW4OuPxRq2ECcEMhduhsk315iG9IHAG+AncLrUi2M/vqQqfkZKpguGoVSGhB9epQSwxrX7ftezZjNYNbx8iawRa7f/sCBpBVls1+y7ZrjKCA+sa+YWPep6VORnaDPYltsWD9p6kMS2S6jQjrmEfUsrPgc8Dts3SvT8AjA48z+Dk8dO+chwuaQiC40Gb1TdKI7Ar04ytArZ+rkwZ4TSCFS+o0g7NuqpEKZe9YWvhVh6AF/v6Bs1WfZWzOqRG0EhBYM1WpjKnXYVoBqKVfNZMP6EwJyln9eZPVGRToCAwJ9bXCMwnINv9goeVieo01AbAyCw2CGBVQSmmBMGAdlknuyunL5ogaJSPwKns3C17+8Ikq3VKcqBGsGUh5A322b6jqRGkp/KAarP/JFUeoudNKmY+UIhV7lf+g9TmDWtfIyVCdrF2r5EEgXZM6U71vm0wjUATBJpGcAKSHlOyoePI+F8nThiCwABQpSSe/u9m3ly5lx6nqn/g1Yvh5/dPdi8i4/URNMI05LKrATcjV5VDcLtDawRVxSoBrPOlKmxSf+1o0QbL7uNg0BRISlOmIbfD3/lceUDV5Elo5JARKbu4dJcKHY2m5LJmPgr0D4BHI9BlFoMSDgZhMQSBARuKjnL1v75j7vd7GNQ+m7+MjbDYRjA2fwKvXRJ97HVDcbtVFmljlwwEVbTs/V/Erk+hOF7TkClRZb+66lQxtRqdRqAXBLsWq9dOl6pzILpFWfQEM58keQZjvSA7ur/x/gHw2edDagS7I/sHNLTIokCzENQvMQEnRiM4zTFSQ89yCoqrmPT6ajJTEnn/3vNpnWltXEMH10PRjyrM0RQHbUL7cTfU9KFn7/cq5DCeK2WBmk1Dw53FbrcKETVZlEYAKk5eP4vWZxfvWKRMNef08plKGvp8vIOlzm6flKZe6475ktoq90Prfg1rW08kjaBsF3SI0rSiCQwtW1ePOYSz2CAshkZwlvPAO6q2zNt3DW68EID6af2xxisIjiNWvrpEDaRVR8IfV7AMXh3V+LVvGxs+qgkQP0FQpPotPD9VLbvY7VIaQadLlLmmsaYhVzCNIN3Tf48gk1KZhhobOgrhK5BqoaNNo/APgErWuvLZ4OWaTcGcxYZGEAlDEJzFFB+rY8vBSu65qAPtc1KPrzHvQB0vQeA4/vY1p2v5nvDHbf8S9q/xlVtoKFpfA+3s0Z6XECAIakrVerfg0wj2/6TWAe58ifrsNQ011Eeg2dF1GkGiRyPQnN01pUpgNMltWNt6UsJoBN7Q0SgFgTlR+TOCRR+ZEtVzd7sNjaABGILgLCZ/r/pRDohFBrFXIzgO0004YmEaqolSEBRvVa+NzdTV97EhWoF2j6ZENYO2pHoEQYkvbFPTCHYtVlqCZk7xagSNNQ2F8REcbzIZqMXYTUlKeAXijRiK0kcQDrNOIBoaQdQYguAsZs2ecpLMCfRoFYN1URuqEVQeUOYXffneWLYfiFaSGCILgiNbw1+rZAf8+7LQZaH15zXET6CVpjBZlA8jM8/nI9A0BE0jOFqkFoPRZtrHqxHoB0u9jwCUoxiOz1ksROiksmhzCKJBixBy1SmNwJR00ip6nk4YguAsZs3ecnrnZpJojsG/QUM1gkMblfll3o3RCYPjNQ3pY/HLd4c+zlYBxzxZtKE0giVPQeEqKN4WfP9xawSe2X1GLpQWqMSpjACNwF7lK5sMjRcErmCCIMBHcLzJZBqhykyUFUQfOhoJ7T6cHo3A0AaiwhAEZwFSSmYt28WOw77Zaa3DxaYDR+nXNkaJYw013Wj296R0JQzKIpSYOl7TkD4EM5xGULJdd80gguDwZhUqG64vbt32hiSVae1pg3pGrs9MpS14roWP2qt9tnz9OQ11cGt2dH2sfaCPoPLA8SWTaYTSCEoLYqMNgH8YrcsQBNFiCIKzgP0VNp75YivvrN7n3ba+sAKHSzIgVoKgoVFDmq342peUyebQhvDHu44zKqnak5SV08UnCLZ9AZ//2v84/Xq4wQbV5X/DW009VASTvo/6WHyXAz6cAls+C3Ge5iz2RHVn5KpwUlAVP4XJZxqqqwouCBpsGrIDwj/kNzHANFS5//iSyTSsWSGcxQWx8Q+ATiOo82gEhqM4GgxBcBaQv1cNuruKfUsgrvFs6x8zjaCRgkCb6epNS/Pv9Nnpve07/F8bSrVnHYvcgSpU0WFTi6Lnz/U/Tm/uCRzoi7er8tBdxnj2h7hXP9OQThB890/Y8L5aGD1Y4p3eWQy+ZwNq2USL1d80lBQLQVCrBk+/hWASlDCo02kEx+Mo1khKr78Mp71GmeJirhHYffdmEBFDEJwFrNnjEQRHfGaK/L3ldGyWSlZqjJaIbuhAbatQ0SmanVszURwtUitQrXs7oP0GOIvz58K6d/y3aaah3P7q9fAmZed32f1n/sVb1Mwb6msEmz8BJAx9MPh+b1+DmIYObYRlf1Uz6yObVfJdIPo8AvA5iAFSctTsVtMI6vkIGhk15LIHHyyT0n3LVR4tOj5HsYYpsb5w1fw10eYQREK7Fy1qyNAIosIQBGcB2ux/f4UNm92FlJKf9pUzoG0My/I2xjRkzfT9UAOTgAIdyA0SBG/UFwTVJcoO3sKzVGD+674oHYdulnpkq6phA/UHrZ2LoFU/3wAdUiPQm4aq1Ox/4VR1v3d8qWbbgZoI6HwEwQRBoEYQwkcQ2KeKQlj4y9BCy1kbfLBMTFPCJhbJZBrmpPr90Baij5VpyKR3FhsaQbQYguAM51itg22HKuncXA0aBSVV7CmtoaLGQd82mbG7UEPDO2srIDnTVzJZc4JqM96D69VqT972G6BxaPZhPdUlKjIly7PwyYb5vn2auaL2qDJTaEsK6tuoKVOz+M6X6madoXwEDt/gaq9SM+sDa2HIfaqefs8bYeNHSisKPA9UQhko7UFb8dWaFaARRCkICr6Bn97whWgG4rQHL8qWlK7MWlWH1X1mtAl+fkMwJdavntqQqqPRYNY5iw2NIGoMQXCGs3ZfBW4JNw9U9uZdxdWsL1QDUO+8GAqChoaP2sp9g5v+fO1VumHfKt/xgYXEwvaltv6AU1MCqU1V7RxLqv9MWBMEmn+gZS//a4IaUKXbU+AtghnG7VCzd3OyGkwrD6rtmZ61cvtPUgP6hg/8zwv0EZgTlZPYmgUmsxKajlqVNRvoIzCHEAR2T+5EqDDWULPmJI+PQJuxx8J0Y/aUiNb7R8oaUHU0GrzRU1oeQYxMn2c4hiA4w1mzt5wEAWP7tkYI5SdYV1iB1WLyaglh2fal/+w5FNrs2N1AQZBgVhmy2sCtr66551vf+4aYnpx19Y+rLlF2diEgq53a1slTnkEbJLVQzWAawY5FKg6+dT//wSYYWgVRzbyi5SVoZSJa9VGDX2CklD6hTCMjV5mFAMxWFWGlJcZFk0eg+ShCJbaF8hEkejSCWGb9epO9dP8jZbtjpw1AEGexoRFEgyEIznDy95Zx3jlNaJqWRF5WCruKlSDomZuB2RTF1//DK/Dtc5GPczbQNGSrUDZzITwmD48g0AbXpCb+foIGmYaCaASaaQh8gqDbdepVHy8P0LST/7243bDza1XsLMEUfEDT43Io8442q9Y0giYtfcdYrPWfVWBCGUCfW9Wfdo6z1tffoKahgD45GqsRpCvhUbbLsz5CXv1jGorebKNRuit2/gEICB8NIeQM6mGUoT6DsTvdrNtXwfX9ldOxY7NUth46xr7SGiYNaxdlIzWhSwfrcTXANCSlTyOAAEHg0Qg6XARb/6vs9skZDfNBOOvqmwRqSnwllXuMUwua5HgGfK+PoFKZjSxWXzsAh9ar8NPOl6rPCSZAhM8jMFlCawSB96w/D/z7rq08BqpftnJff/WCIMGkNKtQpqFQiW3OuhA+gjSfRpDVTpmmjhevGdAOScQ+dBR0QtrQCBqCoRGcwXz4UxHVdheXdFWrOHVslsbOI1XYXW76ROsfcNSobNBIC840RCNw1CgTUrKnD8E0gk6XKpv83pX+7UalEdj8B1mtzpBmYul5A1z1D10GrWdgratUtmpTgDO4ZId6be0JPRXCv+59IC6HGsy1wbTyoKeInK7MtzmpvmnJ5TENJYRYz0F7TlpuQlKAac+UGNo0FFIjCJF9qy1XWRrDZK/AxXNiHToKPq3Dm1BmaATRELUgEEIMEUIsEUKsEEJcF89OGRw/Dpebl5fupFduBhd2VjPhjjqfQNSOYnu1GlwCE4ECaUhCmZZM5tUIdIOi5iPIHahetWiXaGsNuZzK1q4/TqszpGkEGpqN3TtYHlMDYGC5Bq1PlhTfuSbdkoj1+uDwaQR1x1QCW3pA+GVYjSCEINDCR70aQUDpcFNiaNNQSB9BiMFSW66yZHsMI3p0ZhuIfcQQ1C86Z2gEURFSEAghzgnY9DBwDXA5MCOenTI4fj5Zd4DCMhsPXtwZ4cka7dhMCYKctCRaZUT5A9EGwVBLDIKyoWuOzmhm7PUEQRCNQNsX6CSOKAgCFi4HXzKZ5iPQ8AoCTSPwCIKEBDUrD2xLP6MPNvv29sFjGkrymIYqD/j7B8BzzwEaQWBCWSBa+KjXR5Duv99kqd+m1zQUQpCH1Ag8UTyuOt/SkMdLoEO7NIZVRzXMOiFuaARRE87wN0sIkQ/8XUpZC1QAtwJuoPJEdM6gYVTXOZny5hoShGD74WN0bdmES7r6CoV1bKYGvj55mV7hEBFtRllTBpkhYsn1tvKoNAJP/LzVo5VoYZHg8xFo4YSBgkC61OpcCabgbWvHu52+47Q6QykBGoElhCAA/+Qn7wInukElWJashtvhixqqq1LtnhOwDrQ5SG3+wKJzgXg1Ak0QBGoEQcxVEU1DtaF9BBrZ7YOf21ACNYJjh5QwS45BGXSNehqBIQiiIaRGIKW8DlgHfCaEuB14CCUEUgDDNHQK8uOeMr7fVcrhylospgQevbyL34CfnZrIqPOac02fKLNEpfQNkuE0Av3g0yjTUBCNwGxVP2ptu981wmgdek1Aa0urM5Ta1P9Yk1ldRzOb1FX6ZsL6gV4TUma9jT+IGUbfvwSLEiq1R9XSmOlRaASBRecCMScrwVwXShBYwpiGQgmCMCUmNGKd9atfU9hyHMujBkO7F3s1IA1BECVhQwGklJ8KIT4H7gc+Ap6WUn4b7hyDk8fafRUkCPj4gWGkJdX/aoUQ/HvSwOgbdNl91S/DRQ45oxykNYL5CDQThsOmBuGEBP/BMlDYWEKYtvwEQS0kpoQ2DYEaTP00gia+PnmT3HR90tCvjRuIy660gaR0n4ZTzzSURFRRQ3osVvV9eEt4R+Ms1t1bMELNmjVHeqxCR0FnttEJ/Vjb8BNMqlZUrcdoYfgIoiKcj+AaIcR3wBJgI3ALMFYI8a4QIoaBvwaxYm1hBee2SA8qBBqF3q4cbIlBDT/TUBSCQBvIQkUNaTNv/WCpbzec1uEMYqbS6gwlBkmgqycIPDNh/aAabMAyJYXXCDTTkEZQZ3EjfATa/UD9+wkqCCJoBC578MFSE4ixCh0FXR0gnYCNx4zdnOQTfIYgiIpw3/BTwPmAFfhcSjkIeFgI0Rl4GiUYDE4R3G7Jun3ljOnVMvLB0aKZFSC8IAg2+IbDVq5MJ5ppIzCPQBscwmkEIftSW/99tSeHIJhfJDFNCQK3O8BHoLu2wxZEEFgIW2tIcxZrRKURRDANaWaUmlI1qAYKjKCmIU3IhfMRBNFAtL7HNNkrwFnsrAut2R0PJouvcqphGoqKcILgKGqwtwJHtI1Syh0YQuCUY3dpNZW1TvrmxWh9AfDNJiG8aSha+72GrUKZhbSBOVAj0AYHcygfQZQagWayspWr8hDBSExVs2V7FSB1giAxwJYdMGCFzSPQEsp0dvZoNAKtNEUoR74mCKqL6/sHILxpKJhG4HYpp3pQjcDT93iEdno1gjiFd5qSfAULDY0gKsLlEYxFOYadqGghg1OYtfuUuSWmFUX15ZnDOYsboxFYdf0MzCMwJ9ff7mcaCiNs9LWKvPWLakI7JTXTkGZK0KKVTEnhB6xgs28Nty6hDJT2kxLgqA6lEYRKJgN/01Cgf0BrU//83S7fNYJpBF7HfBCNwJoNaS2g7fmh+9NQtP5rfXTESRCYkwyNoIGEixoqkVL+S0o5S0pphIueQhSW1XDFC99SWOabsa/dV056ktmbKxAT4qYR6MpLQIBGUOsvCLyx/EGEzeFNKiJHT7DjwkWnJKX5CwJ9+Gi4AUsvKALRBnTNhp/esv4yj+Zk1b7b7X9eKP8A6DSCkuD+DpPF/7vQm/aCJZR5F64PMhhbkuGR7dDt2tD9aSj6rF+Io0aQ6HMWBwuNNaiHUWLiNOSnfeVsJP/C0AAAIABJREFUOVjJlxsPebet3VdBnzaZJCREmR8QDdpAkpQRW41AW4tAwy+PQC8IIvgI3rkFlv0toC9BfAQOWxiNQBfrD/7ho3qnZuD5wbJ49f3T+wgC/QMQfE0DdwRB4NUIikMIggDTkGYWSs4IrxGcqFLNgaU74hXnb2gEDcYQBKchReXK/LF8h4qPr7E72Xqokr6xXF8AfIIgIzeCRtAY01CARqDVqXfUhvARBDEN2crrO7H9fAQ6c1NY01CVb+Dw0wh02kjggGIOk1DmjRrytBWYQ6DdM/gLLs1HEApvMTxbCB9BgLlKEwRpLZSQCdRgnGE0gnigz/qF+OQRgL9GYPgIoiKiIBBCTBVCxNADaXC87K9QguCH3WXY7C6+2VqMW8LA9jFcehJ8pqGM1hE0gkY6izX8SgcHagRhnMVOm79PAIInlDlr/ZPB9Hh9BJogCKIROGz1zw9bYiIgaijYMo+BWbag6iSFihgC/0EtmI8gsE+aIE9TRQfraQVeQXCCZs31NII4lYAwJ/lCcQ2NICqi0QjOAX4UQrwvhLhcRF2bwCBe7C+3YUoQ2J1ufthdylur9pCbZWVox5zIJzcEzVmckauiMLTqmIHobc2RFqZxOdWg6+cs1s2OA30Eemextqi8y+4rLqe3g0PAwKoN5OGcxWnqOE3j8SsxoRMkgVFDJkuYonMe01BypjKrNe9a/5jj0Qi0fgcSyjSkCYJAP4HrBAsCr/DTFfOLl4/Ae01DI4iGiIJASjkd6Az8G5gE7BBC/NlIKjt5HKiwcUGnHBLNCcxZsYdVBWVMGNwWUyz9A6DTCDyLqGuJYOBZcMVTZ1/TAhLTIpuGtLC+QNMQRNYItFmwy+HL2I1GI3CEMUFoA2rVYfXqTSjTO4uD5RGECB+V0hc1ZEmGh9ZDnwn1jwumEUTyEUQjCJxhBEFIjeAEDZZa1m88M4vBX7AZGkFUROUjkFJK4JDnzwlkAfOFEH8Le6JBzJFSsr/CRsdmaQxun83y7cUkmhK4aUBu7C+mzbabeNrW+wm+fRZev0K91waUxNTIpiFNmAQVBLYgPgJNI6jzDX7OOp9zOZxG4NT8DhHCR0GVigb/PAL9Osr1BEEI01DgcpPWrOAF8oJqBJGcxXpBEEUegVcQeAoPBuYSnGhnMfhHY8Uzj8B7PUMjiIZofAS/9FQh/RuwAugppbwP6A9cH+f+GQRQUeOgxu6idZbVu87AmF4taZoWh5mPvVr9kLRibXo/wbHDqnok+EwMSen1B0cp1bEamnM3OSCPAOprBKYAZ7E2+LnsOo0gUBAEaAQuO6r4WIgBQWuz8qCqRqoN2voZf7CoIXMIQaBtC5cPACF8BPbw51mi8RHoBHFEH4FWTO8EDpaa78XlUHWT4pFZrM+LMDSCqIhGI8gBxkkpL5NSfiCldABIKd3AVXHtnUE9NEdx68xkLu/ekrZNU7jzghiVCQ7EUaMWY9GycvUagbYKmMvpM0cEMw0t+ys81wV2LlafC39Qr2m6AnBhfQS6dQgSdaYhhy40VI/fDLvONxhGMg0dO+hLJgN/jcARJMxRG9ACV26LVDjO234ojSDMeeZIpiFLBI0g0EfgOTZYQlm80CLE4imETIYgaCjRCILPAe8IIIRIF0IMBpBSbolXxwyC4xMEKbRpmsKyX4+kR+sY1nPXY69RM+YUjyDQawTaAGyv0mkEaf4z0oPrYfnf1fuFv4SDP8OSp6DjKGjZx3ecNit0BAoCj49ASo8giFIj0MI2nbU+gRGNaUhfetnkCR91u9VrvaihJECq7F09rgDTUCj0fhHvuRFMQyaLWpcYwjuLNeEU0UdwEjQCs8eP4ThRgsAwDUVDNILgFUD/H1Tt2RYRT5TRNiHETiHEb0IcM0IIsU4IsUkIsSyads9m9ntyCFpnxSH+OhBHdWiNwFvnvlqnEaTqzCl2WHC/Kq0w4QO1SPm/L1Xhkde86F9PR/uxaiGceh8BUg2QLodOI7CH1wiS0gDhGXA8/QwVPqqZWGpK/QWBNkvW7OrBooagfi5BpOUmve1rpiGdRhDJWSyE7z5C+Qj0winQNBS4SpkzSu0llmgCNp5CSHu2IiF8OK6Bl2gEgfA4iwGvSSji0xVCmICXgCuAbsB4IUS3gGMygZeBa6SU3YEbG9D3s5L9FTasFhNZKREGmljgsKl6/knp6gflpxF4fsj2avXDFglKaGgD4aaP4fBGGPM8dL4Uzp+qfvyXPe2LQtLQBgNt5TK9RgAeE1RA1JA2yDlr/WflmmNXS0YLtsykHv3MOlAjgNDFy7yZwQGmsAabhgJ8BJHO0wRSUnr9fV7h5OmD5uPRTF6BpqGTohF4zH3xjFjSvjtzcugCfgZ+RCMICjwOY4vnbxpQEMV5g4CdUsoCKaUdeA8ILFxyK/CRlHIfgJQyoHCMQSD7y220ykyOfqnJaHG76ps57DXKgSqE0gpqQpiGnHW+ssiaaaTa81W2H65eRz0BU5ZA39vrX1sbVGsDBYHOoVrPWaybSQcWmrNYfdEp3oXnI5iGwJdM5tenEIJAG3QDcwm8UUORBEEQjSBSQhmE1wgCy1bYq9Vx5iTlhA40DXl9BCfQjq6t/KaZ9uKSUJYYv7bPUKIRBPcCQ4H9QBEwGLg7ivNaA4W6z0WebXrOBbKEEEuFEPlCiF9E0e5Zzf4KG62zUmLf8Ftj4avH/bc5qn0DaEq2fzkHvWnIZVc/vgSds9I7AHv6ajJD6/7BZ2ja4KYJAu2afk7kugBnsW7w9xMEnmxVLeKosYJAG8i95qpgPgJCawQRB/RGJJTp+xHKWQw+P42jxrcuc1JakPDRIGsxxxstJFjTCOJSYkKnERhERUQTj2eW3pj1B4JNWQNCLDCjwlBHodY9WCmEWCWl3O7XkBB34xE+bdqEWED9LOFAhS0+zuGygvo2ZHsNZHoGcmuAINAGET+NQBe+aK9Wn6NZ3UobiLymoYAfsmYaslgBEUQj0DmMNWezOdnjI9BmniEGHIteEOh9BIEaQZCoITgO01Cw8NEIPgLwmYZC+gh0fbBXKdMeKAd6KGfxiazQaUr0N9nFUyM4kb6P05xobP3JwJ1Ad8ArYqWUd0Q4tQjQL3aaCxwIckyJlLIaqBZCLAd6A36CQEo5G5gNMGDAgEBhcsbz075ynvpsM49f2ZXSaju58XAU26ugPMDxqp9RpmRD2W7/faDTCDTTkE4jiHa2pw34XtOQbqlK7RpInbCxh9cILFZPdEqtzwQRqi/aAvZOW4CPwDOIeAVBkDwCCCIIojUNBdEIIjmL9f0I6iMIFAQ1PoERVCOwAyLyNWOJOUl9z96oIUMjOBWIxjT0Fqre0GXAMtSAHmIlbD9+BDoLIdoLIRJRWsXCgGM+AS4UQpiFECkos5MRkqpDSsmfPt3MT/squPU1FYPfKjMO/+D2arXIu36Rc3u1bkaZ5u9sdARqBIn+ma1aDkI0WAKdxUn+r9oAZrL4ruGnEeg0Gb1GoI8uCieUvINlMI0gIJJJQxt0g60yBpE1oWDnR0oo0/cjVPVRCDAN6b6/wAXstTLQJ9KhqpXBiKtGEPD/YxCRaARBJynl74FqKeUbwBigZ6STpJROYCrwFWpwf19KuUkIca8Q4l7PMVuAL4GfgdXAa1LKjY27lTOTxVuOsK6wgl+O6kzLDDUItM6MsY/AafcNYOV7fNv9BpJUX+0ht9s30/bTCBJVtqjb1UiNwDP7tgRoBNoAZkr0aR0RfQQejSBSQpl2b+CfUBYpasjrIwgoqRGtaUgIX56E91xnFJqExzwWTMgGNQ2F0Qi07+1EopX3PhEJZYZGEDXRBNlq/+kVQogeqHpD7aJpXEr5OSohTb9tVsDnvwN/j6a9sw23W/Lcou20bZrCgxd3YsLgNnywpjC2y1GC/4y6fA+c09O3zKE2kGjlmsF/8NIEgTZIg8+Zawkyaw1GglmFn9aG8BF4BUEojSBAKHh9BFEOOJrjNVgeQWAkk0aoPIJoo4bA5zjV0KqWhsOSrPobbBbvXRM4iGkoMQ2O7vc/3ll74lfw0nw33rDeOOYRGBpB1ESjEcz2rEcwHWXa2Qz8Na69MgBg0ZbDbDlYyUOXdMZiSqBFk2SmXqzeB6W2EmYOgv35DbuQPUAQgG4mrdMInDb/dXDBZxrSZuHgmbFXR68RaLNjWwgfgTYr95qfAqOG9M5iT1+0QTbwPoLhnTUH0QhCRg1FcBZHk8gUqBFE4yNITAvuH4D6eQR6jS7p/7d35uFx3dXd/xyNpNFot7zKe+I4dhI7cRJnhWYFYgdK6FtaApSyltJAWZ6ylj596PK2pVCW9yUtW18KJWUttEBDQgihSVlCjJ3VzuLEjuNYtiXZ2qUZLb/3j9/9zdy5uncWaUYz9pzP8+iZmTszd4623/ee5XdOW3iOYKGvmtPlo+X0CBrKd+7TlJx/rSJSBwwZY04C9wJnLohVCgDf2vUcy9vjvPyCYNVtBAPPQt8TtrXDqosL/6AwIXBhoEafEIBdXPwLb3LE5xG4xXGyuNAQ2H/aYIVO0CPwJ6T9QpAKVg15+wjGT3g5Asl9dRiaIwgmi0MmlMHcQ0PunM4jMMZ6E/ne94J3w9ZXhj83KzQ0mu0RhFUNLWSfIchsKJssY44gph5BseT0CLxdxO9YIFsUHydGU/z0iV5u2raq8DkDbsEMJgXzUYhH4G5To4FFeNTnEXjXFTOTxSWLwS76wavvWTmCQGjIJVbzeQQNidwJUbdjOcwjiKoaikwWFxMa8s9b8AQlnyex9GzYcF34c34hNiZbCOJest/fJG+6GjyCMlQNaWioaAoJDd0lIu8VkTUi0uW+ym5ZjfNfDx9hasbwWxcW6A2ATwhCBpXnwglB8+IcoaHWzGuzhMB5BMHQ0HjGmyiErGEigRYTs5LFnsfhmuE5e4zJVA25DWWF9LwPzRHkqxrK12KiwP0T6XkLJej74w8NTae8Ns++35+Zmb0LuxLJ4nTupkylq5osLppChOBNwNuxoaFfe1+7ymmUAt/d8zybV7RxTnd7/hc73IIZjAXPTMNtvwtP/Tj8fU4Ilm+BgUP29enQUEv2bZRH4K7WwS7UqRzDYMLw/9PmEgLXOmJqItMMz9kzPYmdPRD3hSDG83smYaGhWfsIopLFc9xQ5s4ZnMk8n4XRL8Tudxr83vx/G24j4ELiurYmR/J7anNFPYKiKWRU5RkhX5orKBMDYyl+tr+P3YcGeEUx3gBkQivu1nF4Fzx1Jxy8L/x9bnFYvsUuIsM9mUqi9BWlLzSU7hPTlGk65+L34HkERYaGGkKEwC1ss/YReB5BvNWGh/wN6Nz7XdO5yfH8lSk59xEMYq9cAwt7VNO5oqqGmjIeQXCy2Vzw2xQUAuf1+MOG5Roenwt/7qVcn60eQdEUsrM4tP+PMeYrpTentvnarw7xoe88AkB9nXDTtpXFncCFMYKhof13eccjcgdpj+A8e3vyYEiy2FtIJkcz8eyWpZk21FnJ4tTcksVgz1FXl33MCZsLDU2O24WzvsmKTVoIfMPY0xvKCrBj22uhY032SEl/r6GwK9d0jiBlf67feiPc+LHiruzr45m2HYVONsuFX4hTASF3eRC/RzCdhPoFjvL6q7HKtVCrR1A0hewjuMR3vwnbF2g3oEJQYr656znOXNrC+2/YxNnL2+juKDKRFpUsfsoJQcBTcIQJgfsnbQgJDbmr15Ylto//dKB8dHLCHisqWRzSFiBWb4edO4FzeQhXZtq6zC7SYR5BuqfNeP6E5NJN9ivMHv9AHD9+0et9wortoV8Ut6D7PQInrvPKEQTKdyHEIwiEhirqEZRJCLTFRNEU0nTuj/2PRaQD23ZCKSFHBsbZc2iA992wiR1buud2krAcwchx6Hkw+/kgTgiWbrIL78mD9goZMh6Bv2rIVZ40L7E5hSmXLPYWv3T1T5FVQ/5b//FZVUPevNv6JmufyxFkhYaarGClitjP4CdrAHrI+9OLbjKTRxgfKLJqKD67aqgkOYLJ2TmeaskR+HeRl80j0DbUxVJIsjjIGLCx1IbUOnc8agfB79yyYu4nCfMI3KzgxKLMlXWQ1IhdRBoSdmjMiWfyVA15z7nQkL8NNcxuFVEIkUIQj24x0dDshYYCQtDQlH3lWYwgOWL1mbGQYTkG/6Lrvt+JAc8jkOwwUxRZOYJSCEFYaCjgEQSFYKEXS3/IrWw5gnj2rZKXQnIE3yfTProOO23sm+U0qha549GjbF7RxplLQ/rMF0oyJEew/y67YK/aDoPPhb/PX2/efT4cuh+WecPkwpLFboFsWZLdyjhdaTOQ/d5CSIeiQjwCF0f3N7abmrCvbUj4Wl/4pl75p57N9cozFvdCSyHvr/PGIE4lMz/38QFrT6yhsGqYLI+gFOWjYaGhwIbAZDBHUIHyUbDi2TZHzzcfLUvh8rfDxpeU5/ynIYXkCD7uuz8FPGuMOVwme2qS40MTPPDsCd59/dnzO1GwamhmGp7+CZy9w4Zzjj8W/r7JscwV41kvgn3fhyN77IKfjt17zc5So5krz5YlmXPU+3oNzckjiEjw1cczVUqxhux9BPUJL0cQDA35RGn85Nw8ArDfU5QQgBWK6VTG05oYsOJQ6GKelSPwQkrzShbnCg1FeQQLvaHMtz+jXCJUVwc7/qY85z5NKUQIDgE9xpgJABFJiMh6Y8zBslpWQ9z52FGMgZ1b5xEWguwcgTE2kTt+0rab6H0id2jILRhnvdje7v9xZkwl2H+uxhYrGjMNdsFq8g3IyfIIPCEIS7JGkQ4NBfv++5PHPo/AlYU2tGSSx8EcAdiQy1wbm7lFK3KWgRem8ucImjoKD++EegTzEAIR+3uZSma8KPc7avRyBMFk8UIPb3EhOzNdnl3FypwoJEfwLWDG93jaO6aUiNsfOcqGpS1sXDaPsBBkhGBmyi4wbsZwc5dtsZwMtBhw+ENDHatsWGhqYvbO4IZmKxqTE/a+f1xi1lV4YORkIbjFOqqnj/8zpibsAj/LI/CXj/rOM2ePIE8ZotvclvR5BIXMFHA4j2JmpjRCABmhHD1uz+/aZsTqvX0f7m9kxvsZVsgjAE3mVhGFCEG9N3weAO++zoArEf0jSe4/0M+NW7vnP5DenyROjtima2ATxfF2exXm78vj8AsB2PAQzF5AXSvqybFMO2RHLCw0NJccQS6PwAsNufBGQ1N4sthtKAs7RzGkNyZFeQTekJWsqqHJIkJDrkQ1WdxGtFy40NnIcWhdnp2r8Deec+2zF7zpnF/YtbyzWihECHpF5OXugYjcBPSVz6Ta4kd7jzFjYOdcS0b9JIdtSSfYq1TnESS6MuWDYeGh1Ej2ou6SbMHQTmOrjT27TVr+5+tDQkOlyhE4/JvWwOcRBJPF8ewrz7kOSHefHRVaSoeG/B5BAa2k0+cPzGSGwtpX58J5BCPHoXVp9nP+4TTlbAOd0z7/70WFoFoo5K/ubcBtIvIZ7/FhIHS3sVI8tz/Sw7rFzZzTHdFjvlCmvY6fi8+yIydTPo+guSsTK04OAwHRSY1mX72vvdzGlGd5BF5oqK7OCw35hMDfa2g+HkGuHEFdw+wFPjRZHPAI5ioE+VoVxOIh+wgKGC7j8A+wL8WGMvf+6UkY7c3sBXH4B9g70VzwHEEJPDWl5BTSa+hpY8zl2LLR84wxVxpj9pfftNOfgbEUv3i6n51bigwLpcbg3o9lJ/5cWKh9VeZxmEcQtrs4GBqKNcAVt8DZgfK7dGjIq6TJCg352lDPSwgiPIK6eitA/kXWeSVTEzbmPVliIQjb7ezHhWHcz3Q6aX/uxVQNgecRlGAfQdqmQjwCX6ntQhIL5HyUqiCvEIjI34hIpzFmxBgzLCKLROSvF8K405279h5jasZwY7HVQgf/B37y1/CLWzPH0kLg9SdyOYJYo10sXdIwUggCiepr/xSuel/2MdfXx23mKmloKE+OwJ07Fogxu9dPjefIEczTI4j6PlxLZff9gpeknYNHUIoNZe6ck2PWK2xdnv2cf4C9P4y2kGR1mdWqoWqhkBzBTmPMgHvgTSu7sXwm1Q4/fPQoqzoTbF3Vkf/Fflxp4C9vzVTopIWgO/N47IT1BkQyg9mDOYKZmdkeQRSN3hVlWI7AH78vR44gTAhcshisl1SuHEHUYunCMBNDmUV3pLfwqqHQHEEJPILho3b2QMuy7Of8HsF0pYRAPYJqpBAhiIlI+jcmIglAf4PzZGhikvue6uXGrSuKrxZyO3cnBuH+z9n7wdBQatgKhhveEhUamhoHTIFC0OJLFjfNLh+ti9lNaDOTXjy/iEUtX44gLQS+c7pkMdirYDeMXQKjKeecI/Bvpgt73ttwlhyCzrX22FjfHEJDJc4RDHlD6oOhIX/VUMVCQyX4vSglpxAh+Cpwt4i8WUTeBNyFdh6dN3fvO8bktJlbgznnBWy8wXoFE4OZBT4dGvJ5BOALDQUazwV3oOaisTkzj6ChOVObDrOv2IuZTgaZCpKoSWCRHoETgvHsnbIlyRG40FBUjqDRy8MY6Fxnj81MzSE0VMocQaP1CGB2aMg/wD7di2iBF+OskJ1eT1YLhSSL/x74a+Ac4Dzgr4wxHy23Yac7P3zkKCvam7hwTWfxb54YsFd3L3y3FYED92YW+FYv35Ac8TyCRfZxVPmoWxiCOYIwGlu9K+CRzALiBCQYwil2E1eupnOQWSBnlY96n+88grAE75xzBHmSxfWNMOpVUjuPwG9rPrI8glJtKGsg3RosGBpyob2ZGeu5QKbceKGoi9kOt6BVQ1VEQd1HjTF3GGPea4z5E2BERG7N+yZlFnuPDPHdPYcZHJ/kp0/2smPLCuoKHUzvZ3wAmjozjeFOHsx4BE0dtkzQlY86j6Aulp0sdAQnWeXCvWb8RGZxdcdigQW72CvNXG2oITw0lOURjGV7BFmewzw9gsiqocbMTt1F67KPF3R+n0cwU8LQkCOsagjsvov0rvPF8/u8uZCvGktZcAravSIi24BXA68CDgDfKadRpyt/d8fj3PtkL0vb4qSmZrhx6xw3kU0MQKLTfjV1WiFwV6TxNvsP7zaUuRwB2PBQcjD7XKlAl8pcuKt8M+PzCLzFpT4QuinaI4hYHHImi5sznzM5Hu0RzDdHENlryBfa6FjtOz4Xj8ATgnlvKPO1YI4H5l37h9M4TyaxaH6fNxdijVa4VQiqhsi/OhE5G7gZKwD9wDcAMcZcu0C2nXbsPTLE1lUd9A4nWdWZ4OJ1c/wndB4BwKL1VggSiwDxSkXbbJx4ZjLjEYA9Pt/QkCPdnjrgEbiql2KFoH2V/R6WBDqwpj2FPOWjziNw8fzgfoO5kLdqyPcZiS5PaIfm5hFMewn2+bYZcTYF20tA9nCasX77847NU3jmgo6SrDpy/RU8DtwH/KbbQCYi71kQq05Djg9N0DeS5JZrNvCay9aSnJwhNpewEFiPoOtMe3/Rejj2KHRtsAuRiF2wBw7Z5/0egWs856eo0JBvcXcLbjpHEAjdFLv4NnfBBw7OPj7LIwhuKPN7BL6W0SL2/tRE+XoN+Reypg4rzsmhuZePzjc/ABmbg2EhyB5gP9ZfmbAQ5Pe0lAUnV47gt4GjwD0i8gURuR6Y5+VK7fJYj70SP3dlO00NMTqa5/FPH/QIBg5ZcXB7BeJtGSHwu/7xttnlo3PJEcDs0FCwumeuHT+D1Aeu8NOLr9jPSoeGAjkCv01l6zXku/Jv6oBER7athZ5/KllctVEunE3BRDH4ZhKM2mTxQieKHeoRVB2RQmCM+a4x5lXAZuCnwHuA5SLyTyKio3+KZO8RuwCf0+2L246fhOOPF38ylyMAKwTTKeh7MuP6x9syu2wTwRxB0COYb2jI5QjmmSyOIsojaEjYq373OalA1ZD/vfP2CAoQgnh7Rpzn1GKiiPbVuUiHhnJ4BKkRL39UIY8ga9iRUg0UUj46aoy5zRjzMmA18CDwwbJbdpqxt2eINV0JOhK+f/Z7Pw5f2hE+IyCKqZS9+vULAcCxvRkh8C/YwdDQrBxBER6B/yq/3hcakrrMjN657iOIIipZnG5J4X3OWB+cOJDtAdXH7WIz17h73l5DvtBRfWPmdzKnpnOp0jSAS4eGls9+Lu4bTjPaBy2VCg3pcPlqo6jh9caYE8aYzxljriuXQacr+44McW53oIrj5EHrFbiWEYXgdhU3BYRgOpntETjyeQSTY4AUdnWWFRryFuBF66DdXzFT6tBQxD4C5wnEGmylza+/bMtat785+73z8Uzy9RpyNrmQXFORQiBiw1dTE3ZUZSlCQ/U5QkNpj6DCOQItH606ihICpTD+9vZ9vPFLv+L+Z/oBGE1OcaB/lHO7Az2Fho7Y28EiRkA70XBXvh1rMht00kLg8wiycgTttobczceFTJ+hugL+FLJCQ97iePnb4ZafZ46XPDQUsY/Af/6GFisCZ14D667w2TJPIWhfZT8/qsTSLWiuxXeiyNAQkJ5bvCDJYk/Ih3psRVmlcgT5BFZZcCpQO3Z6MzE5zZd/cZCJyRnueaKXnVtW8Por12OMTRRnMdxjbwcPQ/f5hX3AeMAjiNVD5xrrXcR9yWKAeEd2eWCTrwOpCxmlRgq/es+qGnJX5PUQ83kgsTmWj0aRFoJAiMjvwTQk7P6IqwMRy/l6BJt2wnseyw6v+XG2uJ+7E4xiYv1ubvFMEZPNcpErNOSE/ORBe1txj0BDQ9WCCkGJ+fWzJ5mYnOHW11zEgb4RPv6jJ9lzyC7e5/mFYHoKRo7Z+8V4BC405K4+IbOXIJ0j8G6bA1ey6RjxsE8ICuw8Ct7iK4DJES5ZqNCQL6zQugyWn5vtDbj3Ts9DCESgJcdVs7PFeQTFhobA/k5GjttNevPdTOb/7LDQUF2d9Z4GnrWPK1Y+micJryw4KgQl5t4ne2mICddsWspLz7cDZz525xN0NjfQ3eH7wx/1/vnhikc8AAAYZklEQVQBBp8r/AOCHgFk8gRBjyARuJINm0kQNosgCjeZbHI0eqFfqNCQfxH5vX8Pt6dlaekEKYy0EDiPYA6hoQ3Xwp7bYOW20ngEzUusYLdFzLiIt2Y8gkoli+vj1mtyBQZKxVEhKDH//WQvF69bREvc/mhvuWYD0zOG6RmT3W56qCdzvxghiPIIYHaOIBjS8HsEjtRI4R4B2NdOjuavpFmoZDFYjyCM3/x0cRVZc7VtPh7Bua+AB74Iz90Pay6bv00XvBrOvDo7T+SnsRVOPG3vV3JDmXoDVYUKQQk5PjTB40eHef+OTeljIsI7r984+8XDXqK4qbPIZLHzCHyJ51lCEOERhA2nSY1mexf5aGyBUQoIDZXLIygirBAV2y8VbsGPBz2CIoRg3ZU2jFPMZLNc1Ddm/h7C8AtEpZLFzV2V80aUULRqqITc95Rt5HXVxpCKjSDOI1h9SfE5gsbW7EVjiSc8LkGYzhEEPQI3wD4YGirSI4ACQkNl2kfg4ujVUHESC3gErSsAKU5Y62Jwzm9690sgBPlwfxuxeHG/91Jy1fvg9/+zMp+thKJCUELufaqXxS2Ns/cLhDF8xP7jr9xmG8RNpQr7EH97Ccfyc+EtP4GzXmQfu6u+WTmCwJSyqaT97KYC7HU0tmD3HeQY3wgl3FCWsIuWW2zFtZaoBiFw+wg82zpWwVvvgc0vLe485/2Wd74S5Ajy4f42WpbMv8HdXEl05vZalAVHQ0MlwhjDL57u58qzlhQ2Y2Coxyb0OtcCxgpDIf8c/vYSflZfnLmf6AIE2gIlhMHQ0O6v2PNt/Z38n+tobMm0dwij5DmCRnjLXbapnsM1eKs0wRwBwMoLiz/PuiutNxcV1y8ljRH5I6WmKatHICI7ROQJEdkvIpFtKUTkEhGZFpFXltOecvL8wDjHh5Ncsr7A1tLDPdDWneljX2h4KMwjCNK6FN50B5x/c/bx+iZ7hX3wPttm4L5PwJrL4YyrC/ts8GYA5LgaL0fopvuC7EXydd+FK99ZuvPPFedh5SoxLYS6GLz++/Cij8zXovykCwkqlB9QqpKyCYGIxIBbgZ3AucCrReTciNd9FLizXLYsBLu9vQIXrS1CCNq7ocMbKFOoEER5BEHWXj67a6YIvPgv4OmfwGdfYL2Qaz5YXIggsWj2wBM/C7FrdMXW6kg2rjjflq6ecc38z7V0U/Zwm3KR9giq4OenVA3lDA1dCuw3xjwDICJfB24C9gZe98fAvwOXlNGWsrP72ZMkGmJsXtGW/8VgQ0MbrrdxZSi8hLQQjyAXl/2h3b9wxwetN3DmNcW9/5oPZqZbhZEWggolIhcSkUxe5lTBeTEqBIqPcgrBKsC/uh0GsgqlRWQV8FvAdeQQAhF5K/BWgLVr10a9rKLsPnSSC9Z0UB8rwMlKDtvGX+3d9sq5eUnpPYJcXP5HsHSznQZWbMKwY3XuK9fGZuyktDJu5FLmTqMvWawoHuXMEYStMMHdPZ8CPmCMmc51ImPM540x240x25cuLaA0c4EZT02z98hQ4WEhVzrattLedqwuTAhcC+pSJEo3XJvxRkrJBa+G13wjuwOqUj1EbTZUappyegSHgTW+x6uBI4HXbAe+7u24XQLcKCJTxpj/KKNdJefhwwNMzZjCZxC7zWTt3vD6jtXQvz//+8J2FVcbzV1w9g2VtkKJolGTxcpsyukRPABsFJEzRKQRuBn4nv8FxpgzjDHrjTHrgW8Dt5xqIgCZRPGFRXsETgjW2NGS05O53+daUFdD6aRyauJKXTU0pPgomxAYY6aAd2CrgfYB3zTGPCYibxORt5XrcyvB7kMnOWNJC10tXqL09vfD3661X/9xy+w3OI/ACcGZ19iQzxM/zH7doV/C566yYwUh016imj0Cpbo542q48eOw9or8r1VqhrLuIzDG3G6MOdsYs8EY87+9Y581xnw25LVvMMZ8u5z2lANjDHsODXDhWt/ifOjntgX0mkvgwdvgyJ7sNw0ftVdmLqF61ovsEJRf/0v26w4/AD0PwUNfs49d22r1CJS5Ut8Il/6Bdv5UstAWE/OkZ3CCvpEk29b4FufUGKy8CF75Jbto//Sj2W8aO5Edo43Vw4Wvs/X9rkUw2HGCYAXCGNj1z7a18vLzyvXtKIpSg6gQzJOHD9twzfmrfUIwOW6v9pva4cp3wJM/zPYKJgaz2xIAXPQ6W8q5+yuZY04I+p6E//kEPPNTeMG7tTRTUZSSokIwTx46PEhDTDin21cu6R/ccukfWq/gvn/IPB8mBB2rYeNLYM9XYcYbWDN2AjrX2a6hd/+l9Qa2v6m835CiKDWHCsE8eei5ATavaCde74u5To5nWiw0tcOG6+CYb0N1mBAAnHmtzQO46qCxE7ai6PzftY/VG1AUpQxo99F5MDNjeOTwIC/ftjJzcHoKplPZLRYSizKLO0QLQau3WW7kmO2lM9Zve9C84F22mZt6A4qilAH1CObBgf5RhpNTXJCVHxizt/6ma4lFdjOYC/lECYEbOD563N6On7A9YTrXwM6/U29AUZSyoEIwD9KJ4jW+RX1y3N76F+1Ep230lhq2w2CmxiM8Am9+wEivrRIaO6GtABRFKTsaGpoHDz03SKIhxllLfb3yJ0ftrX8wS8LbcTx+MhMyyhUaGj1uvQYzrV0iFUUpOyoEc2QsNcWvDpxgy6r27I6jziPwC4HbADY+YHMI/mN+mjptG+eRY5nSURUCRVHKjIaG5sA3HjjECz96D3t7htixpTv7yZTLEUR4BBOD9n6YRyBiS0RHejNtJYJzhxVFUUqMegRFYozhz//zMc5e3sYXfv9iLl7XZTeBLVoPZ1yVSRY3RgiB8RLGYUIA0LrMhobGPSFQj0BRlDKjHkGRTEzOkJyaYefWFVYEjIE7/wwe+Gf7gtCqIS8MNDGQ2yMAWzk0ctwXGlKPQFGU8qJCEIExhn/52QGOD01kHR8ct62iOxIN9sBoLyQHITViH0/OIzQENmGsQqAoygKiQhDB0aEJPvL9vXz1l89mHZ8lBH1P2dvksL0NSxY3JKC+ySaLC/EIRnvtXOC6+tyD4hVFUUqA5ggi6BtOAfDI84NZx2cLwZP2Nul5BGHJYrAVQeMn7eJe15AdOvLTusyWjfbvt/mBYmcKK4qiFIkKQQR9o0nACoExBm+c5mwhcCMm0x5BSLIYMm0mYo3WG4ha4Fu93cW9j2vFkKIoC4KGhiLoH7EeQd9Iip7BTJ4gOjQ0ZG+dENQHrvgTnTYsFNVewuHaTJx4RiuGFEVZEFQIIugbSabv+8NDTgg6E95YynRoaNhWEE2OWRGoC/xonUcwMWg7kkbhPAIzo4liRVEWBBWCCPpHkjTW1xGrEx457BOCsRQi0NZUb/sGDTxr8wFm2iaKU2Ph8f8sIcjlESzN3FchUBRlAVAhiKB/JMWytjhnL2/j4YBH0Bavp65ObPjGzED3BfbJ1Ig3naxl9gmbOjNVQ7mEILHIJpNBQ0OKoiwIKgQR9I4kWdwa5/xVHTzqJYzBCkFHcyA/sPIie5sctqGhKI9gctTuGs4lBCKZ8JAKgaIoC4AKQQT9IymWtDSyZXUHJ0ZTPD9g9wcMjk/6KoacEFxob5NDOYTANZ47mVsIIBMe0qohRVEWABWCCPpHkyzxPAIgnScYHJ/kwtgz0P+09QjaVkK713guOeyNqQwJDbndxZBfCNQjUBRlAVEhCGFmxtA/kmJxayObVrQhAk8cs/sEBsdS/Gnfh+Az22Hv92DJWRD3BtcnhyE1mtsjgPAW1H5aVAgURVk4VAhCGJqYZGrGsLg1TlNDjGVtcY54oaHk+CiJmVFYvgUwsOYyaPQG0yRdsjhkpGTTXDwCDQ0pilJ+dGdxCH3eZrIlrXavQHdHgiMDExhjaJjohwbg0rfC+b9rW0a42QHJIZsQDraXgIBHkEcIlp0L8Y7M6EpFUZQyokIQgttMtqQ1DsCqzgT7eoaYmJyhdcbbQdyyBOrt81mhocnxCCEowiPY+krY/FIdVq8oyoKgoaEQXHuJxZ5HsLKziecHxhkYT7FYPCHwx+/r47b2PznsbSgLCw11hN8PQ0RFQFGUBUOFIIR+r+Hc4hZ7xb+yM0FyaoYDfaMswmsu5xcCEesVuH0EYYt4XSwjAPmEQFEUZQFRIQihbziJCHS1OI/AVgHtPTJEV5hHABBvhbE+wES3mHbhIRUCRVGqCBWCEPpGU3Q1NxKrs62iV3lCsK9nmC4Zxkj97MU83g7Dx+z9sH0EYMtG6+rDQ0eKoigVQoUghP6RZDo/ABmPYF/PEF0MM5Pomj1PIN4GI04IcngEuWYRKIqiVICaEYIf7z3GZX/zY3oGx/O+tm8kla4YAljU3EBTQx37j4/QJcPhG72yhCDiir9jld2JrCiKUkXUTPloe6KBY0NJ9vUM0d0RccXu0T+SZOvqTN2/iLCyM8EzvaN0xYaoC6vvj7dlBthHVfy8+K8yg2sURVGqhJrxCDZ321r/fT3DeV/bP5JicUtj1rGVnngsqRtBojwCR1RoqLkLOlYXZrCiKMoCUTNC0N7UwJquBHt7hnK+bmJymuHkFEvb4lnHV3Y2AdDFsN1MFsS1mYDoZLGiKEoVUjNCAHDOinb2eULwbP8oN3zyXnYdPJH1mmd6RwFY2hoUggQxpmljJCJH4Bs/GeURKIqiVCG1IwTTk1ywtI6+vl7Ghk7wo91PcuTYMf7kK/dyuOeonRyWGuW2+5+lsb6O689ZlvX2lZ0JOhmhDgPNIR6BPzQUNqFMURSlSqmZZDGP/4C33/8G3h4HPgF/APxBEzADfM6+xCAcnv4wr9j2EhYHPIJVnQkWidtVHNIVtJAcgaIoShVSViEQkR3Ap4EY8EVjzN8Fnn8t8AHv4QjwR8aYh8pizPKtnHzhR/jMPfu5/pxl/OTxXq7csJi1i5v5+q+eY2VHnDeMfont5lFe9II/nPX2lZ0JFrv2EmE5giwh0A1jiqKcOpRNCEQkBtwKvBg4DDwgIt8zxuz1vewAcLUx5qSI7AQ+D1xWFoOWnEXHde/mm/f9iP86VM/RqQluuPYKzlrfxSUbjvKOf9vNFbE7+Y2Ww5zT3T7r7d0dTXTVhfQZcqgQKIpyilLOHMGlwH5jzDPGmBTwdeAm/wuMMT83xpz0Hv4SKGttZV2dsLm7jaNDE7Q31XPhGrtX4IbzVvD539/O0/VncR7PgDeo3k9TQ4x3XObtLcglBBKDWEO5vgVFUZSSU04hWAU853t82DsWxZuBH4Y9ISJvFZFdIrKrt7d3Xka5q/3f2LiU+ljm27920zJedsONNCRPwNDzoe89r2PK3sklBI0t2kJCUZRTinLmCMJWw9mX2oCIXIsVgheGPW+M+Tw2bMT27dtDz1EoTgiu3rR09pMrL7S3Rx60C/sXrrON5Orq4GWfhLF+aGzLDKTx44RAE8WKopxilFMIDgNrfI9XA0eCLxKR84EvAjuNMf1ltAeAF5+7nD2HTrJjy4rZT67YYkM7PQ/CcA/074eL3wBP3wM/+zQsORtaIgbKp4VA8wOKopxalFMIHgA2isgZwPPAzcBr/C8QkbXAd4DXGWOeLKMtaZa0xvn7V14Q/mRDApZuhiN7YPgorDgfXvYpeOCLcPt7rXfQERHdcjuLVQgURTnFKFuOwBgzBbwDuBPYB3zTGPOYiLxNRN7mvezPgcXAP4rIgyKyq1z2FMzKbfDMf8OxR603IGKH1NcnYORo+GYysBPIGlp0xKSiKKccZd1HYIy5Hbg9cOyzvvtvAd5SThuKpnsbPHibXdS3/o491tQBW34bHvxqeKLYEW/THIGiKKcctdNiolBWbrO3W38bmnz7CS5+g70N21XsiLdpaEhRlFOO2mkxUSgrL4Ir3wmXBByV1dvhuj+Ds3dEv/fqD+QWCkVRlCpETMjmqWpm+/btZteuyqcSFEVRTiVE5NfGmO1hz2loSFEUpcZRIVAURalxVAgURVFqHBUCRVGUGkeFQFEUpcZRIVAURalxVAgURVFqHBUCRVGUGueU21AmIr3As3N8+xKgr4TmlAO1sTSojaVBbZw/1WLfOmNMyCCWU1AI5oOI7IraWVctqI2lQW0sDWrj/Kl2+0BDQ4qiKDWPCoGiKEqNU2tC8PlKG1AAamNpUBtLg9o4f6rdvtrKESiKoiizqTWPQFEURQmgQqAoilLj1IwQiMgOEXlCRPaLyAcrbQ+AiKwRkXtEZJ+IPCYi7/KOd4nIXSLylHe7qMJ2xkRkj4j8oErt6xSRb4vI497P8ooqtPE93u/4URH5mog0VdpGEfl/InJcRB71HYu0SUQ+5P3/PCEiN1TQxo95v+uHReS7ItJZbTb6nnuviBgRWVJJG/NRE0IgIjHgVmAncC7wahE5t7JWATAF/Ikx5hzgcuDtnl0fBO42xmwE7vYeV5J3Aft8j6vNvk8DdxhjNgMXYG2tGhtFZBXwTmC7MWYLEANurgIb/wUIzl4Ntcn7u7wZOM97zz96/1eVsPEuYIsx5nzgSeBDVWgjIrIGeDFwyHesUjbmpCaEALgU2G+MecYYkwK+DtxUYZswxvQYY3Z794exC9gqrG1f9l72ZeAVlbEQRGQ18FLgi77D1WRfO3AV8M8AxpiUMWaAKrLRox5IiEg90AwcocI2GmPuBU4EDkfZdBPwdWNM0hhzANiP/b9acBuNMT8yxkx5D38JrK42Gz0+Cbwf8FfkVMTGfNSKEKwCnvM9PuwdqxpEZD1wIXA/sNwY0wNWLIBllbOMT2H/mGd8x6rJvjOBXuBLXvjqiyLSUk02GmOeBz6OvTLsAQaNMT+qJht9RNlUrf9DbwJ+6N2vGhtF5OXA88aYhwJPVY2NfmpFCCTkWNXUzYpIK/DvwLuNMUOVtschIi8Djhtjfl1pW3JQD1wE/JMx5kJglMqHqrLw4uw3AWcAK4EWEfm9ylpVNFX3PyQiH8aGV29zh0JetuA2ikgz8GHgz8OeDjlW8bWoVoTgMLDG93g11jWvOCLSgBWB24wx3/EOHxORbu/5buB4hcx7AfByETmIDaddJyJfrSL7wP5uDxtj7vcefxsrDNVk44uAA8aYXmPMJPAd4Moqs9ERZVNV/Q+JyOuBlwGvNZnNUNVi4was6D/k/e+sBnaLyAqqx8YsakUIHgA2isgZItKITdZ8r8I2ISKCjW3vM8Z8wvfU94DXe/dfD/znQtsGYIz5kDFmtTFmPfZn9hNjzO9Vi30AxpijwHMissk7dD2wlyqyERsSulxEmr3f+fXYfFA12eiIsul7wM0iEheRM4CNwK8qYB8isgP4APByY8yY76mqsNEY84gxZpkxZr33v3MYuMj7W60KG2dhjKmJL+BGbIXB08CHK22PZ9MLsW7hw8CD3teNwGJsxcZT3m1XFdh6DfAD735V2QdsA3Z5P8f/ABZVoY1/ATwOPAr8KxCvtI3A17A5i0nsYvXmXDZhwx1PA08AOyto435snN39z3y22mwMPH8QWFJJG/N9aYsJRVGUGqdWQkOKoihKBCoEiqIoNY4KgaIoSo2jQqAoilLjqBAoiqLUOCoESk3hdYL8B9/j94rIRypoUiQi8gYR+Uyl7VBOf1QIlFojCfwvf1tgRal1VAiUWmMKO0P2PcEnRGSdiNzt9bm/W0TW5juZiLxPRB7w3vMX3rH1Xr/8L3vHv+31n0FErvea4z3i9bGPe8cvEZGfi8hDIvIrEWnzPmKliNzhzQf4+5L9FBTFhwqBUovcCrxWRDoCxz8DfMXYPve3Af8n10lE5CXYFgGXYnc3XywiV3lPbwI+751rCLhFRJqwvetfZYzZim2Y90de25NvAO8yxlyA7U007p1nG/AqYCvwKq/HvaKUFBUCpeYwtsPrV7DDYvxcAfybd/9fsS1AcvES72sPsBvYjBUGgOeMMT/z7n/VO9cmbPO5J73jX8bOUtgE9BhjHnD2mUy//buNMYPGmAlsD6V1xXyvilII9ZU2QFEqxKewi/eXcrwmX/8VAf7WGPO5rIN2tkTwvYbwFsTuPFGflfTdn0b/Z5UyoB6BUpMYY04A38Q2MXP8HNtlFeC1wP/kOc2dwJu8eRKIyCoRcYNc1orIFd79V3vnehxYLyJnecdfB/y3d3yliFzinafNm2SmKAuCCoFSy/wD4K8eeifwRhF5GLtIvwvstCkR+cvgm42dMvZvwC9E5BHsLASX5N0HvN47Vxd2cM4E8EbgW97rZ7CdM1PYPMD/FZGHsDN5m0r+3SpKBNp9VFFKjBca+oGxg+oVpepRj0BRFKXGUY9AURSlxlGPQFEUpcZRIVAURalxVAgURVFqHBUCRVGUGkeFQFEUpcb5/1PekGx2hpIBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history['accuracy'], label='accuracy (testing data)')\n",
    "plt.plot(hist1.history['val_accuracy'], label='accuracy (validation data)')\n",
    "plt.title('Accuracy/epoch plot')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history09_04_20.pickle\", 'wb') as f:\n",
    "    pickle.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.load_weights(\"Batch_normed_inc_res_net_v2_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "246/246 [==============================] - 29s 116ms/step - loss: 4.9717 - accuracy: 0.8593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.97166115478785, 0.8592924]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate_generator(Test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2459 images belonging to 5 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "58/99 [================>.............] - ETA: 10s - loss: 12.6556 - accuracy: 0.0456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-80efcb7e18b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blood-cells/dataset2-master/dataset2-master/images/TEST/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf36/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.evaluate_generator(gen2.flow_from_directory(\"blood-cells/dataset2-master/dataset2-master/images/TEST/\", target_size=(299, 299), shuffle=True, batch_size=25), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
