{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten, Activation, BatchNormalization, Add, AveragePooling2D, Input, ZeroPadding2D, concatenate, GlobalAveragePooling2D, Lambda\n",
    "from keras.initializers import glorot_uniform, Constant\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, num_filters, filter_size, strides=1, padding=\"same\", activation=\"relu\", name=None, kernel_initializer=None, bias_initializer=None):\n",
    "    X = Conv2D(num_filters, filter_size, strides=strides, padding=padding, \n",
    "               kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, name=name)(X)\n",
    "    X = BatchNormalization(axis=3, scale=False)(X)\n",
    "    if activation:\n",
    "        X = Activation(activation)(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(input_layer, kernel_init, bias_init, name=None):\n",
    "    X = conv2d(input_layer, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = conv2d(X, 32, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X = conv2d(X, 192, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "#     X1 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "#     X2 = conv2d(X, 96, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "#     X1 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X1 = conv2d(X1, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X2 = conv2d(X2, 64, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X2, 64, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X2, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "#     X1 = conv2d(X, 192, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3, name=name)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normal1(X, X_prev, kernel_init=None, bias_init=None, name=None, scale=1):\n",
    "    X_short = X\n",
    "    \n",
    "    \n",
    "    X1 = conv2d(X, 64*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 48*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 64*scale, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X_add_1 = Add()([X1, X2])\n",
    "    X_add_1 = Activation(\"relu\")(X_add_1)\n",
    "    \n",
    "    \n",
    "    X3 = conv2d(X_prev, 64*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = conv2d(X_prev, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X4 = conv2d(X4, 48*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X4 = conv2d(X4, 64*scale, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X_add_2 = Add()([X3, X4])\n",
    "    X_add_2 = Activation(\"relu\")(X_add_2)\n",
    "    \n",
    "    X5 = conv2d(X, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 64*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_conc = concatenate([X_add_1, X_add_2, X5], axis=3)\n",
    "    \n",
    "    X_conc = conv2d(X_conc, 384*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_fin = Add()([X_conc, X_short])\n",
    "    X_fin = Activation(\"relu\", name=name)(X_fin)\n",
    "    \n",
    "    return X_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduction1(X, X_prev, kernel_init=None, bias_init=None, name=None, scale=1):\n",
    "    X1 = conv2d(X, 128, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X1 = conv2d(X1, 128, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X_prev, 128, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 128, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X3 = conv2d(X_prev, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X3 = conv2d(X3, 96, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X3 = conv2d(X3, 128, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = MaxPool2D((3, 3), strides=1, padding=\"same\")(X)\n",
    "    \n",
    "    \n",
    "    X5 = conv2d(X, 96, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 128, (1, 5), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 128, (5, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X6 = MaxPool2D((3, 3), strides=1, padding=\"same\")(X_prev)\n",
    "    X6 = conv2d(X6, 128, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X7 = conv2d(X, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_add_1 = Add()([X1, X2])\n",
    "    X_add_1 = Activation(\"relu\")(X_add_1)\n",
    "    \n",
    "    \n",
    "    X8 = MaxPool2D((3, 3), strides=2, padding=\"valid\")(X_add_1)\n",
    "    \n",
    "    X_add_1_2 = Add()([X8, X7])\n",
    "    X_add_1_2 = Activation(\"relu\")(X_add_1_2)\n",
    "    \n",
    "    \n",
    "    X_conc_1 = concatenate([X3, X4], axis=3)\n",
    "    \n",
    "    \n",
    "    X_add_2_1 = Add()([X6, X5])\n",
    "    X_add_2_1 = Activation(\"relu\")(X_add_2_1)\n",
    "    \n",
    "    \n",
    "    X9 = conv2d(X_conc_1, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X10 = conv2d(X_add_2_1, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_add_2_2 = Add()([X9, X10])\n",
    "    X_add_2_2 = Activation(\"relu\")(X_add_2_2)\n",
    "    \n",
    "    \n",
    "    X11 = MaxPool2D((3, 3), strides=2, padding=\"valid\")(X_add_2_1)\n",
    "    \n",
    "    \n",
    "    X_fin = concatenate([X_add_1_2, X_add_2_2, X11], axis=3, name=name)\n",
    "    X_fin = conv2d(X_fin, 384*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    return X_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model1(size=(299, 299, 3), n_classes=5, name=None):\n",
    "    input_layer = Input(shape=size)\n",
    "    kernel_init = glorot_uniform()\n",
    "    bias_init = None\n",
    "    \n",
    "    X0 = Stem(input_layer, kernel_init, bias_init, name=\"Stem\")\n",
    "    X_mem = X0\n",
    "    X_mem = conv2d(X_mem, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X_0_1 = conv2d(X0, 192, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init) \n",
    "    X_0_2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X0)\n",
    "    X0 = concatenate([X_0_1, X_0_2], axis=3, name=\"stem\")\n",
    "    \n",
    "    \n",
    "    X1_1 = Normal1(X0, X_mem, name=\"Norm1_1\")\n",
    "    X1_2 = Normal1(X1_1, X0, name=\"Norm1_2\")\n",
    "#     X1_3 = Normal1(X1_2, X1_1, name=\"Norm1_3\")\n",
    "#     X1_4 = Normal1(X1_3, X1_2, name=\"Norm1_4\")\n",
    "#     X1_5 = Normal1(X1_4, X1_3, name=\"Norm1_5\")\n",
    "    \n",
    "    \n",
    "    X2 = Reduction1(X1_2, X1_1, name=\"Reduce1\", scale=2)\n",
    "    \n",
    "    X_mem2 = X1_2\n",
    "    X_mem2 = conv2d(X_mem2, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X2_1 = Normal1(X2, X_mem2, name=\"Norm2_1\", scale=2)\n",
    "    X2_2 = Normal1(X2_1, X2, name=\"Norm2_2\", scale=2)\n",
    "#     X2_3 = Normal1(X2_2, X2_1, name=\"Norm2_3\", scale=2)\n",
    "#     X2_4 = Normal1(X2_3, X2_2, name=\"Norm2_4\", scale=2)\n",
    "#     X2_5 = Normal1(X2_4, X2_3, name=\"Norm2_5\", scale=2)\n",
    "#     X2_6 = Normal1(X2_5, X2_4, name=\"Norm2_6\", scale=2)\n",
    "#     X2_7 = Normal1(X2_6, X2_5, name=\"Norm2_7\", scale=2)\n",
    "\n",
    "\n",
    "    X3 = Reduction1(X2_2, X2_1, name=\"Reduce2\", scale=3)\n",
    "    \n",
    "    X_mem3 = X2_2\n",
    "    X_mem3 = conv2d(X_mem3, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X3_1 = Normal1(X3, X_mem3, name=\"Norm3_1\", scale=3)\n",
    "    X3_2 = Normal1(X3_1, X3, name=\"Norm3_2\", scale=3)\n",
    "#     X3_3 = Normal1(X3_2, X3_1, name=\"Norm3_3\", scale=3)\n",
    "\n",
    "\n",
    "    X4 = Reduction1(X3_2, X3_1, name=\"Reduce3\", scale=4)\n",
    "    \n",
    "    X_mem4 = X3_2\n",
    "    X_mem4 = conv2d(X_mem4, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "\n",
    "    \n",
    "    X4_1 = Normal1(X4, X_mem4, name=\"Norm4_1\", scale=4)\n",
    "    X4_2 = Normal1(X4_1, X4, name=\"Norm4_2\", scale=4)\n",
    "    \n",
    "    \n",
    "    X_fin = GlobalAveragePooling2D(name=\"GLBL_Pool\")(X4_2)\n",
    "    X_fin = Dropout(.8)(X_fin)\n",
    "    X_fin = Dense(n_classes, activation=\"softmax\", name=\"final_out\")(X_fin)\n",
    "    \n",
    "    model = Model(input_layer, X_fin, name=\"V1.0\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "nn = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"V1.0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 145, 145, 192 55488       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 145, 145, 192 576         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 145, 145, 192 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 72, 72, 192)  331968      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 72, 72, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 72, 72, 32)   55328       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 72, 72, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 72, 72, 192)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 72, 72, 32)   96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stem (Concatenate)              (None, 72, 72, 384)  0           activation_4[0][0]               \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 72, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 72, 72, 32)   1056        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 72, 72, 32)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 72, 72, 32)   96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 72, 72, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 72, 72, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 72, 72, 48)   13872       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 72, 72, 48)   13872       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 72, 72, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 72, 72, 48)   144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 72, 72, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 72, 72, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 72, 72, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 72, 72, 64)   24640       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 72, 72, 64)   27712       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 72, 72, 64)   2112        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 64)   27712       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 72, 72, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 72, 72, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 72, 72, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 72, 72, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 72, 72, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 72, 72, 64)   18496       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 72, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 72, 72, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 72, 72, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 72, 72, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 72, 72, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 72, 72, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 72, 72, 192)  0           activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 72, 72, 384)  74112       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 72, 72, 384)  1152        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 72, 72, 384)  0           batch_normalization_15[0][0]     \n",
      "                                                                 stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Norm1_1 (Activation)            (None, 72, 72, 384)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 72, 72, 32)   12320       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 72, 72, 32)   96          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 72, 72, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 72, 72, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 72, 72, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 72, 72, 48)   13872       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 72, 72, 48)   13872       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 72, 72, 48)   144         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 72, 72, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 72, 72, 32)   12320       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 72, 72, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 72, 72, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 72, 72, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 72, 72, 64)   24640       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 72, 72, 64)   27712       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 72, 72, 64)   24640       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 72, 72, 64)   27712       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 72, 72, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 72, 72, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 72, 72, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 72, 72, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 72, 72, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 72, 72, 64)   18496       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 72, 72, 64)   0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 72, 72, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 72, 72, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 72, 72, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 72, 72, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 72, 72, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 192)  0           activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 72, 72, 384)  74112       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 72, 72, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 72, 72, 384)  0           batch_normalization_26[0][0]     \n",
      "                                                                 Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm1_2 (Activation)            (None, 72, 72, 384)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 72, 72, 64)   24640       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 72, 72, 96)   36960       Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 72, 72, 64)   192         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 72, 72, 96)   288         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 72, 72, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 72, 72, 96)   43104       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 72, 72, 128)  61568       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 72, 72, 128)  49280       Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 72, 72, 128)  49280       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 72, 72, 96)   288         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 72, 72, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 72, 72, 128)  384         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 72, 72, 128)  384         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 96)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 72, 72, 384)  0           Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 72, 72, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 72, 72, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 72, 72, 128)  86144       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 72, 72, 128)  49280       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 72, 72, 128)  82048       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 72, 72, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 72, 72, 128)  16512       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 72, 72, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 72, 72, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 72, 72, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 72, 72, 128)  384         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 72, 72, 128)  384         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 72, 72, 384)  0           Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 72, 72, 128)  0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 72, 72, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 72, 72, 512)  0           activation_25[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 72, 72, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 72, 72, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 128)  442496      Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 128)  589952      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 128)  147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 128)  0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 128)  384         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 128)  384         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 35, 35, 128)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 35, 35, 128)  0           batch_normalization_39[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 128)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce1 (Concatenate)           (None, 35, 35, 384)  0           activation_29[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 768)  295680      Reduce1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   110624      Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 768)  2304        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 768)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 64)   2112        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 64)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 96)   55392       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 96)   55392       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 96)   288         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 96)   288         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 96)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 96)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 64)   192         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 128)  98432       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 128)  110720      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 128)  4224        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 128)  110720      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 64)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 128)  384         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 128)  384         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 128)  384         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 128)  384         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 128)  73856       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 35, 35, 128)  0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 35, 35, 128)  0           batch_normalization_47[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 128)  384         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 128)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 384)  0           activation_36[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 768)  295680      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 768)  2304        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 35, 35, 768)  0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm2_1 (Activation)            (None, 35, 35, 768)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 64)   192         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 96)   55392       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 96)   55392       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 96)   288         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 96)   288         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 96)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 96)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 64)   192         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 128)  110720      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 128)  98432       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 128)  110720      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 128)  384         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 128)  384         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 128)  384         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 128)  384         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 128)  73856       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 35, 35, 128)  0           batch_normalization_54[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 35, 35, 128)  0           batch_normalization_58[0][0]     \n",
      "                                                                 batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 128)  384         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 128)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 768)  295680      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 768)  2304        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 35, 35, 768)  0           batch_normalization_64[0][0]     \n",
      "                                                                 Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm2_2 (Activation)            (None, 35, 35, 768)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 35, 35, 96)   73824       Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 64)   192         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 35, 35, 96)   288         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 64)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 96)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 96)   43104       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 128)  61568       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 96)   288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 35, 35, 128)  384         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 128)  384         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 128)  384         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 96)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 768)  0           Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 128)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 128)  86144       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 35, 35, 128)  98432       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 128)  82048       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 128)  16512       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 128)  384         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 35, 35, 128)  384         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 128)  384         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 128)  384         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 128)  384         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 768)  0           Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 35, 35, 128)  0           batch_normalization_75[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 35, 35, 128)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35, 35, 896)  0           activation_54[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 128)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 128)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 128)  884864      Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  1032320     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 17, 17, 128)  0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 128)  384         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 17, 17, 128)  0           max_pooling2d_7[0][0]            \n",
      "                                                                 batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 128)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 17, 17, 128)  0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce2 (Concatenate)           (None, 17, 17, 384)  0           activation_58[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 1152) 443520      Reduce2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 32)   221216      Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 1152) 3456        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 32)   96          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 1152) 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 32)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 96)   3168        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 96)   288         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 96)   288         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 96)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 96)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 144)  124560      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 144)  124560      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 144)  432         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 144)  432         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 144)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 144)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 96)   288         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 192)  221376      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  249024      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  6336        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  249024      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 96)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 192)  166080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 192)  576         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 17, 17, 576)  0           activation_65[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 1152) 664704      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 1152) 3456        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 17, 17, 1152) 0           batch_normalization_91[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm3_1 (Activation)            (None, 17, 17, 1152) 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 96)   110688      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 96)   288         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 96)   288         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 96)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 96)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 144)  124560      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 144)  124560      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 144)  432         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 144)  432         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 96)   110688      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 144)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 144)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 96)   288         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  221376      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  249024      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  221376      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  249024      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 96)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 192)  166080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 17, 17, 576)  0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 1152) 664704      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 1152) 3456        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 17, 17, 1152) 0           batch_normalization_102[0][0]    \n",
      "                                                                 Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm3_2 (Activation)            (None, 17, 17, 1152) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 64)   73792       Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 96)   110688      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 96)   43104       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 128)  61568       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 128)  147584      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  147584      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 96)   288         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 128)  384         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 128)  384         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 96)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 1152) 0           Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 128)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  86144       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  147584      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 128)  82048       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 128)  147584      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 128)  16512       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 128)  384         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 128)  384         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 17, 17, 1152) 0           Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 17, 17, 128)  0           batch_normalization_104[0][0]    \n",
      "                                                                 batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 17, 17, 1280) 0           activation_83[0][0]              \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 128)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 128)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 128)    1327232     Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 128)    1474688     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 128)    147584      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 128)    0           activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 128)    384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 128)    384         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 128)    384         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 128)    0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 128)    0           batch_normalization_115[0][0]    \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 128)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 128)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 8, 8, 128)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce3 (Concatenate)           (None, 8, 8, 384)    0           activation_87[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 1536)   591360      Reduce3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 32)     331808      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 1536)   4608        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 32)     96          conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 1536)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 32)     0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 128)    4224        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 128)    384         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 128)    384         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 128)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 128)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 192)    221376      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 192)    221376      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 128)    384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 256)    393472      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 256)    442624      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 256)    8448        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 256)    442624      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 128)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 256)    768         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 256)    768         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 256)    768         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 256)    768         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 256)    295168      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 256)    0           batch_normalization_119[0][0]    \n",
      "                                                                 batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 256)    0           batch_normalization_123[0][0]    \n",
      "                                                                 batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 256)    768         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 256)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 256)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 768)    0           activation_94[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 1536)   1181184     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 1536)   4608        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 1536)   0           batch_normalization_129[0][0]    \n",
      "                                                                 activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm4_1 (Activation)            (None, 8, 8, 1536)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 128)    196736      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 128)    384         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 128)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 192)    221376      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 192)    221376      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 192)    576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 128)    196736      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 128)    384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 256)    393472      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 256)    442624      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 256)    393472      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 256)    442624      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 128)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 256)    768         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 256)    768         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 256)    768         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 256)    768         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 256)    295168      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 256)    0           batch_normalization_130[0][0]    \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 256)    0           batch_normalization_134[0][0]    \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 256)    768         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 256)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 256)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 256)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 768)    0           activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 1536)   1181184     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 8, 8, 1536)   4608        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 1536)   0           batch_normalization_140[0][0]    \n",
      "                                                                 Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm4_2 (Activation)            (None, 8, 8, 1536)   0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "GLBL_Pool (GlobalAveragePooling (None, 1536)         0           Norm4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536)         0           GLBL_Pool[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 5)            7685        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,905,765\n",
      "Trainable params: 25,851,877\n",
      "Non-trainable params: 53,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(nn, to_file=\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "nn = Model1(size=(299, 299, 3), n_classes=5)\n",
    "    \n",
    "initial_lrate = .02\n",
    "def decay(epoch, steps=100):\n",
    "    init_rate = .02\n",
    "    drop = .95\n",
    "    epochs_drop = 4\n",
    "    lrate = init_rate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "RMS = SGD(lr=initial_lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=[\"categorical_crossentropy\"], optimizer=RMS, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'samplewise_center':1, 'samplewise_std_normalization':1}, {'featurewise_center':1, 'featurewise_std_normalization':1}, {'rescale':1./255.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 975 images belonging to 5 classes.\n",
      "Found 235 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "gen1 = image.ImageDataGenerator(zoom_range=.15, vertical_flip=True, horizontal_flip=True, brightness_range=[.15, 1], rotation_range=30, **params[0])\n",
    "gen2 = image.ImageDataGenerator(**params[0])\n",
    "    \n",
    "train = gen1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/SelfCutData/\", batch_size=15, target_size=(299, 299), shuffle=1)\n",
    "test = gen2.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/Test/\", batch_size=10, target_size=(299, 299), shuffle=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-7741a395d5c1>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 65 steps, validate for 24 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "65/65 [==============================] - 86s 1s/step - loss: 2.9125 - accuracy: 0.3262 - val_loss: 35.1871 - val_accuracy: 0.2128\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 2.2735 - accuracy: 0.4605 - val_loss: 1.7303 - val_accuracy: 0.2213\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 2.0568 - accuracy: 0.5405 - val_loss: 2.5904 - val_accuracy: 0.3106\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 1.8037 - accuracy: 0.5487 - val_loss: 3.2058 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 1.3111 - accuracy: 0.6482 - val_loss: 1.3263 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 1.2743 - accuracy: 0.6974 - val_loss: 2.1240 - val_accuracy: 0.4255\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 64s 980ms/step - loss: 1.4315 - accuracy: 0.6687 - val_loss: 321.3631 - val_accuracy: 0.2553\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 1.0225 - accuracy: 0.7303 - val_loss: 139.6288 - val_accuracy: 0.2340\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 1.3046 - accuracy: 0.7087 - val_loss: 4.4989 - val_accuracy: 0.4340\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 1.1018 - accuracy: 0.7538 - val_loss: 0.7732 - val_accuracy: 0.7362\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 1.0319 - accuracy: 0.7651 - val_loss: 1.4313 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.7755 - accuracy: 0.8205 - val_loss: 1.5414 - val_accuracy: 0.6383\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 63s 975ms/step - loss: 0.7603 - accuracy: 0.8010 - val_loss: 1.5306 - val_accuracy: 0.5957\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 0.5600 - accuracy: 0.8400 - val_loss: 1.2746 - val_accuracy: 0.6936\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.6497 - accuracy: 0.8513 - val_loss: 0.9326 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 65s 996ms/step - loss: 0.6475 - accuracy: 0.8462 - val_loss: 0.7290 - val_accuracy: 0.7787\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 0.5402 - accuracy: 0.8451 - val_loss: 1.4063 - val_accuracy: 0.7021\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.4634 - accuracy: 0.8687 - val_loss: 1.1395 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.4370 - accuracy: 0.8749 - val_loss: 1.3844 - val_accuracy: 0.7234\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.3956 - accuracy: 0.8933 - val_loss: 1.0288 - val_accuracy: 0.7787\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.3392 - accuracy: 0.9118 - val_loss: 1.1511 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.2732 - accuracy: 0.9210 - val_loss: 0.6635 - val_accuracy: 0.8340\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.3108 - accuracy: 0.9128 - val_loss: 0.4959 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 65s 999ms/step - loss: 0.2367 - accuracy: 0.9364 - val_loss: 0.4730 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.2431 - accuracy: 0.9118 - val_loss: 0.7400 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 0.2692 - accuracy: 0.9354 - val_loss: 0.9185 - val_accuracy: 0.7745\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.2782 - accuracy: 0.9323 - val_loss: 0.3942 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 0.2877 - accuracy: 0.9210 - val_loss: 0.6130 - val_accuracy: 0.8340\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.1347 - accuracy: 0.9651 - val_loss: 1.0589 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.1523 - accuracy: 0.9610 - val_loss: 0.6347 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 65s 995ms/step - loss: 0.2769 - accuracy: 0.9405 - val_loss: 0.5003 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.1555 - accuracy: 0.9518 - val_loss: 0.5579 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.4209 - accuracy: 0.9026 - val_loss: 1.0228 - val_accuracy: 0.7362\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 65s 993ms/step - loss: 0.2883 - accuracy: 0.9282 - val_loss: 0.3522 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 65s 993ms/step - loss: 0.2039 - accuracy: 0.9354 - val_loss: 0.4202 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 65s 995ms/step - loss: 0.1422 - accuracy: 0.9672 - val_loss: 0.2960 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.1988 - accuracy: 0.9467 - val_loss: 1.0685 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.1526 - accuracy: 0.9528 - val_loss: 0.8704 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.1284 - accuracy: 0.9610 - val_loss: 1.4755 - val_accuracy: 0.7191\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.1076 - accuracy: 0.9641 - val_loss: 0.2607 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0572 - accuracy: 0.9846 - val_loss: 0.7345 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0435 - accuracy: 0.9836 - val_loss: 0.9660 - val_accuracy: 0.7787\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0686 - accuracy: 0.9764 - val_loss: 0.5517 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.1048 - accuracy: 0.9631 - val_loss: 0.2756 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.4462 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.4465 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 64s 980ms/step - loss: 0.0444 - accuracy: 0.9826 - val_loss: 0.2474 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0354 - accuracy: 0.9877 - val_loss: 0.4245 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.0216 - accuracy: 0.9918 - val_loss: 0.7021 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.0710 - accuracy: 0.9795 - val_loss: 0.4226 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 65s 994ms/step - loss: 0.0598 - accuracy: 0.9846 - val_loss: 0.4610 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 65s 995ms/step - loss: 0.0237 - accuracy: 0.9877 - val_loss: 0.5677 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 64s 989ms/step - loss: 0.0386 - accuracy: 0.9928 - val_loss: 0.4154 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0242 - accuracy: 0.9897 - val_loss: 0.4889 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0429 - accuracy: 0.9918 - val_loss: 0.6726 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.5431 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.5275 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 63s 975ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.5937 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.5079 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.4322 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0150 - accuracy: 0.9938 - val_loss: 0.4197 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.4027 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.4973 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.3797 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.6189 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 63s 975ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.2779 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0143 - accuracy: 0.9990 - val_loss: 0.3685 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.3374 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 63s 975ms/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.4201 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0125 - accuracy: 0.9928 - val_loss: 0.4657 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.6749 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.7262 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0086 - accuracy: 0.9959 - val_loss: 0.4214 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.3275 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.3170 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.6575 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.2045 - val_accuracy: 0.9617\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.3057 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.2483 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.5673 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.4532 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3739 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.3910 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.4042 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.4817 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.3713 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.4897 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 63s 973ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.4595 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.3782 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.005547791462436676.\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 63s 974ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.3503 - val_accuracy: 0.9234\n"
     ]
    }
   ],
   "source": [
    "scheduler = LearningRateScheduler(decay, verbose=True)\n",
    "hist = nn.fit_generator(train, validation_data=test, epochs=100, verbose=1, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "Test = gen1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/TestMod//\", target_size=(299, 299), shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-8eb8ecd5c02f>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "14/14 [==============================] - 4s 308ms/step - loss: 0.2111 - accuracy: 0.9478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2111310316227091, 0.9477612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate_generator(Test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: Unrecognized location 'lower rigth'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'], label='accuracy (testing data)')\n",
    "plt.plot(hist.history['val_accuracy'], label='accuracy (validation data)')\n",
    "plt.title('Accuracy/epoch plot')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"lower rigth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save_weights(\"first_iter100ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
