{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten, Activation, BatchNormalization, Add, AveragePooling2D, Input, ZeroPadding2D, concatenate, GlobalAveragePooling2D, Lambda\n",
    "from keras.initializers import glorot_uniform, Constant\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, num_filters, filter_size, strides=1, padding=\"same\", activation=\"relu\", name=None, kernel_initializer=None, bias_initializer=None):\n",
    "    X = Conv2D(num_filters, filter_size, strides=strides, padding=padding, \n",
    "               kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, name=name)(X)\n",
    "    X = BatchNormalization(axis=3, scale=False)(X)\n",
    "    if activation:\n",
    "        X = Activation(activation)(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(input_layer, kernel_init, bias_init, name=None):\n",
    "    X = conv2d(input_layer, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "    X = conv2d(X, 32, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "\n",
    "    X = conv2d(X, 192, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "               bias_initializer=bias_init)\n",
    "    \n",
    "#     X1 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "#     X2 = conv2d(X, 96, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "#     X1 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X1 = conv2d(X1, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X2 = conv2d(X2, 64, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X2, 64, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "\n",
    "#     X2 = conv2d(X2, 96, (3, 3), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3)\n",
    "    \n",
    "#     X1 = conv2d(X, 192, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init,\n",
    "#                bias_initializer=bias_init)\n",
    "    \n",
    "#     X2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X)\n",
    "    \n",
    "#     X = concatenate([X1, X2], axis=3, name=name)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normal1(X, X_prev, kernel_init=None, bias_init=None, name=None, scale=1):\n",
    "    X_short = X\n",
    "    \n",
    "    \n",
    "    X1 = conv2d(X, 64*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 48*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 64*scale, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X_add_1 = Add()([X1, X2])\n",
    "    X_add_1 = Activation(\"relu\")(X_add_1)\n",
    "    \n",
    "    \n",
    "    X3 = conv2d(X_prev, 64*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = conv2d(X_prev, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X4 = conv2d(X4, 48*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X4 = conv2d(X4, 64*scale, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X_add_2 = Add()([X3, X4])\n",
    "    X_add_2 = Activation(\"relu\")(X_add_2)\n",
    "    \n",
    "    X5 = conv2d(X, 32*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 64*scale, (3, 3), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_conc = concatenate([X_add_1, X_add_2, X5], axis=3)\n",
    "    \n",
    "    X_conc = conv2d(X_conc, 384*scale, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_fin = Add()([X_conc, X_short])\n",
    "    X_fin = Activation(\"relu\", name=name)(X_fin)\n",
    "    \n",
    "    return X_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduction1(X, X_prev, kernel_init=None, bias_init=None, name=None, scale=1):\n",
    "    X1 = conv2d(X, 128, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X1 = conv2d(X1, 128, (3, 3), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X2 = conv2d(X_prev, 128, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X2 = conv2d(X2, 128, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X3 = conv2d(X_prev, 64, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X3 = conv2d(X3, 96, (1, 7), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X3 = conv2d(X3, 128, (7, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X4 = MaxPool2D((3, 3), strides=1, padding=\"same\")(X)\n",
    "    \n",
    "    \n",
    "    X5 = conv2d(X, 96, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 128, (1, 5), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X5 = conv2d(X5, 128, (5, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    X6 = MaxPool2D((3, 3), strides=1, padding=\"same\")(X_prev)\n",
    "    X6 = conv2d(X6, 128, (1, 1), strides=1, padding=\"same\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X7 = conv2d(X, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_add_1 = Add()([X1, X2])\n",
    "    X_add_1 = Activation(\"relu\")(X_add_1)\n",
    "    \n",
    "    \n",
    "    X8 = MaxPool2D((3, 3), strides=2, padding=\"valid\")(X_add_1)\n",
    "    \n",
    "    X_add_1_2 = Add()([X8, X7])\n",
    "    X_add_1_2 = Activation(\"relu\")(X_add_1_2)\n",
    "    \n",
    "    \n",
    "    X_conc_1 = concatenate([X3, X4], axis=3)\n",
    "    \n",
    "    \n",
    "    X_add_2_1 = Add()([X6, X5])\n",
    "    X_add_2_1 = Activation(\"relu\")(X_add_2_1)\n",
    "    \n",
    "    \n",
    "    X9 = conv2d(X_conc_1, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X10 = conv2d(X_add_2_1, 128, (3, 3), strides=2, padding=\"valid\", activation=None, kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X_add_2_2 = Add()([X9, X10])\n",
    "    X_add_2_2 = Activation(\"relu\")(X_add_2_2)\n",
    "    \n",
    "    \n",
    "    X11 = MaxPool2D((3, 3), strides=2, padding=\"valid\")(X_add_2_1)\n",
    "    \n",
    "    \n",
    "    X_fin = concatenate([X_add_1_2, X_add_2_2, X11], axis=3, name=name)\n",
    "    X_fin = conv2d(X_fin, 384*scale, (1, 1), strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    return X_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model1(size=(299, 299, 3), n_classes=5, name=None):\n",
    "    input_layer = Input(shape=size)\n",
    "    kernel_init = glorot_uniform()\n",
    "    bias_init = None\n",
    "    \n",
    "    X0 = Stem(input_layer, kernel_init, bias_init, name=\"Stem\")\n",
    "    X_mem = X0\n",
    "    X_mem = conv2d(X_mem, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    X_0_1 = conv2d(X0, 192, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init) \n",
    "    X_0_2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"valid\")(X0)\n",
    "    X0 = concatenate([X_0_1, X_0_2], axis=3, name=\"stem\")\n",
    "    \n",
    "    \n",
    "    X1_1 = Normal1(X0, X_mem, name=\"Norm1_1\")\n",
    "    X1_2 = Normal1(X1_1, X0, name=\"Norm1_2\")\n",
    "#     X1_3 = Normal1(X1_2, X1_1, name=\"Norm1_3\")\n",
    "#     X1_4 = Normal1(X1_3, X1_2, name=\"Norm1_4\")\n",
    "#     X1_5 = Normal1(X1_4, X1_3, name=\"Norm1_5\")\n",
    "    \n",
    "    \n",
    "    X2 = Reduction1(X1_2, X1_1, name=\"Reduce1\", scale=2)\n",
    "    \n",
    "    X_mem2 = X1_2\n",
    "    X_mem2 = conv2d(X_mem2, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X2_1 = Normal1(X2, X_mem2, name=\"Norm2_1\", scale=2)\n",
    "    X2_2 = Normal1(X2_1, X2, name=\"Norm2_2\", scale=2)\n",
    "#     X2_3 = Normal1(X2_2, X2_1, name=\"Norm2_3\", scale=2)\n",
    "#     X2_4 = Normal1(X2_3, X2_2, name=\"Norm2_4\", scale=2)\n",
    "#     X2_5 = Normal1(X2_4, X2_3, name=\"Norm2_5\", scale=2)\n",
    "#     X2_6 = Normal1(X2_5, X2_4, name=\"Norm2_6\", scale=2)\n",
    "#     X2_7 = Normal1(X2_6, X2_5, name=\"Norm2_7\", scale=2)\n",
    "\n",
    "\n",
    "    X3 = Reduction1(X2_2, X2_1, name=\"Reduce2\", scale=3)\n",
    "    \n",
    "    X_mem3 = X2_2\n",
    "    X_mem3 = conv2d(X_mem3, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "    \n",
    "    \n",
    "    X3_1 = Normal1(X3, X_mem3, name=\"Norm3_1\", scale=3)\n",
    "    X3_2 = Normal1(X3_1, X3, name=\"Norm3_2\", scale=3)\n",
    "#     X3_3 = Normal1(X3_2, X3_1, name=\"Norm3_3\", scale=3)\n",
    "\n",
    "\n",
    "    X4 = Reduction1(X3_2, X3_1, name=\"Reduce3\", scale=4)\n",
    "    \n",
    "    X_mem4 = X3_2\n",
    "    X_mem4 = conv2d(X_mem4, 32, (3, 3), strides=2, padding=\"valid\", activation=\"relu\", kernel_initializer=kernel_init, bias_initializer=bias_init)\n",
    "\n",
    "    \n",
    "    X4_1 = Normal1(X4, X_mem4, name=\"Norm4_1\", scale=4)\n",
    "    X4_2 = Normal1(X4_1, X4, name=\"Norm4_2\", scale=4)\n",
    "    \n",
    "    \n",
    "    X_fin = GlobalAveragePooling2D(name=\"GLBL_Pool\")(X4_2)\n",
    "    X_fin = Dropout(.8)(X_fin)\n",
    "    X_fin = Dense(n_classes, activation=\"softmax\", name=\"final_out\")(X_fin)\n",
    "    \n",
    "    model = Model(input_layer, X_fin, name=\"V1.0\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "nn = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"V1.0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 145, 145, 192 55488       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 145, 145, 192 576         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 145, 145, 192 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 72, 72, 192)  331968      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 72, 72, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 72, 72, 32)   55328       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 72, 72, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 72, 72, 192)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 72, 72, 32)   96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stem (Concatenate)              (None, 72, 72, 384)  0           activation_4[0][0]               \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 72, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 72, 72, 32)   1056        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 72, 72, 32)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 72, 72, 32)   96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 72, 72, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 72, 72, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 72, 72, 48)   13872       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 72, 72, 48)   13872       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 72, 72, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 72, 72, 48)   144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 72, 72, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 72, 72, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 72, 72, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 72, 72, 64)   24640       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 72, 72, 64)   27712       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 72, 72, 64)   2112        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 64)   27712       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 72, 72, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 72, 72, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 72, 72, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 72, 72, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 72, 72, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 72, 72, 64)   18496       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 72, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 72, 72, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 72, 72, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 72, 72, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 72, 72, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 72, 72, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 72, 72, 192)  0           activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 72, 72, 384)  74112       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 72, 72, 384)  1152        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 72, 72, 384)  0           batch_normalization_15[0][0]     \n",
      "                                                                 stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Norm1_1 (Activation)            (None, 72, 72, 384)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 72, 72, 32)   12320       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 72, 72, 32)   12320       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 72, 72, 32)   96          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 72, 72, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 72, 72, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 72, 72, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 72, 72, 48)   13872       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 72, 72, 48)   13872       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 72, 72, 48)   144         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 72, 72, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 72, 72, 32)   12320       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 72, 72, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 72, 72, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 72, 72, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 72, 72, 64)   24640       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 72, 72, 64)   27712       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 72, 72, 64)   24640       stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 72, 72, 64)   27712       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 72, 72, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 72, 72, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 72, 72, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 72, 72, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 72, 72, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 72, 72, 64)   18496       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 72, 72, 64)   0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 72, 72, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 72, 72, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 72, 72, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 72, 72, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 72, 72, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72, 72, 192)  0           activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 72, 72, 384)  74112       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 72, 72, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 72, 72, 384)  0           batch_normalization_26[0][0]     \n",
      "                                                                 Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm1_2 (Activation)            (None, 72, 72, 384)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 72, 72, 64)   24640       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 72, 72, 96)   36960       Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 72, 72, 64)   192         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 72, 72, 96)   288         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 72, 72, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 72, 72, 96)   43104       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 72, 72, 128)  61568       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 72, 72, 128)  49280       Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 72, 72, 128)  49280       Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 72, 72, 96)   288         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 72, 72, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 72, 72, 128)  384         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 72, 72, 128)  384         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 96)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 72, 72, 384)  0           Norm1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 72, 72, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 72, 72, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 72, 72, 128)  86144       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 72, 72, 128)  49280       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 72, 72, 128)  82048       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 72, 72, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 72, 72, 128)  16512       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 72, 72, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 72, 72, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 72, 72, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 72, 72, 128)  384         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 72, 72, 128)  384         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 72, 72, 384)  0           Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 72, 72, 128)  0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 72, 72, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 72, 72, 512)  0           activation_25[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 72, 72, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 72, 72, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 128)  442496      Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 128)  589952      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 128)  147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 128)  0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 128)  384         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 128)  384         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 35, 35, 128)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 35, 35, 128)  0           batch_normalization_39[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 128)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce1 (Concatenate)           (None, 35, 35, 384)  0           activation_29[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 768)  295680      Reduce1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   110624      Norm1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 768)  2304        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 768)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 64)   2112        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 64)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 96)   55392       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 96)   55392       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 96)   288         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 96)   288         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 96)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 96)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 64)   192         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 128)  98432       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 128)  110720      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 128)  4224        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 128)  110720      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 64)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 128)  384         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 128)  384         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 128)  384         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 128)  384         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 128)  73856       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 35, 35, 128)  0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 35, 35, 128)  0           batch_normalization_47[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 128)  384         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 128)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 384)  0           activation_36[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 768)  295680      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 768)  2304        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 35, 35, 768)  0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm2_1 (Activation)            (None, 35, 35, 768)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   49216       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 64)   192         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 96)   55392       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 96)   55392       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 96)   288         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 96)   288         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 96)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 96)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 64)   192         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 128)  110720      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 128)  98432       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 128)  110720      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 128)  384         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 128)  384         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 128)  384         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 128)  384         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 128)  73856       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 35, 35, 128)  0           batch_normalization_54[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 35, 35, 128)  0           batch_normalization_58[0][0]     \n",
      "                                                                 batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 128)  384         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 128)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 768)  295680      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 768)  2304        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 35, 35, 768)  0           batch_normalization_64[0][0]     \n",
      "                                                                 Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm2_2 (Activation)            (None, 35, 35, 768)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 64)   49216       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 35, 35, 96)   73824       Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 64)   192         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 35, 35, 96)   288         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 64)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 96)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 96)   43104       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 128)  61568       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 128)  98432       Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 96)   288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 35, 35, 128)  384         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 128)  384         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 128)  384         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 96)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 768)  0           Norm2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 128)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 128)  86144       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 35, 35, 128)  98432       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 128)  82048       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 128)  16512       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 128)  384         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 35, 35, 128)  384         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 128)  384         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 128)  384         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 128)  384         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 768)  0           Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 35, 35, 128)  0           batch_normalization_75[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 35, 35, 128)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35, 35, 896)  0           activation_54[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 128)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 128)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 128)  884864      Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  1032320     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 17, 17, 128)  0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 128)  384         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 17, 17, 128)  0           max_pooling2d_7[0][0]            \n",
      "                                                                 batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 128)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 17, 17, 128)  0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce2 (Concatenate)           (None, 17, 17, 384)  0           activation_58[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 1152) 443520      Reduce2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 32)   221216      Norm2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 1152) 3456        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 32)   96          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 1152) 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 32)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 96)   3168        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 96)   288         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 96)   288         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 96)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 96)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 144)  124560      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 144)  124560      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 144)  432         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 144)  432         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 144)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 144)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 96)   288         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 192)  221376      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  249024      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  6336        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  249024      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 96)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 192)  166080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 192)  576         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 17, 17, 576)  0           activation_65[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 1152) 664704      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 1152) 3456        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 17, 17, 1152) 0           batch_normalization_91[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm3_1 (Activation)            (None, 17, 17, 1152) 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 96)   110688      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 96)   110688      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 96)   288         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 96)   288         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 96)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 96)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 144)  124560      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 144)  124560      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 144)  432         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 144)  432         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 96)   110688      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 144)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 144)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 96)   288         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  221376      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  249024      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  221376      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  249024      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 96)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 192)  166080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 17, 17, 576)  0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 1152) 664704      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 1152) 3456        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 17, 17, 1152) 0           batch_normalization_102[0][0]    \n",
      "                                                                 Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm3_2 (Activation)            (None, 17, 17, 1152) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 64)   73792       Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 96)   110688      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 96)   43104       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 128)  61568       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 128)  147584      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  147584      Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 96)   288         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 128)  384         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 128)  384         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 96)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 1152) 0           Norm3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 128)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  86144       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  147584      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 128)  82048       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 128)  147584      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 128)  16512       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 128)  384         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 128)  384         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 17, 17, 1152) 0           Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 17, 17, 128)  0           batch_normalization_104[0][0]    \n",
      "                                                                 batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 17, 17, 1280) 0           activation_83[0][0]              \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 128)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 128)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 128)    1327232     Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 128)    1474688     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 128)    147584      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 128)    0           activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 128)    384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 128)    384         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 128)    384         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 128)    0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 128)    0           batch_normalization_115[0][0]    \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 128)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 128)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 8, 8, 128)    0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Reduce3 (Concatenate)           (None, 8, 8, 384)    0           activation_87[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 1536)   591360      Reduce3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 32)     331808      Norm3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 1536)   4608        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 32)     96          conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 1536)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 32)     0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 128)    4224        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 128)    384         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 128)    384         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 128)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 128)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 192)    221376      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 192)    221376      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 128)    384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 256)    393472      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 256)    442624      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 256)    8448        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 256)    442624      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 128)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 256)    768         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 256)    768         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 256)    768         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 256)    768         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 256)    295168      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 256)    0           batch_normalization_119[0][0]    \n",
      "                                                                 batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 256)    0           batch_normalization_123[0][0]    \n",
      "                                                                 batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 256)    768         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 256)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 256)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 768)    0           activation_94[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 1536)   1181184     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 1536)   4608        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 1536)   0           batch_normalization_129[0][0]    \n",
      "                                                                 activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Norm4_1 (Activation)            (None, 8, 8, 1536)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 128)    196736      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 128)    196736      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 128)    384         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 128)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 192)    221376      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 192)    221376      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 192)    576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 128)    196736      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 128)    384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 256)    393472      Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 256)    442624      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 256)    393472      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 256)    442624      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 128)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 256)    768         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 256)    768         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 256)    768         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 256)    768         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 256)    295168      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 256)    0           batch_normalization_130[0][0]    \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 256)    0           batch_normalization_134[0][0]    \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 256)    768         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 256)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 256)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 256)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 768)    0           activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 1536)   1181184     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 8, 8, 1536)   4608        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 1536)   0           batch_normalization_140[0][0]    \n",
      "                                                                 Norm4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Norm4_2 (Activation)            (None, 8, 8, 1536)   0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "GLBL_Pool (GlobalAveragePooling (None, 1536)         0           Norm4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536)         0           GLBL_Pool[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 5)            7685        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,905,765\n",
      "Trainable params: 25,851,877\n",
      "Non-trainable params: 53,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(nn, to_file=\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = Model1(size=(299, 299, 3), n_classes=5)\n",
    "    \n",
    "initial_lrate = .02\n",
    "def decay(epoch, steps=100):\n",
    "    init_rate = .02\n",
    "    drop = .95\n",
    "    epochs_drop = 4\n",
    "    lrate = init_rate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "RMS = SGD(lr=initial_lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint(\"Weights_epochs_BEST.h5\", save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=[\"categorical_crossentropy\"], optimizer=RMS, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'samplewise_center':1, 'samplewise_std_normalization':1}, {'featurewise_center':1, 'featurewise_std_normalization':1}, {'rescale':1./255.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 975 images belonging to 5 classes.\n",
      "Found 235 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "gen1 = image.ImageDataGenerator(zoom_range=.15, vertical_flip=True, horizontal_flip=True, brightness_range=[.15, 1], rotation_range=30, **params[0])\n",
    "gen2 = image.ImageDataGenerator(**params[0])\n",
    "    \n",
    "train = gen1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/SelfCutData/\", batch_size=15, target_size=(299, 299), shuffle=1)\n",
    "test = gen2.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/Test/\", batch_size=10, target_size=(299, 299), shuffle=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 65 steps, validate for 24 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 1/150\n",
      "65/65 [==============================] - 76s 1s/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 1.6421 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 2/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.4101 - accuracy: 0.9262 - val_loss: 0.2535 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.02.\n",
      "Epoch 3/150\n",
      "65/65 [==============================] - 65s 999ms/step - loss: 0.1803 - accuracy: 0.9518 - val_loss: 1.0805 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 4/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.1323 - accuracy: 0.9569 - val_loss: 1.1250 - val_accuracy: 0.7532\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 5/150\n",
      "65/65 [==============================] - 65s 999ms/step - loss: 0.0880 - accuracy: 0.9672 - val_loss: 0.3694 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 6/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.1132 - accuracy: 0.9621 - val_loss: 0.5303 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.019.\n",
      "Epoch 7/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0620 - accuracy: 0.9774 - val_loss: 0.3907 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 8/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.1239 - accuracy: 0.9692 - val_loss: 0.4505 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 9/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0426 - accuracy: 0.9908 - val_loss: 0.4221 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 10/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0533 - accuracy: 0.9805 - val_loss: 1.2581 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.01805.\n",
      "Epoch 11/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0691 - accuracy: 0.9785 - val_loss: 1.5356 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 12/150\n",
      "65/65 [==============================] - 65s 1000ms/step - loss: 0.1115 - accuracy: 0.9662 - val_loss: 1.0457 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 13/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.8495 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 14/150\n",
      "65/65 [==============================] - 65s 1000ms/step - loss: 0.0167 - accuracy: 0.9938 - val_loss: 0.6290 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0171475.\n",
      "Epoch 15/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.7336 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 16/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 1.4085 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 17/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.1603 - accuracy: 0.9641 - val_loss: 1.3743 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 18/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0648 - accuracy: 0.9826 - val_loss: 0.6051 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.016290125.\n",
      "Epoch 19/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0357 - accuracy: 0.9856 - val_loss: 0.4090 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 20/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.6306 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 21/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.4022 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 22/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.5293 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.015475618749999996.\n",
      "Epoch 23/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.5855 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 24/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.4359 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 25/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 26/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.4696 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.014701837812499997.\n",
      "Epoch 27/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.5028 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 28/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0441 - accuracy: 0.9908 - val_loss: 0.3763 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 29/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.3756 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 30/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.5443 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.013966745921874996.\n",
      "Epoch 31/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.4826 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 32/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.5841 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 33/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5063 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 34/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.013268408625781245.\n",
      "Epoch 35/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 36/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.7083 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 66s 1s/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.7377 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 38/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.012604988194492182.\n",
      "Epoch 39/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 9.3311e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 40/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 41/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.3361 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 42/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.3627 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.011974738784767574.\n",
      "Epoch 43/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.8297 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 44/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 45/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.5144 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 46/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.6397 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.011376001845529194.\n",
      "Epoch 47/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 48/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0062 - accuracy: 0.9969 - val_loss: 1.4065 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 49/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.1306 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 50/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.7851 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.010807201753252733.\n",
      "Epoch 51/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 9.8176e-04 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 52/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 53/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 54/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.010266841665590096.\n",
      "Epoch 55/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 56/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.3874 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 57/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 58/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.009753499582310591.\n",
      "Epoch 59/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 60/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.6041 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 61/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 62/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.6645 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00926582460319506.\n",
      "Epoch 63/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.6968 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 64/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.7141 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 65/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.5438 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 66/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.4669 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.008802533373035307.\n",
      "Epoch 67/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.5611 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 68/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.2569e-04 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 69/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 6.0869e-04 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 70/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 1.2966 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.008362406704383542.\n",
      "Epoch 71/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.9381 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 72/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.8976 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 73/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 66s 1s/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.6615 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 74/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.6675 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.007944286369164364.\n",
      "Epoch 75/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 7.8455e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 76/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.1737e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 77/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.5562 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 78/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.2840e-04 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.007547072050706145.\n",
      "Epoch 79/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 9.0170e-04 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 80/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 3.3004e-04 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 81/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 2.5538e-04 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 82/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.4839 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0071697184481708375.\n",
      "Epoch 83/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.6653e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 84/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.9614e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 85/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.6245 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 86/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.5239 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.006811232525762296.\n",
      "Epoch 87/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 88/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 6.2708e-04 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 89/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.4440e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 90/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 7.9028e-04 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.0064706708994741804.\n",
      "Epoch 91/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0014 - accuracy: 0.9990 - val_loss: 0.5618 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 92/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 93/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 9.6337e-04 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 94/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.3020e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.006147137354500472.\n",
      "Epoch 95/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.3771e-04 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 96/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.3893e-04 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 97/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 5.5061e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 98/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.9840e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.005839780486775448.\n",
      "Epoch 99/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.4974 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.005547791462436676.\n",
      "Epoch 100/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 8.5515e-04 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.005547791462436676.\n",
      "Epoch 101/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.4618e-04 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.005547791462436676.\n",
      "Epoch 102/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.005547791462436676.\n",
      "Epoch 103/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 7.4369e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.005270401889314841.\n",
      "Epoch 104/150\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.4423 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.005270401889314841.\n",
      "Epoch 105/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.0547e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.005270401889314841.\n",
      "Epoch 106/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.4410 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.005270401889314841.\n",
      "Epoch 107/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.6818e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.005006881794849098.\n",
      "Epoch 108/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.6712e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.005006881794849098.\n",
      "Epoch 109/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 65s 1s/step - loss: 8.2547e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.005006881794849098.\n",
      "Epoch 110/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.7422e-04 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.005006881794849098.\n",
      "Epoch 111/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.8625e-04 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.004756537705106643.\n",
      "Epoch 112/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.4187e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.004756537705106643.\n",
      "Epoch 113/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.2531e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.004756537705106643.\n",
      "Epoch 114/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 0.4406 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.004756537705106643.\n",
      "Epoch 115/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.1803e-04 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.004518710819851311.\n",
      "Epoch 116/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 7.3351e-04 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.004518710819851311.\n",
      "Epoch 117/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 8.9993e-04 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.004518710819851311.\n",
      "Epoch 118/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 7.5036e-04 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.004518710819851311.\n",
      "Epoch 119/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.6215e-04 - accuracy: 1.0000 - val_loss: 0.5200 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0042927752788587455.\n",
      "Epoch 120/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.5557 - val_accuracy: 0.9021\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0042927752788587455.\n",
      "Epoch 121/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.5463 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.0042927752788587455.\n",
      "Epoch 122/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.5091 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.0042927752788587455.\n",
      "Epoch 123/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.5483 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0040781365149158075.\n",
      "Epoch 124/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.2164e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.0040781365149158075.\n",
      "Epoch 125/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.3085e-04 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0040781365149158075.\n",
      "Epoch 126/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 7.5098e-04 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.0040781365149158075.\n",
      "Epoch 127/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 6.7915e-04 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.0038742296891700174.\n",
      "Epoch 128/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.7395e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.0038742296891700174.\n",
      "Epoch 129/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.8427e-04 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.0038742296891700174.\n",
      "Epoch 130/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 7.6883e-04 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.0038742296891700174.\n",
      "Epoch 131/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.2331e-04 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.0036805182047115166.\n",
      "Epoch 132/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.4160e-04 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.0036805182047115166.\n",
      "Epoch 133/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.5256 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0036805182047115166.\n",
      "Epoch 134/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.9982e-04 - accuracy: 1.0000 - val_loss: 0.5250 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.0036805182047115166.\n",
      "Epoch 135/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.4277e-04 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0034964922944759405.\n",
      "Epoch 136/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 6.8222e-04 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0034964922944759405.\n",
      "Epoch 137/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.3762e-04 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0034964922944759405.\n",
      "Epoch 138/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.0034964922944759405.\n",
      "Epoch 139/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.8601e-04 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0033216676797521434.\n",
      "Epoch 140/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.4478e-04 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.0033216676797521434.\n",
      "Epoch 141/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 1.6929e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.0033216676797521434.\n",
      "Epoch 142/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 3.7370e-04 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0033216676797521434.\n",
      "Epoch 143/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.7492e-04 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.003155584295764536.\n",
      "Epoch 144/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.2619e-04 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.003155584295764536.\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.003155584295764536.\n",
      "Epoch 146/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.0376e-04 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.003155584295764536.\n",
      "Epoch 147/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 4.7293e-04 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.002997805080976309.\n",
      "Epoch 148/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.6687e-04 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.002997805080976309.\n",
      "Epoch 149/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 5.3756e-04 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.002997805080976309.\n",
      "Epoch 150/150\n",
      "65/65 [==============================] - 65s 1s/step - loss: 2.4393e-04 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9106\n"
     ]
    }
   ],
   "source": [
    "scheduler = LearningRateScheduler(decay, verbose=True)\n",
    "hist1 = nn.fit_generator(train, validation_data=test, epochs=150, verbose=1, callbacks=[scheduler, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "Test = gen1.flow_from_directory(\"/home/alex/CourseWork_2020/SelfCutData/TestMod//\", target_size=(299, 299), shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-8eb8ecd5c02f>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "14/14 [==============================] - 4s 308ms/step - loss: 0.2111 - accuracy: 0.9478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2111310316227091, 0.9477612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate_generator(Test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/tf36/lib/python3.7/site-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: Unrecognized location 'lower rigth'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'], label='accuracy (testing data)')\n",
    "plt.plot(hist.history['val_accuracy'], label='accuracy (validation data)')\n",
    "plt.title('Accuracy/epoch plot')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"lower rigth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save_weights(\"first_iter150ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXyU1b3/3yeTfSMhhLCHfV8iILggonWrW9Fa0bpWxYtWaq3Lba2tW29df9feuqF1b11wwVoVtVpAUFEEZEcWWQMBQiD7Nsv5/XGeZ+aZyTNbMpME5rxfr7wmmXmWM8nkfM53PUJKiUaj0WgSl6SOHoBGo9FoOhYtBBqNRpPgaCHQaDSaBEcLgUaj0SQ4Wgg0Go0mwdFCoNFoNAlO3IRACJEuhFgmhFgthFgvhLjX5phpQogqIcQq4+uP8RqPRqPRaOxJjuO1m4BTpZS1QogU4AshxEdSyq8DjlsipTw3juPQaDQaTQjiJgRSVarVGj+mGF+6ek2j0Wg6GfG0CBBCOIAVwGDgSSnlNzaHHS+EWA3sBW6TUq63uc71wPUAWVlZE4YPH972wR3cDMIBBYPCH+ush/JN0HUgpHdRz1XthoYq6DG67WMJh5RQtgpye0FTDUgPdBsa//tqNJqjhhUrVhyUUhbavSbao8WEECIPeBeYLaVcZ3k+F/AY7qOzgf+TUg4Jda2JEyfK5cuXt31Qz58BKRlw5Xvhj937HTw7DS55HYafrZ778FZY/y7csa3tYwmHswH+pwecdg9sWwTN9XDdp/G/r0ajOWoQQqyQUk60e61dsoaklJXAIuCsgOerpZS1xvfzgRQhRLf2GBMiSa2sI8EUSyFad35bMe8jktSX9rBpNJoYEs+soULDEkAIkQGcBnwfcEwPIdTsKoSYZIynIl5j8h9gkm+CD4t5XCcQAkT73Vej0SQE8YwR9AReNuIEScCbUsoPhBCzAKSUc4CLgBuEEC6gAbhEtlc71KgsAvOcQCFop5V5oEWgO8ZqNJoYEs+soTXAMTbPz7F8/wTwRLzGEBIhwBPpyroTWQRCWwSJhtPppLS0lMbGxo4eiuYIID09nT59+pCSkhLxOXHNGurUiCTwuKM8R/h/325CYMYodIwgESktLSUnJ4f+/fsjrJ9BjSYAKSUVFRWUlpYyYMCAiM9L3BYTwhF9sNjvfB0j0LQPjY2NFBQUaBHQhEUIQUFBQdTWYwILQTQTeWdxDQnjvu1zW03nQYuAJlJa81nRQhAJXtdMK89vKzpGoNFo4ogWgojoLBaBIQTaJNC0M9nZ2XG79l/+8hdeeeUVAF566SX27t3bqussWrSIr776yvvznDlzvNeNJYsWLeLcc0O3R1u1ahXz588Pe621a9dy9dVXx2hkrSfBhSDCCTVUQVl7pHLqGIHmKMXlcvHCCy/w85//HIitEMyaNYsrr7wyJuOMlkiFYMyYMZSWlrJr1652GFVwElgIoplQ7SwCh/FSOwuBriPQdCBSSm6//XZGjx7NmDFjmDt3LgBlZWVMnTqVkpISRo8ezZIlS3C73Vx99dXeYx977LEW11uwYAHjx48nOTmZt99+m+XLl3PZZZdRUlJCQ0MDK1as4OSTT2bChAmceeaZlJWVAfDXv/6VkSNHMnbsWC655BJ27NjBnDlzeOyxxygpKWHJkiXcc889PProowBMmzaN//7v/2bSpEkMHTqUJUuWAFBfX8/FF1/M2LFjmTFjBpMnT8auhc3HH3/M8OHDmTJlCvPmzfM+v2zZMk444QSOOeYYTjjhBDZt2kRzczN//OMfmTt3LiUlJcydO9f2OJPzzjuPN954I3Z/pFaQ2Omjsi3po4aGSg9x11MdI9AY3Pv+ejbsrY7pNUf2yuXu80ZFdOy8efNYtWoVq1ev5uDBgxx77LFMnTqV1157jTPPPJPf//73uN1u6uvrWbVqFXv27GHdOtVerLKyssX1vvzySyZMmADARRddxBNPPMGjjz7KxIkTcTqdzJ49m/fee4/CwkLmzp3L73//e1544QUefPBBtm/fTlpaGpWVleTl5TFr1iyys7O57bbbAPjPf/7jdy+Xy8WyZcuYP38+9957L5999hlPPfUU+fn5rFmzhnXr1lFSUtJijI2NjcycOZMFCxYwePBgZsyY4X1t+PDhLF68mOTkZD777DPuvPNO3nnnHe677z6WL1/OE0+oMqnq6mrb4wAmTpzIgw8+yB133BHR3yAeJK4QJLU1fdQQhfaYlHWvIU0n4YsvvuDSSy/F4XBQVFTEySefzLfffsuxxx7LNddcg9PpZPr06ZSUlDBw4EC2bdvG7NmzOeecczjjjDNaXK+srIwRI0bY3mvTpk2sW7eO008/HQC3203Pnj0BGDt2LJdddhnTp09n+vTpEY39wgsvBGDChAns2LHD+35uvvlmAEaPHs3YsWNbnPf9998zYMAAhgxR/TAvv/xynn32WQCqqqq46qqr2LJlC0IInE6n7b1DHde9e/dWu8NiReIKQSyCxdBOQmApKNMxgoQm0pV7vAjWAWbq1KksXryYDz/8kCuuuILbb7+dK6+8ktWrV/PJJ5/w5JNP8uabb/LCCy/4nZeRkRE0511KyahRo1i6dGmL1z788EMWL17Mv/71L+6//37Wr2/Rvb4FaWlpADgcDlwuV8j3E0iwlMw//OEPnHLKKbz77rvs2LGDadOmRX1cY2MjGRkZEY0jXiRwjCAG3UehAywCoWMEmg5j6tSpzJ07F7fbTXl5OYsXL2bSpEns3LmT7t27M3PmTK699lpWrlzJwYMH8Xg8/PSnP+X+++9n5cqVLa43YsQItm7d6v05JyeHmpoaAIYNG0Z5eblXCJxOJ+vXr8fj8bB7925OOeUUHn74YSorK6mtrfU7N1KmTJnCm2++CcCGDRtYu3Zti2OGDx/O9u3b+eGHHwB4/fXXva9VVVXRu3dvQAW67d5HqOMANm/ezOjR7bCvSQi0EERER1sEAQVl2jWk6SAuuOACxo4dy7hx4zj11FN5+OGH6dGjB4sWLaKkpIRjjjmGd955h5tvvpk9e/Ywbdo0SkpKuPrqq3nggQdaXO/HP/4xixcv9v589dVXM2vWLEpKSnC73bz99tv893//N+PGjaOkpISvvvoKt9vN5ZdfzpgxYzjmmGO45ZZbyMvL47zzzuPdd9/1Bosj4cYbb6S8vJyxY8fy0EMPMXbsWLp06eJ3THp6Os8++yznnHMOU6ZMobi42PvaHXfcwe9+9ztOPPFE3G5fzPGUU05hw4YN3mBxsOMAFi5cyDnnnBPReOOGlPKI+powYYKMCfP+S8rHRkd27A+LpLw7V8rtS3zPffm4eq6hKjbjCcX+Depe6+ZJ+c71kY9bc1SwYcOGjh5CXJk+fbrcvHlzh9zb5XLJhoYGKaWUW7dulcXFxbKpqand7t/Y2CgnT54snU5nTK9r95kBlssg82qCxwiiXVl3tEVgpo/G/5YaTXvx4IMPUlZW5g3Gtif19fWccsopOJ1OpJQ8/fTTpKamttv9d+3axYMPPkhycsdOxQksBCKK7qNBms5BB8UIdLBYc/QwbNgwhg0b1iH3zsnJsa0baC+GDBnSIQIYSALHCFqRPmobLG7vgjLdYkKj0cSWBBaCtgaLO6COAIFOH9VoNLFGC0EkhLQIoqxObg2BG9Po9FGNRhNDtBBEhI1FkGT2GmrngjIdI9BoNDFGC0EkBNu8HnSLCY1Gc8ST4EJwpKWP6hiBpmNor/0IouXqq6/m7bffBuC6665jw4YNLY556aWXuOmmm0Jep732MrCONxiRtuK+7bbbWLBgQUzGlcDpo9F0H+1M6aM6RqA5ejD3I7BrPxEtzz33XKvPXbRoEdnZ2ZxwwgmA2sugo3jppZcYPXo0vXr1Cnnc7NmzmTlzJqeeemqb7xk3IRBCpAOLgTTjPm9LKe8OOEYA/wecDdQDV0sp2/6JiISkI7nXkLYIEpaPfgv7WvbDaRM9xsCPH4zoUCkld9xxBx999BFCCO666y5mzJhBWVkZM2bMoLq6GpfLxdNPP80JJ5zAtddey/LlyxFCcM0113DLLbf4Xc+6H8HGjRu56qqrWLZsGQA7duzg/PPPZ82aNdx33328//77NDQ0cMIJJ/DMM8+0aAQ3bdo0bwvrF198kQceeICePXsydOhQb8O5999/nz/96U80NzdTUFDAq6++SkNDA3PmzMHhcPCPf/yDxx9/nP/85z/eltarVq1i1qxZ1NfXM2jQIF544QXy8/OZNm0akydPZuHChVRWVvL8889z0kkntfh9zZ49mwULFjBgwAC/Jnd27+mdd97x7smQkZHB0qVLeeSRR2zfe3FxMRUVFezbt48ePXpE/We3Ek/XUBNwqpRyHFACnCWEOC7gmB8DQ4yv64Gn4zgef2LWa6gDNqbRMQJNB2Hdj+Czzz7j9ttvp6yszLsfgflaSUmJ334Ea9eu5Re/+EWL61n3IxgxYgTNzc1s27YNgLlz53LxxRcDcNNNN/Htt9+ybt06Ghoa+OCDD4KOsaysjLvvvpsvv/ySTz/91M9dNGXKFL7++mu+++47LrnkEh5++GH69+/PrFmzuOWWW1i1alWLyfzKK6/koYceYs2aNYwZM4Z7773X+5q5x8Ff/vIXv+dN3n33XTZt2sTatWv529/+5ud+sntPF110ERMnTuTVV19l1apVZGRkhHzv48eP58svvwz5N4uEuFkERm+LWuPHFOMrcAb7CfCKcezXQog8IURPKWVZvMblJRab10P7WwTo7qMJTYQr93gR7/0ILr74Yt58801++9vfMnfuXO8OaAsXLuThhx+mvr6eQ4cOMWrUKM477zzbMX7zzTdMmzaNwsJCAGbMmMHmzZsBKC0t9Vowzc3NDBgwIOT7raqqorKykpNPPhmAq666ip/97Gfe1+32OLCyePFi7++rV69efm6cSN9TqONitZdBXIPFQgiHEGIVcAD4VEr5TcAhvYHdlp9LjecCr3O9EGK5EGJ5eXl5jAZ3BBaU6TbUmg5GBvnsmfsR9O7dmyuuuIJXXnmF/Px8Vq9ezbRp03jyySe57rrrWpwXuB/BjBkzePPNN9m8eTNCCIYMGUJjYyM33ngjb7/9NmvXrmXmzJlB9zAwCbZ/wOzZs7nppptYu3YtzzzzTNjrhMNuj4NIxhLpewp3XKz2MoirEEgp3VLKEqAPMEkIEdh02+6v1eKTJqV8Vko5UUo50VT5NhOVEJjndIYYgXYNaTqOeO9HMGjQIBwOB/fff793S0hz4uvWrRu1tbVhs24mT57MokWLqKiowOl08tZbb3lfs+4L8PLLL3ufD7aXQZcuXcjPz/e2tf773//utQ4iYerUqbzxxhu43W7KyspYuHBh2PdkHUu49x6rvQzaJWtISlkphFgEnAWss7xUCvS1/NwHaJ8921rjGgo8Hzpgh7J2uqdGY8MFF1zA0qVLGTduHEII734EL7/8Mo888ggpKSlkZ2fzyiuvsGfPHn7xi1/g8ajPa7D9CK644gq/52bMmMHtt9/O9u3bAcjLy2PmzJmMGTOG/v37c+yxx4YcY8+ePbnnnns4/vjj6dmzJ+PHj/fuAXDPPffws5/9jN69e3Pcccd573Heeedx0UUX8d577/H444/7Xe/ll1/2BosHDhzIiy++GNXva8GCBYwZM4ahQ4d6RSTUezL3ZDCDxcGOczqdbN26lYkTJ0Y8nqAE60/d1i+gEMgzvs8AlgDnBhxzDvARyjI4DlgW7rox249g4QOqx7/bHf7YjR+oY/d853tuw7/Uc2VrYjOeUGz6RN1r93IpP7lLyvuL4n9PTadB70egsWPevHnyrrvusn0t2v0I4uka6gksFEKsAb5FxQg+EELMEkKYSbrzgW3AVuBvwI1xHI8/IooWEaHSRyNuZd0G/HYo0+mjmqMLcz8CTXS4XC5uvfXWmFwrnllDa4BjbJ6fY/leAr+M1xhCElWw1y5Y3J69hnSMINGRUgYNgB7pdOR+BEcy1uwlK7IVySSJ3WIC2m4RtHcdgW4xkXCkp6dTUVHRqn9wTWIhpaSiooL09PSozkvsFhPQBotAt5jQtA99+vShtLSUmKVOa45q0tPT6dOnT1TnaCGIZiIXnaWOQFsEiURKSkrYwieNpi1o11A0rqHWnt9WdIxAo9HEES0EEXUg7USuIXMM2j2k0WhiROIKgXeHsQgm1A7vPhqwVaX1OY1Go2kjiSsER2SwWLRvbEKj0SQECSwEUUyoHW4R2AiBjhNoNJoYkcBC0JqJvKOFwBoj0BaBRqOJDVoIWjuhtquv3hoj0MFijUYTW7QQWIWgcjc0HG55rJ1rKCmarKM20iJ9FLRrSKPRxAotBNamca/+DBa2bJXbeYLF2jWk0WhiTwILgU3TuIZDUF/R8thOEyzW6aMajSb2JLAQ2EzkHhe4m20O7kyVxdoi0Gg0sUULgXVl7XaB29ny2A63CGwKynSMQKPRxIgEFgKblbXHCe6mUCdZvtUxAo1Gc3SQwEIQzDVkYxF0GteQ0DECjUYTc7QQWCdyt9M+RtCZNqbRdQQajSbGaCEw6wA8bkCCy8411InSR3WMQKPRxJjEFYKkgPRRj0s9Rhws7qCNaQKf02g0mjaSuEIQuKI3BSBk+mgnsgi0a0ij0cQILQRei8AUghBZQ52ioExnDWk0mtgSNyEQQvQVQiwUQmwUQqwXQtxsc8w0IUSVEGKV8fXHeI2n5QADVtbuCFxDfucbriWP7jWk0WiObOK5eb0LuFVKuVIIkQOsEEJ8KqXcEHDcEinluXEchz2BK2szRtApg8WWgjJdR6DRaGJM3CwCKWWZlHKl8X0NsBHoHa/7RU1g0zmva6gzVhbr9FGNRhM/2iVGIIToDxwDfGPz8vFCiNVCiI+EEKOCnH+9EGK5EGJ5eXl5jAZ1JAaLhXYNaTSamBN3IRBCZAPvAL+WUlYHvLwSKJZSjgMeB/5pdw0p5bNSyolSyomFhYUxGlhg+qhhGbibWq62O0NBmVcAtGtIo9HElrgKgRAiBSUCr0op5wW+LqWsllLWGt/PB1KEEN3iOSbf4IJkDYEvXuDFziJo5zoCc7w6fVSj0cSYeGYNCeB5YKOU8n+DHNPDOA4hxCRjPDYbAsRjgEFcQxDEPUTHxgi8QqAtAo1GE1vimTV0InAFsFYIscp47k6gH4CUcg5wEXCDEMIFNACXSNlOS90WFoElDdTVBKlZvp9t00c7SggSt/RDo9HEh7gJgZTyC/x8KbbHPAE8Ea8xhCTQxWJ1Ddl2IIWODRab99YWgUajiS2Ju7wMbDrn5xoKqCXo8PRRaeMa0jECjUYTGxJYCIIUlIGNRdDR6aN2QqAtAo1GExsSVwiCdR+FlsHiDrcI7GIE2iLQaDSxIXGFIFTWkG2biQAChSSeSI9FhLRFoNFoYosWgqhcQyHOjye6jkCj0cQRLQR2BWURuYY6qqBMWwQajSa2aCHwuoasFkGga8gmWGxeQ8cINBrNEY4WAk8EriE7i8C8RnsLgY4RaDSaGKOFwM411CJY3JksAl1HoNFoYosWgkh6DXW4RSC1a0ij0cQNLQR2vYYiaTFhXqPDXENaCDQaTWzQQmCbNRTMNWRzjXbbj0D47glaCDQaTczQQmDba6iDgsX1h+yf94sRWJ7TaDSaGJC4QuBIVY/mpO/nGgrcjyBYsFjEbkKu3guPDoEdX7R8TaePajSaOJLAQpCiHs1JP1TWUHtYBLX7VQrr4R0tX9PpoxqNJo4krhAkp6lHUwjcTryTbCTdR0Hte2y1JNqCyxhHU03L13SLCY1GE0cSVwhM15A5AXtcShyEI7KtKiG2FoF5z6balq/pFhMajSaOxHOrys5NksN/0ve4IClFTbjBNqYJJKZCYNyzqbrlazpGoNFo4kjiCgEoq8CcgN1Oo7V0UhSuoVgKgXHPZjuLQOoYgUajiRtaCLxZQy4jgCxsgsXGo61rKEYrc/OeQWMEuo5Ao9HEh8QWguRU3wTscVpcQx1hEUQaLNYWgUajiS2JLQRWi8DtgqRk5R6KuNdQDOsIwgaLAywCHSPQaDQxIm5ZQ0KIvkKIhUKIjUKI9UKIm22OEUKIvwohtgoh1gghxsdrPLY4Uv2DxY5klTnUEfsRuCIMFuteQxqNJsbE0yJwAbdKKVcKIXKAFUKIT6WUGyzH/BgYYnxNBp42HtsHa7DYdA05UoI3nYtr+qhxz4hdQ1oINBpNbIibRSClLJNSrjS+rwE2Ar0DDvsJ8IpUfA3kCSF6xmtMLUi2cQ1ZrQST9kwftcsaQrYUAu0a0mg0MaJdCsqEEP2BY4BvAl7qDey2/FxKS7GIHw5rsNhwDTnSgm9ME0+LINLKYp0+qtFoYkzchUAIkQ28A/xaShnoABc2p7RY6gohrhdCLBdCLC8vL4/d4Bxp/r2GgrmGglkESY7YB4tdjfb31y0mNBpNnIirEAghUlAi8KqUcp7NIaVAX8vPfYC9gQdJKZ+VUk6UUk4sLCyM3QAdKf69hpJCBYttNCseriFoaRXo9FGNRhNH4pk1JIDngY1Syv8Ncti/gCuN7KHjgCopZVm8xtSCZKtF4FbCYE0pNZGypVsIYpw+armnrRDo9FGNRhMf4pk1dCJwBbBWCLHKeO5OoB+AlHIOMB84G9gK1AO/iON4WuJItTSdcyphsFoJXtrBIrDGJQIDxjpGoNFo4kjchEBK+QX2MQDrMRL4ZbzGEBZrhpDbaVgEdsHiIMSjshjCuIZ0jECj0cSWxG1DDQF1BG4jfTRIsNjWNdQRQqAtAo1GE1sSWwisdQQeZ/A6gvZ2DUViEegYgUajiRERCYEQYpAQIs34fpoQ4ldCiLz4Dq0dsNYRmK4hawDZpF0sAiekG7/SUEKgW0xoNJoYE6lF8A7gFkIMRmUCDQBei9uo2ovANtRe11AHWATuJsjqpr4PFSzWMQKNRhNjIhUCj5TSBVwA/EVKeQvQfq0g4oVfjMDYocwMFlsn2pAWQYwmZHczZHRV37ewCGxaTOgYgUajiRGRCoFTCHEpcBXwgfFcSnyG1I6Y8QApDdeQESNA+m9K31gJ6V1anh/rFhMp6ZCSFaaOQPca0mg0sSVSIfgFcDzwP1LK7UKIAcA/4jesdiLZ2MDe4/J3DYG/e6hqD+TatECKaUFZk7JG0nLshcDrmtIWgUajiS0R1REYraN/BSCEyAdypJQPxnNg7YLDEAJXk881lJymnnM3AZnq++o9UDC45fnCATLCmoNwuJ1qPGnZLYWgqVYJBOg21BqNJuZEmjW0SAiRK4ToCqwGXhRCBGsbceTgMCf9ZotryLQILLUE1XuhS5+W54skfxdSW3A1KQvFziJoOAwZ+b57Ato1pNFoYkWkrqEuRufQC4EXpZQTgNPiN6x2wuoG8lj2IzCfA2isVruG2bqGYlxQ5kiF1Gz/rCFXEzjrIMPM1tWuIY1GE1siFYJkY8OYi/EFi498TDeQq8nShtryHCi3EECXdhKCtFx/i6ChUj0GWgTaNaTRaGJEpEJwH/AJ8IOU8lshxEBgS/yG1U54YwSNxs8pLV1DVYYQxNsicDUpYUrL8d+3uOGwevQKgbYINBpNbIk0WPwW8Jbl523AT+M1qHbDFILmOvWY5LAEiw3XUHWpegwqBLGqI7AGiy2uoRZCoGMEGo0mtkQaLO4jhHhXCHFACLFfCPGOEMImenqEYQqBs149JqW0jBFU71WTb45N/VzM00dtgsWNAa4hHSPQaDQxJlLX0IuoTWR6ofYUft947sgmOcAi8HMNGUJQtQeye6iMokBi5RqS0hIjyFHxCjNGYVoEZh8iHSPQaDQxJlIhKJRSviildBlfLwEx3DOyg2jhGkq2CRaX2geKIXZCYMYjklMh1agXMK2CoDECLQQajSY2RCoEB4UQlwshHMbX5UBFPAfWLpiTvtc1ZE0ftQSLc3vZnx8zIWjyjccsHDMDxg2H1X3Scn33BHSMQKPRxIpIheAaVOroPqAMuIj23lYyHphuoOZ6389W15CUKn00N0g4JNYWgRksBl/AuOGwcgslBfypdIxAo9HEiIiEQEq5S0p5vpSyUErZXUo5HVVcdmTjDRZbXEPWFhONlcpaiLdryHRDmZXF4O8a8gaK0TECjUYTc9qyQ9lvYjaKjsKc9JutriFLHUGoGgJQ6aYxsQiMwLQjEiHQWUMajSa2tEUIQm5Mf0TgdQ1Zs4YsdQTequJ4u4ZMIUjzBYubLa4hO4tAxwg0Gk2MaIsQHPkzUahgsasJqsxismDB4hjVEXiFIMU+WGwVAl1HoNFoYkxIIRBC1Aghqm2+alA1BaHOfcEoQFsX5PVpQogqIcQq4+uPbXgfrcO2oMziGqreo8Qhu8j+/JjHCNJ8k37dQfUY1DV05OuwRqPpHIRsMSGlzGnDtV8CngBeCXHMEinluW24R9toUVAWECyuKlUVxUkO+/MjEYKafWrSzg2xs6c1RpCSrmISh7apFteN1UGCxdoi0Gg0saEtrqGQSCkXA4fidf2YYFtQZqkj2LcOCocHPz8SIXj/Zpg3M/QxViEA6DoQKn6AxipA2ruGjgLPnEaj6RzETQgi5HghxGohxEdCiFHtfnc711CSQ+081lgF5d9Dr5Lg50ciBLUH4MDG0Me4DCEwrZGuA+HQDy2ris17gnYNaTSamNGRQrASKJZSjgMeB/4Z7EAhxPVCiOVCiOXl5eWxG4EQavK3FpSBEoi934F0Q882CkFzHdQfbLnrmBVrsBigYBDUV8DhHepnHSPQaDRxpMOEQEpZLaWsNb6fD6QIIboFOfZZKeVEKeXEwsIYtzhKTrMUlBmxAEcq7Fmpvu85Lvi5kQoB+CZ1O6wtJkBZBOAbg04f1Wg0caTDhEAI0UMItbwVQkwyxtL+/YscFosgyViRJ6eCqwEyC4LXEEBk+xGY9QCHtgc/poVraJB63LNcPer0UY1GE0ci2pimNQghXgemAd2EEKXA3UAKgJRyDqpf0Q1CCBfQAFwiZQf4Oxxp/gVl4Isd9CzxuWLsiMQiMOMPh0MIQaBrKL+/etyzQj0eKa6hVa/Dhn/Cz+d29Eg0Gk0UxE0IpJSXhnn9CVR6acfiSGjGHg4AACAASURBVAXnAfV9kvHrMCfkUIFiCC8ErmbfJB/KIgh0DaVmqhRSs7I5vYvlnp3YIihdBps/9m27qdFojgg6Omuo40lO9U2qXiEwJrFQ8QEILwRm7AHCWARm99EU33NmnCCtS8tNcUQSnTJG4DT2fq7d37Hj0Gg0UaGFwHQDgb1rKBQiSRV9BcOMPUCYGIGlstjEFIKMLi2PJ4ZbZMYS0w1WXdax49BoNFGhhcC6CjctguRU5ZfP6xf63HAWgRl7yB+gqpTNlX8ggQVloFJIISBQbL1vJ7QIXIZFUKOFQKM5ktBC4LCswk0h6NIHBk4LHSiGCITAyBjqMVrVJFTusj/O3QwI3/3BYhHYCUFntQga1KMWAo3miCJhhKDJ5ebzzeW0SEyycw399AW48G/hL2r66oOtzk1XSdFo9RgsTmAGV63C0zWMRdApYwSGEFTv7dhxaDSaqEgYIXhv1V6uemEZ6/dW+7+QbBECb7A42d9lFIxw7R5M15ApBMHiBG6nvyCBL4XUTgg6a4zAZVoE+zp2HBqNJioSRgjOGFlEcpLgw7UBbgvrBJwUweRvJVwnUNM1VDAIktODVxe7m1oKQWomTLkFRk63ua/onDEC7RrSaI5IEkYI8jJTOX5QAR+tLfN3D/kJQZB208EIl9NvZg2lZqsVfjAhcDW3FAKA0+6BgSfb3LcNweLK3aoRXjxw6mCxRnMkkjBCAHD2mJ7sqKhnY5mlAZw5ASclhw8OBxLWIjBcQ6lZKnMoqGuo2d9FFf7GtCpGICW8cj58/Nvoz40E0zVUXdY5LRaNRmNLQgnBGSOLSBLw0TrLitXM3Y/WLQSRu4ZSsyCvL1SX2h/nbvLPXorkvq2ZaPetURve1MeppZOzQbXwdtaF7raq0Wg6FQklBAXZaRw3sIAPre4hbxFZPISgzrfZTU5PtceBtcjMxC5YHPK+Ie4Zio0fqEfThRNLpFRCYNZeaPeQRnPEkFBCAMo9tK28js37jdW6uRKPNj5gPSfYpOysV9aAEEoIwH6CdDVF5xpqbfroxvd944o1riZA+uofdAqpRnPEkHBCcOaoHggB883sIdMSiJdrKCVLfZ8bQgjcQYLFwW8cvUVwcAuUb1TnuuJgEZjxAVMI4pVCWn8Inj8jdMsOjUYTFQknBIU5aUzq39UnBGaMIF6uoVRDCEyLwK4PT7RC0JoYgWkN9J8SH9eQeU2vEMTJIijfBLu/gbJV8bm+RpOAJJwQgHIPbTlQy5b9Nf5ZQwa1TS7qm13hLxRWCOpbCkEw11BUQtAKi2DDe9BrPBQM9q3eY4npbsrsqtpmx8siMIPQzXWhj9NoNBGTkEJw1ugeAHy0bp+tENz02kpue2t1+AuFrSOwWATpuaqewNY15Iyuf3+0MYKt/1Er6HGXQEqmr/ArlpjuppQMJXrxihE0GZXhdkF3jUbTKhJSCIpy05lYnK/cQ6YQWFxDa0ur2FYewYozkhiBKQQAOT3sJ0i7yuLQN47cIvB44NO7Ia8YJlwNKenxEQLzmsmGEMTLIjBTcp3aItBoYkVCCgEo99D3+2o42GCsrI1gcXWjk4q6ZirqmsNfJJwQOOsDhCDIBBnPGMHaN2H/WvjRH5XVkZyhOqEGa4ndWkwhSMmA3F7xSx/1uoa0RaDRxIqEFYLTRxYBsLnCmPCNVNCdB9UEc7iuuWWn0kCiCRaDIQQ2FoErysriSHsNeTyw4E9qg51RF6rnUjLUY6xTSK1CkNNDCZ65aY+zERY/Ehu/vikE8UiB1SQOzfWw9m1dAW+QsELQJz+DnPRkymqNycpwDW2vUJOVyyOpbggTMI4mfRRUCmnNPvXhK1sDb1ymAsXRuoYijRE0VUHVbhh7MSQZY01JV4/BMofqD8Gih5SIRIMZgE5OVwFp6Yby79Vzmz5UgrRtUXTXtEMHizWxYMN78M61cGBDR4+kU5CwQiCEYFBhNntqzP2KlRDsOOibYA7WNYW5iPHra66HOVNg+2L/15ttXEPuZjXZrpkL338ABzYalcXRbPYeYYygyfCnp+X4nks2LIJgmUMb34dFf4aDm6MYDz5hScmAAVPV9z8s9H9sOBzdNe3QFoEmFtQaLtpgjSATjIQVAoDB3bMprTZW/YZryCoEh8LFCUwhOLwD9q1V+e0mrmbwOFsKASj3kHlsxdZWVBZjb9KWb4IH+vqKrbxN77J9x3gtgiBCYPYhinbFbU7MKRlqh7eCIcoCkNJnCbRGCMo3wYe3+txM2iLQxILacvUYbNfABCOhhWBQYTbl5nxocQ11yVDfV9RGKATVe9Sj+eEC/4ZzJrm91OPhHbDXKIg6uFkJRtTBYhuLYN9alV556IeAMViFIFM9hhWCKJvGWdNHAQadAju/VBZP1W7j2oeiuybA5o/h2+d8QXZtEWhiQZ0WAitxEwIhxAtCiANCiHVBXhdCiL8KIbYKIdYIIcbHayzBGNw9GydG/YDhGtpZUc+EYrUrWEWkriEzJbTOKgSWFtQmOap+gU0fq8kfYP969Rht+qhdjMDcZ8C7ajZdQxYhSDYsgmBtJuoOGue20iIwXU8Dp6nnFj+sfk5Kbp1F0GjUDZjnaotAEwvM/9XDOzt2HJ2EeFoELwFnhXj9x8AQ4+t64Ok4jsWWQYVZNEtTCJKpanByqK6Z8f3yADgUsUVgIwTmxGgVgmxDCL43uoD2HNc6IQiWPlpnCkGt/6N1DN6soTAWgXlupDgbAeErjOs/RbWkXv8udOmn9mNojRA0BQiBKW46fVTTFswFj7YIgDgKgZRyMRDKF/AT4BWp+BrIE0L0jNd47OjXNRPpLShL9sYHhhTlkJOeHL6WwCsExj4DdTauIWvWUHIqZHaDxko1MRaf6NvQPqrK4iDBYtMi8E6WdjGCcEJgWgRRCoGrQV3brLZO7wJ9JqrvB01TrSdiaRHogjJNW9CuIT86MkbQG9ht+bnUeK4FQojrhRDLhRDLy8vL7Q5pFcmOJLrlGZNkUgo7jNTRAd2yKMhKjUIIInQNga8Lad/JKs3SJJqmd8HSR1u4hoxHqxB4s4aCuYbMGEG0FkGDz+1kMnCa8XgKZOS30iIw3oNXCI7gFhMej85b7wx4PGrBk5KpUqxjkc12hNORQmC3L6Ttf4mU8lkp5UQp5cTCwsKYDqJnfq76JimZ7QfrEEJZCl2zUjkUbYyg/hC4jSykZhvXEECOETDuOwm6DfE9H4v00dr96jHQj57WHllDjb5AtMm4S2HkdBhyOmS00iKwuoakjCxY/MNC2PpZ9PeKN/Oug9dmdPQoNI2V4HGpQkvQVgEdKwSlQF/Lz32Adt/NpHc3FQ9wi2R2VtTTq0sG6SkOumalRZ415J2UpGUitfHPgy9g3HeSSrE0ibbpnG2MoNz/3k21gPCfoJNDuIacDT6XS2uCxSkBFkHXAXDxy6qOobUWQWOVemw4rMYnPSrw3FwXfHX9+cPwye+jv1ckHNoG3z4f2bG1B4wNe4D9G2DdO7BneXzGpYkc8/+kzwT1qIWgQ4XgX8CVRvbQcUCVlLLd9zfs060LADVO2HKghuICNWl2y47CNQSqqRtYJuMgrqE+x0K3odB9pBKFVKPYKyrXkI1F4PHYuIbqlFtIWIyvlBAFZda9jKPdc9jV6BMZOzLylUC5IujhZMVqEZhjyi4y+iUFuVZTta8+I9aseAk+/A3sXBr6OLcLnj4RXr1Iff/VX9Xz9RXRB+KtLPyzqvw2+X4+fHxn66/Xmdn0MSx6MPbXNf9HexsxLJ05FNf00deBpcAwIUSpEOJaIcQsIcQs45D5wDZgK/A34MZ4jSUU/bqrVNEFmw+xbk81xw0sAKBrVmr4fkNWIeg5Vj2amTt2WUMA46+Am75VBWxCQDcjThDt5vWBNBxWkyP4Jprmmpb39waLbWIEZiYFtMIiaPBd244MZXnRWBnddRuDCEGoMTZVK9O/Ymvk91nxcmQdU83V4xf/G/q4PcvVZ2H7Ynjvl7D2Ld9iobINE8+aubDoAdizQv293rsRvn5SFd61J+veUdZRPFn1D/jqidhf1xSCbkMgLVdbBMQ3a+hSKWVPKWWKlLKPlPJ5KeUcKeUc43UppfyllHKQlHKMlLJDbObi7mqCqm6W3PeTUcw+VU3MXbNSw/cbsk7IPUwhCMi6SQmYiAMx3UNR7ZBmYxGY8QHrvZvr/OMDoAQoKSWIRWAVglYEiwNdQ1Yyuxr3iKKoTMoAi8D43nSvBYsTmIJxYGNk96k7CO//Cla9Gv7YSiO/Ycu/YZ9tiYzvdeFQcZI1b6jnzrhfPbZ2BerxQNUeQKpq63/fpd6rSFIN1GJJqAVQ/SF4+1plnQSy9ztlpcSCyt1qMRPrxADzfzSrO+T100JAglcWA2RmqFXs9An9ufL4/gjDjdItW63QQxaVWV0uXiGwuIaSUsK3jjADxlGnjwb8o5qWSGq2b8Jsqm1pEUDwzWnMSTqre/QWgauhZbDYSoayvKKKEzgb1MoeoKHSJ06hLAJrQDnShmLm+47EIqjaDSPOU7/nL/8S/Lgtn6o40Hl/heHnwgmzoXiKeq21/W3qDqhCxH4nqAl39etwwq+g/0mwLoadNL95Fv4yBmr227++Ywkg1YZHZusPUBbCKz+BD26JzTjMinTzsx0rag8AQi1O8vq1zUI7Skh4ITBdMnlZ/m6NrllqAg8ZJ7BaBIVD1cTvzeWvt5+EA+k2VD2GmkRb3NfOIjAEqOtAi2uozheDsBJscxpzpZRfHH2MwC591EprhMA6BqtryLQI7ITA1egTj0gtAnNM4fZQcDYqy6vHWLXJz7p3YOUrLY+r2Q/71sDg09RC4JJX4bR71MSTmt36iafKaGVy4q9USm7XQTD1dhhzkZqE965s3XWt7FkBn/xOTcLfBKnxNJsrNhyCPcY9m2pVN93GKkOw3PbnRkpznS9mVRtjIagrh8wCZR3nFSuLIMHTerUQJDmg2zD/VE4sQhAqc8gqBDk9IavQv0VDarb9eVaGnwMXPONLZYsEuzoC0zXUdaDFNWQTIwA1YdvVEdRXKHdGbq/QFsHqN3wTgImzMUyMoDVCYFg2Wd3tYwR2riGreJhV2+Ew4xbhLIIqo3CwS181AQ+YCv+arb6sE5+ZujrkDP/zhYD8/q13DZkr5C594bK3YdYXkJqpLBRHKqx9p3XXNWmshrevUZ/lIWeo7Cgza8vK9sUq6UEkKRcYKFdV+fdqLNLjn3jQGszfNfi7PWNBXbn6XwVlETTXJnwtgRYCIeCmZVDyc7+nTddQyA6kRsdS0vPUJJhd6J/CmRrBKt+RovYSTormT2FjEdQdUJNBlz7+WUOBMQIwXEM2k2j9QbVqTcsNHiOQhn/6m2f8n3fWRygEUcQIzEBxfrFKazUnF69ryOY9mOcUDFEr70gydLwWQTghMHzJef1U8Pvyeco1s/IV2PyJ77gt/1btRHqMaXmNvOI2WASmEPUBR7Lv85WRD4NPVxZKW7YhXfqkWh3/9Dk49S4lxN8+539MdZlqlDjyJ0oMtvwbdn2t4iAn3QpjfqaOa+vkXWmpNY25EBxU/6ug/pbgq/BPULQQBCE/y+xAGipGYPz6zPbSWYU+f2bg7mSxxC5GUHtArZzTctSk7HGHiBGkB88ayuymLJlgFkGj4auvC6jwDpc+mparrI2oLAJjNerNtjEmhxzTIrAZo2lF9JusHiPJprEKQagNecz75xnlL0kONWGmZMIPC9RzbidsW6jcQsKmZjK/WFkErXFFVJWqv016l5avTZqpeuy/d1Pr3Rx7lkP3UdDvONUHa/Bp8PXT/lbWjiXqccBUVShYtgrev1kVSk65xSfSbZ28qywB3Hi4hkyLwBTrcOnARzlaCIKQluwgJy1MvyGvEBgffqtryFkfmWuoNdi1oa49ANndfZvQNNcGjxEkZwRxDR1SvtO0bHW+3YRi+qmtGUZShk8fFSL6ojKrRQBqtZqUoqqUwd4iMCetvoYQRBIwNsfkcYa2WKp2KzEzq8NBBfmLT1STP8D2z5U7ZdiP7a+RZ1g31lTdSKkuVdaAncAMOgV+dLcKGn/+cPTXBuVKKxrl+3nqHeoz8fqlPktj++fKAi4a43N9lX+vYiCpWeozCG2fvCt3q8LBjK6xEYKvHodnpiqhtwpBfjEUjlDtzhMYLQQhKMhODe0asrMIag+oibG5NroAcFTYtKE2hcAUn8Zqwz0VzCIIkj6aVaDOkR77Y8y9F6wTmdupahhCpY9C9EJgru7zLEKQlu17T6FiBD3GKMGLJGDcYKltCBUwrtyl4ieOZP/nB52iahYqd8O6d5X1M/g0+2vk9zeu1Qr3UJUhBMGYcotKV130ZzV5H/g+8mvXVaj33mO077l+k+GCObDjC3jj57DmLdW+Y8BJypXZYyzk9obeE3wuoSxTCNpqEexW187tFRsh2P0NlK2G7YvU5yqrm++1YWfBzq8SOk6ghSAEXbNSw6SPmkJgZLFkFar9h5uqof5wHF1DNi0m6kyLINv3MzJEjCBI1lBmgU9M7NxD3pS+ct8YvPsVh7AIoO0WQdUuZfGYAms3PlMI0vOg+/DoLALwpUwe3uGzfkwqd6tAbSCDTlWPWz6B79+HYWcHF0XzvRzeAWveVFucRlptHU4IhFDpqqf+QU3eTx8PWyLsubTfqImwWgSg9rs+/69KAOZdpxYCg0/33e/qD+Hnb/liXGnZ6vMTC4sgr5+xuIpBjMDsB7b0KfVoWgSg/l7SrdJhExQtBCEI22/INNGtFgGo0viqXWrlFA8C00c9bsPc7a5Wo+ALfAbNGgoQAo9bTYhmjADsdykzJ0d3s6UBnHGtUK4hUIHoaArKzOubk29jlXp/3l3WQlgEabnK371/XXifecNhn7vJtAhevRgeHw+LH/FN1FW7ffEBK4XD1Wfg80fUGEdfGPxeZnDy4Gb49I9qV7lg/YekVNfcv179juvKQwsBqHTVqbfBzavVuP51U2Tia2ZYFY1u+dr4K+G2zXDTcpi9Uv1s0nWAsiKtZHePjUXQpa+KOcTCIjCFYOun6tG0XEBZNJndYNNHbb/PEYoWghD07ZrBrkP1eDxBJhJzBWz+c5qZCEseVZOpaS7HmsAWE/WHlDBkF/kmcXNCC1pHYMQIGg7Dwa3GZCGVyZwWwiKotqySzYBxpEKQke/vhglHU7Uav9WMT8tRq8+UzCAWgWFFpGVDrxI1Rmsqoh2NldB9hPq+Zp8Sk4OblDgs+BPMvVz1C6rea28RCKFabtfuU5bIwFOC3ys1Sy0Yvp7j+xttX2J/bE0ZLPwTfPGYbyLLDSMEJpldYfrTahL9+Hfhj9+/Xk2O2d3tX8/urlKsCwbZxyj8jm3j5O12qvee19cnKm3J83c71d+11zG+56wWQZIDhp6pRMIdopPAUYwWghAMK8qhvtnNnsogKXndR8Clc2GosRGb+eE6uFmJQJrNJBwTDIvA1aQ2qjdXX9mFvkk8lEVgTR/9/GF45iTfijCzwHeOXeplVSneDuJmOmfgfsXBsHMNffGYsqDsaKxWv0Mz4wh8QhdUCGpUkWBymlrpgSqSCkXDYTV5ZeSrCciMK5zz/2Dancrls+UT5T4wV/SBmJP/iHPDV5PnFauMqP4nqewcs0ArELOFxZZ/+9Ibw1kEVnqVKOtg9evhW1DsX9fSLdRasovaZhFU71Gfb9MicDfZ1zNESu1+QELJZWrlD/6LC1D/w41VsOur1t/nCEYLQQiGFKmJfNO+IFW2QqhAk1lPYF1lTPxF/AZmpo8uexb+WqLMf1D/NKb4mKtNuxiBtaCscpcSBbNtc2aBz4qwjRGU+orvvBZBwH7FwcjIV+4mt9P33Bd/gRUv2h/fVAXpuer9mimT5vtLDVIL0VTjO6ZotKqtiEQIMvKVe6dmn7+/fPJ/qX5R//6Des7ONQQqlbLXeJh4beh7gS9gPO13Kg2zdJl9zGbfGvXYWOUrFotGCABOug36HQ//vAF2fGl/jNulxK+zCIE1TddMRw1MV44G05rKK1ZuO5Hk/78KMPhH6jMWWB+TIGghCMHQIjWJbtofYbsFc7XRa7xa6cULM0ZwaJua6MwVrLWttdcisAsWG+mjHo8v+2f/WuM9WCyCwBiBx6P+qcwqaK8QmBZBBFlD4LMKXE3KLXMoSDFPY7Uv5mGea07yKVnBLQLzmORUlT209zv1c8UPSvCsVcBSKndVRr76/dWUKesoLddXOHbMZXDoB3V8lyAWQWZXuH4h9B4f+ncAysc+7XfQ/0ToP1XFW8ysliePU+MEJUjZPZSFs+4dQKgsmmhIToVLXlPi88al9nUVh35Qq267ArjWkN1diZddrUokmE3guvS1pKO20cIA9bs79S644t2WC6TULJg8S+0nvj/CHlWtQcpO2c5CC0EIctJT6J2XweZIhSA5VVWann5vfAdmtpioPaD6zfzyG7joRdVewusaMv5xggkBKDGoO6BcFGYANqubRQgCJlqz6Zkpct6aCTNGECZdNlAITD/y4R32hVxN1coisJ4bjUUASpT3fqcm/8WPwtIn/NsnN9Uol49pEdTu9+XTm77wybPwusOiXZHbMfBkmPZb9X3x8crttfU/8O4NUL4RNvxTvbZvrdr3ecBUNVFnF0XXnNAks6tqSSGS4LN7Wr4eLGOotXhX8a2ME5iZabm9YyQEZnyll1r1D5xmf9zkWWqBEa7FeGupPQB/OxXmnAR7V8XnHq1EC0EYhhZls3l/FC2Zz7hf/ePGFcMiqCtXcYH8/r5MleQ0ZSV4g8V2WUNWITioXChTfqMCnZndfBNpYIzAzBgqGKRWzKYQeNNHo7QIzInC3WSfvx/SIsgMXlBmngMqTtBcq9xD699Vz5kTg3UsGXmGRbCvZWFVwSDVEyqvX3irJ1rSctQYlz4JB9ariWrrAiXCFT+oVfowIwbVxXZL78jIL4Zjr1OZMabFYbJvnSre6jas9de34q0ubqUQVO5W10hJb/u1QP29kzN8n6FgZHaFY69R1lfg76itVPwAz5+uiu/qDsBzP/KlsnYCtBCEYWhRDj8cqMXlDtF6oL0x6wjMthKBpGb7Kn9t6wiMyczs8Z/VTQUVf7NBWTVeiyBQCMymZ32UC6mFa6iVFgHYb3LSVBPCIsgK3mLCahGYAeNP7vQJlq0QGBaBdKtrBK6Opz+tcubjwYCT1H3H/Ex1Nd39DexeBkglBEONKuW2WiPHXqcm/G/m+D+/Z4Wqrg0X5I6Utq7iD2/3FRGm5xldfdvoGsrtFT7bCeD42ep/a+1brb9fIG4X/OOnamFz1ftw49fKKvns7ujSqeOIFoIwDC3KodntYUdFPVJKDofbvrI9EFaLwEYIrJO/nWvItAjMiT2rUF3TFIDkNPXPF+ga8vpae6tzTLExXTThVsvezWnM9sKWf267pl9NrbUILEJQMFhdo/Rb9T1ATTAh6OF7PjCfPj03eMZQWxl7ieraedZDMOhHyv1mTtZFo5UlcNwvYfRFbbtPTg/Vsvq7V31pvM5GJTyxrHlpS78hjwfK1vjiFUlJRgppGy2CSGMrOUVKcGO5+9r376vP9/mPK1dfZlfVksPdrIoKOwFaCMIwrIeaVDbvr+GpRT9w3AP/YfehGO+YFC0iSU2+zbUtsx/AN3k60ux3PjNjBGZQzk5MUrN8/Ypema5WqFV71AScka+sCK9rKEKLINuYaKsNN5D5zy0cLQPGrmZ13UCLwBS21KzIYgRJSSqNEmDS9cr1Um1xQ5ktqDPyfeMDtad0e1E4FGb8QxVm9TtO/R43fwxpXXzic9afYeT5bb/XcTcoS2rly+rn0mXq9zzg5LZf2ySrGyBaN3kf2qaSFKw5/7EQgmisqfz+rd88yI6lT6lrWvtP9Rijki6++3unCB5rIQjD4O7ZCAGfbyrniQVbaXJ5+NuSOO/VGhZhqR0I4hqC4C0uvEJgsQgCSctRIrBvrWqo9v7Nqj+O2fQsq5tN+mgYi8D0+Zp9dmr3qwk4r19Li8BbGGakjXotglzfewtWUBZYv1F8oq/AL6eXfzzCtAjS83wWQf4Ae5dae5CcBv2Nncx6jI7MnRENPcepHc6Wv6gmoO2LlRAXnxC7ezhSlOswlEUgpaofCWy+V2YEUU3xhralo3rc6u8dTbZVfnHshKB0uRLbyTf40sxNxl+hAvVmVlsHooUgDOkpDoq7ZjJ3+W7cUnLy0ELmfrubg6HaU8cbIXwTmF2MwJzEgk1m5oRtWgSBxTWgJtqmGji4Rf18YIMKNOYaAcusQuXi8Xh8MYJwQgD+e8TW7lfj7zqgpUVgFhCZk7qta6jOfzXlalLmdqAQTLkFbvpWmeS5Pf2ro63BYtOlEavsmdZi9i6KVTpnIBOuUsK74wvY9rlKeU3PDX9eNISrLt67El6fAa/N8O+1tPc7ZckWDvc9ZzZzbA115WrHuqiEoL/6bMZir+Svn1KLl2Mua/na6IvU/8x3/2j7fdqIFoIIGGoUls08aQB/OHckzW4PL3+1o+MGZG0xkR1kNQ/B22CbLhyvENhcw9yT4OBmlYVUPEUFNE0TO7Ob+gdrrFRB2OT0yDbX8RMCI8aRPyC4RWBOUH0mQp9Jyo0CKn1UutXE7z3H0mfISnKabyLI7eXvGmo4rGImKRkqWDp2hvKjdyRDzlCr9D7Hxuf6I85XltbXT6lAcTyy3ML1G1r+oopD7VmugqYmZauVJWR1aXbpo671ye8j21ca1CTuavaPa0VK/gD12Na9jPetg/X/VMJr12UgIw9GToflL8DzZ6od4TrITaSFIAJOGlrIoMIsbpw2mMHdszl9RBGvLN1JXVNH9SWxuAuCZQ1ZHwNJsVgEKVn2LiQzRnBwiwqy/vghNTkVDDLua4hH3cHw+xVbyeunqpM9bvXPnV2kLILGKv8MCrPzqDmpFwyC6z71WQYpNrUOXndSiNYeOb3Ufc3qZrOYzOTCBuFwggAAGrtJREFUZ2HUBZG9l3hRMAh+tRJGhWhe1xZSM1VX0U3zlZjGMj5gEsqd01ilUjRLLlW5+18/Bd9/aASKV7fctnXS9Wq8Xz8Fj42Cl89Xk2awfZEbq1Tn1Vd+4uszFa1FAG1zD3k88OFv1GQ/5TfBj/vxg6qmpKlGHb9+Xuvv2QbiKgRCiLOEEJuEEFuFEL+1eX2aEKJKCLHK+PpjPMfTWq44rpj/3DqNrDTVh/7K4/tT1eDkm+1t3Je1tVj9xsH8+xA8RmBO2jV77S0K8xrNdVCxRbWU6DEablwKk/7LuK/RcbLeEIJI917I66eyYmr2GXsoFPlWYFarwNtOOojLwtym0RowDncOKNcQ0jdJNRxW/6ydjfz+UW5fGiVmB1FHGvSdFPvr5/RQQdrdy1q+tuZN9XebcDWcfr/KjPrkTtXor6naPz4AyqV34bMwewWcMFt9dj78jdpsxo75t6tJfNdXsMQoDovKIuivHlu7tzTA6tdUNtbp9/uy5ezIyFdCMGuJEsCPf2ffV6nuoGpzEqdW2XH7pAkhHMCTwI+BkcClQgi7VIwlUsoS4+u+eI0nlkwozseRJFixs4M2sjCFID3PPvfbFIJgMQJz0pYeeyEBJSL1h5TvvsDoLVQ4zDcBey2CckMIorAIQLXFcNYpIepqCIE1TtAUYBG0eA+mRWAjBKEsAnNCMN1DgRZBotBzLPQ9TuWzh2sW2BqOvU79rV8+T038LiOm5myAFS+pTW16jVef39PuVRP3h7caYyuxv2bXgSrt8qZlMPxcWPSgf5qnlLDqdVgzF07+rUoSKFulXJuZBfbXtMPck6M1FsGhbaqR4yd3qh5P4y6N7LwkB5z7mFocfXavmvgPbVOW0ie/h7+MVVXxe1ZGP6YISA5/SKuZBGyVUm4DEEK8AfwEiGMjj/YhI9XBqF65HSgEhn4HaxkcqWsIQghBti/fvtvQlq+b51Xuhl1LfTn64TALhUq/VY/ZRb4VmFUITNeQ3f68YLEI6tQk40iNTAjMvSPM99Zw2CdEicYV8/BzM8aSvL5w7Weqv9G8marpXW4vlYIs3WoDHXNBM/hHKga18wtloZgtwUNx9iPwxCR4/9cwajpseA/2fKcaFfaeCFNvV8/PmRJ5MZmJENGlkB7eCZ8/pILvZlyheIra0Ccaq673eLX39LJnYfnzlvEkKXflyb/1xchiTDyFoDew2/JzKTDZ5rjjhRCrgb3AbVLK9YEHCCGuB64H6NcvTkU9UTK+Xz5zv92N0+0hxdHeoRbjQ20XHwCfJRBMCKxdQkNZBCbdbCZ5c4X11eOqD/+FzwYfrhUz2GxuxpLd3djrtodKU03LVpbKTqMdcLBJ3bRqqveqzJPjbvCt9oNZEeDzFZvVxY2VndM11B7Eawc9k6wCVUm7ab4qEju8QxXP9Z6g+v+bCKFW+s+f1jJQHIzcXnDa3TD/NrWPcsEQGPNTZWmMmq62E+0+QgmGXWfXcOT3j6zNxJ6V6vPnrFdblh53g7JWgnWpDcfp96kaFnez+vt0GwZFI+P+t4qnENhJcGBIfCVQLKWsFUKcDfwTGNLiJCmfBZ4FmDhxYsdXX6DcQy99tYPvy2oY0yfIqjVeeC2CYP59S669HclpePc9DmURmBS0+JOof9b0PCUCQ8/y5b6HIyVDWQGlphAYKZs9xqiNQXZaWiVn9wg+KZjjW/SA8vdv+dTXbymURZBZoKyHaotFkJ6gQtAeJKep1Wy4AHzfY2HqHb5khEiYeK36rBeNVHEGu1X/xGuiG69Jfn/lj5fS/rpNtaoob8GfVAbd1R8o12lbScmIbwv7IMRTCEoBqyz2Qa36vUgpqy3fzxdCPCWE6CalDKgy6XxM7K/8yst3HuoAITAtgjCTeLAYgRDqA+esD34N89zsHsGDr1mFypd/2j2RjNpHXj+fa8i0amb8XU3oacb+Aw2Vwd1C4HMN7VtrpCGu8GW/hBICIYx9B8pU/YOzPjFjBJ2RU38f3fFJSTBuRnzGkt9fpUXXHlBtJ0zqKmDZM8p903BYpd5e+Jz/MUcg8RSCb4EhQogBwB7gEuDn1gOEED2A/VJKKYSYhAped1AqTnT07JJBry7prNh5mF+c2L4+5qpGN10ghGsoTB0BqMwhZ31wq8K0JrrZWAMmI3+imphF4tO1YgqBSPIVs6Vk+GIFEH5yNl1DjlQlRJ/cCTuWqPGES2XN7a0sAmt7CY3GijWFtHKXcm8d3KysBFcDDDsHpvw6PhlXHUDchEBK6RJC3AR8AjiAF6SU64UQs4zX5wAXATcIIVxAA3CJlJ2g8UaEjC/OZ2UHBIw376/lWMCTVWif9hUuRgBq4m0gvFURSgh+9Ifwg7XDzBzK7Nay7D5SMvKUkBw7E8ZcrIRg11IlguECg7k9lW/3gJG3EE1GiSYxMIXg6ydV5g6orKUxF8HxN0H34UFPPRKJp0WAlHI+MD/guTmW758AnojnGOLJhOJ8PlhTxp7KBnrnxSEFLwi1zaoldgVdsJ3G84qVXz9UiwIzZTCYVeEVgjhkKZhCkN0GczojH65fpAJrjhSVtVSxNbJ9ok3X0Pzb1VgGn9b6cWiOTrr0BYTKRup3Avz8jdCuyiMcXVncBk4c3I0kAdOf/JLnlmyj2dU+exbUNqmKyl1NQYLBGXkwe3nLwhwrZuZQMIvAdBnFo++OVwiC3DtSeo7zBZP7HaceQ2UMmeT2Vh03K7aq1sAd1WBO03lJSVcZTINPh8vfOapFALQQtImhRTm8PvM4hnTP5k8fbuS+D1pkvsac6kYnjS7lPdtU2wYrJCVdtYwI5h/vNR6uW6C2sYw1Zi1BWyyCQPoZ3TMjsQhyjVqC8VcF37ZQo5m5EC57y5eYcBSjhaCNTB5YwGszj+OaEwfwj6938dXW+CY87T5UjzQyc9dUtmL/WpPkdBWoDVbwIgT0mRD7NshgtLJO8t8Ipq14LYIIhGDQqSpV8Yw/xe7+mqMPR0p8Pv+dEC0EMeL2M4cxsFsWt7+9hnkrS7n1zdW8t2pP0OPrmlys2Bn9NnW7KpQQ1JLBxoPO1g84s2t0/VdiSUoGXPKar29RLOg6UDWUC+bqspLeRaUqxrr1skZzhBLXYHEikZHq4JGfjeWiOUv5zZurSU4SvL9mL6N65TK4u/8qtbrRyZXPL2PV7kr++csTKekbeUHTrkP1LPUcS5fCAWzdX4OUEtGaVcuZf/b1f+kIrLs1xQIh4Kp/RWYRaDQaP7RFEEMmFHfljZnH8d4vT+TL355KVqqDW99c7bfxfU2jk6teWMa6PVWkJSfx6tfRdTjcdaieVemTODjhFuqa3eytamzdYLv0ia6K80ig25DYups0mgRBC0GMmTywgHF98yjKTedP08ewurSKOZ/7epY88NH3rC2t4snLxnPh+D68v2YvVfU+F4+Ukpe/2sHeSvv+KLsO1VPcNdO7Wc6W/TXxfUMajeaoRwtBHDlnbE/OGdOTJxZupayqgX1Vjby9vJQZx/blzFE9uGxyPxqdHuZ9V+o9Z/GWg9z9r/X8z4cbba+5+1A9fbtmMqS7Snncsr+2Xd6LRqM5etFCEGd+d/ZwPBIe/WQzzy3ZhltK/muqcsmM7t2Fkr55vPrNLsyC6r8tVv3V568r44dy/0ne7ZGUHm6gX9dM8rNS6ZadypYD2iLQaDRtQwtBnOmTn8k1Jw5g3nel/P3rnZw/rhf9Cnx5yZdN7sfWA7W8+OUO1u2p4outB5l50gDSkpOYs8i/De7eygZcHkm/rur8Id1z2KwtAo1G00a0ELQDN54yiPzMVJpcHm6Y5h+gveCY3pwxsoj7PtjAr+euIivVwU2nDuGSY/vx7nd72GOJFew+pHbjMoVkSFE2Ww/U0uQKsnerRqPRRIAWgnYgNz2FR382lrvOGeEN8pokO5J4/OfHMGVwN7YeqOXSSf3okpHCzKkDAbj59e84UKMyg3aZQmBYBKePLKK2ycWzn29Do9FoWosWgnbi1OFFXHfSQNvX0pIdPHPFBO48ezizT1XdPnvnZfC/M0pYt7eK8x7/go/X7WPrgVqSkwQ9u6jWEicNKeScMT15fOFWdhysa7f3otFoji60EHQSstKSuX7qILpk+nbkOn9cL+bdcCLpKQ5m/WMFz32xnT75GTiSfAVkfzxvJGmOJP7w3jqOoA7eGo2mE6Erizs5I3vl8uktJ/PlDwf5aG0Zo3r5d0Esyk3nN2cM5d73N/DVDxWcOLib97W6Jhf3f7CBwpw0ThtRxJjeXUhKSozeKRqNJnLEkbaKnDhxoly+fHlHD6NT0eh0M+WhhYzslcsr16gdk5pcbq57eTlfGk3wPBKG98jh16cN5cxRRa1rS6HRaI5YhBArpJQT7V7TrqGjgPQUB784sT+LN5ezsayaZpeHm19fxZItB3nop2NZcdfpPPzTsTS5PMz6xwqueelbGp0600ij0Si0RXCUUFXv5PgH/8MJg7pRWd/M8p2H+cO5I7l2im8/ZZfbw8tLd3L/BxuYNqyQOZdPID2llVtFajSaI4pQFoGOERwldMlMYcaxfXnxyx1kpDh4/NJjOG9cL79jkh1JXDtlAFmpDn47by0nP7KQgqw0hhZlc+fZI+ieG2bTd41Gc1SiheAo4oaTB1Hd4OK6kwYwomfwXvuXTOpHTnoKH60ro77ZzUfr9rFoczk3nDyIqgYn+6obyUhxkOJIYvP+GvZWNnD7mcM5Z2zPuI6/qsHJnz/cSHWjk8dmlGhrRaNpJ7RrSMPWA7Xc+tZqVu+uxJEkKMpJo8nlodnlYWBhFvXNbnYeque16yYzsX/XuIzh620V3DJ3FQdqmnB7JGeOKuKpyyb4pcpGitq8R1JcEGRPZ40mAQnlGtJCoAFUQ7uyqgaKctNJcfjnEByua+bCp7+isr7ZWxSXlpxEbnoKfbpmMK5PHllpyXg8EgneybuqwcnKXYc5fmBByNX9mtJKLn5mKb3yMnjs4hJW7jrMve9v4JRhhYzomUtyksDpkaQlJ3HZ5GIKc9LYU9nAXz/bgssjKcpNY8rgbhw/qICP1u3j1jdXkyTguauO5fhBBXH7nWk0RxIdJgRCiLOA/wMcwHNSygcDXhfG62cD9cDVUsqVoa6phaBj2HGwjkue/Zp91S03wkkSkJeZSmV9M9lpyVw6uR8DCrJ49N+bOVjbRFFuGjecPIiJ/bvSs0s6tU0uDtQ00SUjhRRHEhc/s5S05CTevfFECnPUPsxPLNjCM59vo9HlxumWpDqScHo85KQlc8mkfry+bBcutyQvM4XymiZcHknfrhnsPtTAMf3yqGl0sftQPf9zwRhOG9Gd3PQUdlTUsWz7IT5cW8aq3ZWcNaoH1500kGE9/Nt+SClZsfMwX/1Qwbo9VRTmpHHzj4Yc1TGURqebP8/fyOrdlfzfJcfQv5u2po42OkQIhBAOYDNwOlAKfAtcKqXcYDnmbGA2SggmA/8npZwc6rpaCDoOt0fi8niQEppcHmoanWw5UMt3Ow9TUddMfmYq2w7W8vG6fXgkjOubx9UnFPPq17tYvvNw0OvmpCUz78YTGFJkv82kuR3n1gO1/P7dtXyz/RATivN57OIS+hVk0uh088GaMt5avpvhPXK485wR1DW5ufrFZawprQIgPSWJRqfaKa64IJOxffL4dMM+Gp0e8jNTGFSYzaDCbPrkZ/DZxv2sLq1CCBhQkMXuw/WkOpK4ZFI/eudlIIH1e6rYfKCGitpmGpxupg4p5PxxvchMc1Db6CIzNZm8zBQq653sPFSH2yPpmpXqbSXe5PIwqDCLotx06ppc1Da5cCQJkpOSSE4SJDvU944kQYpDGI/qZ7dH0uRyI4QgPzOVrDQHHg+4pcTjkbg90ve9VD97PODyeKhtcnG43snW/TWs3aN+N6N6deHTDfvZtL+GrFQHaSkOnvz5eIYUZZMkBAK1E6gQAiSU1zaxv7qRrLRk+uRnkJ7ioMnpRqIsxeQkf4tSYoxBgscj8Ug1LinVZ8rtMb6XkuQkQUaqg7omFzsr6qlvdtE9N52umam4jHPTkpNIS3aQlpxEarL6nQgBjU4P9c0ukpOSyM1IxiEEzW4PFbXN7DpUT12Ti975GWSmJrN5fw37qxvpX/D/2zv7IKvKOo5/vsu+sbC8h7zLSwxgvqAlA1nGaKNSDjT9EThYiDWOvYzkZAXD1Gh/5PRCWWkpYyK+V2TFMOZLWDZlKSnx1oKAiKyAgBCwC+yy7K8/nufCZdu74Lp7z4Hz+8zc2fM855znfvbc+9zfPc895/d0Y1T/7jQ3G0eOHqOyLLS7aXcdq2v307NrGRNH9mVYnyqaLTy/GTQea+ZQwzEam5qpKCuhorTk+L7NFo516C+h3SONzZR2Ed0rSymPZ9wHjhyldt9h6huaGNCjkl5V5dQ1NFHf0ERFaQldy7tQVV5KVXkXupSIEomS3OvQDpIKBJOA283s6lieB2Bmd+Ztcx/wFzN7PJY3AJPNbEehdj0QpJ/afYfYsqeey0b1o6REmBk1Ow6y9Z16dh44QnVlGf26l7P/8FG27T3E5DH9OX9wz1M3TAgK67YfYOyAakq7tH0bTGNTM69s3cfKbfvYfbCBcQN6cOHQnow5pxpJ7KtvZOmq7azfeZDNu+t4fXcde+oaGd63ii98dCTTxg+iurKMLXvq+e5TNTy/fhfHmkN/eV91BeMG9qB/dQVm8Keat9l/+GibPvlIkOSobIlCGnMJNu6qo3dVGQs+M55hfaq4YdHLbH3nUHJyTkFu/tgo5k4Z2659k7p8dDCwLa9cS/jWf6ptBgMnBQJJNwE3xWJdDBjtoR+wp537FpszxfWs89wKvHAa23Ti15GiHNMtLcqTv/WumzjrXvuEOaXnvO/BvPa3f26hFZ0ZCFo7f2n5Heh0tsHMFgIL37OQ9K9CETFtnCmu7tnxnCmu7tmxJOnZmSkmaoGheeUhwPZ2bOM4juN0Ip0ZCFYAoyWNkFQOzACWtthmKfA5BSYC+9v6fcBxHMfpeDptaMjMmiR9BXiGcPnoA2a2TtLNcf29wFOEK4Y2ES4fnd1ZPpH3PLxURM4UV/fseM4UV/fsWBLzPONuKHMcx3E6Fk9D7TiOk3E8EDiO42SczAQCSddI2iBpk6S5SfvkkDRU0p8l1UhaJ2lOrO8j6TlJG+Pf3km7QrhjXNJKSctiOa2evSQtkbQ+HttJaXSVdGt83ddKelxSZRo8JT0gaZektXl1Bb0kzYt9a4Okq1Pg+oP42q+W9DtJvZJ2bc0zb91tkkxSv7y6onlmIhDEdBf3AFOA84DrJJ2XrNVxmoCvmdk4YCLw5eg2F1huZqOB5bGcBuYANXnltHr+BHjazMYCFxGcU+UqaTBwC/AhMzufcFHFDNLh+SBwTYu6Vr3i+3UG8IG4z89jnysWD/L/rs8B55vZhYRUN/MgcdfWPJE0lJCK5828uqJ6ZiIQABOATWb2upk1Ak8A0xJ2AsDMduQS7ZnZQcIH1mCC3+K42WLgU8kYnkDSEOCTwP151Wn07AFcDvwSwMwazey/pNCVcOVeV0mlQBXhPprEPc3sr8DeFtWFvKYBT5hZg5ltIVwFOKEoorTuambPmllTLP6TcI9Soq4FjinAj4FvcPLNtEX1zEogKJTKIlVIGg5cDLwEnJO7pyL+7Z+c2XHuIrxhm/Pq0ug5EtgNLIrDWPdL6kbKXM3sLeCHhG+COwj30TxLyjzzKOSV9v51I/DHuJwqV0lTgbfMbFWLVUX1zEogOK1UFkkiqTvwW+CrZnYgaZ+WSLoW2GVmryTtchqUApcAvzCzi4F60jNkdZw4xj4NGAEMArpJuj5Zq3aR2v4laT5h+PXRXFUrmyXiKqkKmA98u7XVrdR1mmdWAkGqU1lIKiMEgUfN7MlY/bakgXH9QGBXUn6Ry4Cpkt4gDK1dIekR0ucJ4fWuNbOXYnkJITCkzfXjwBYz221mR4EngQ+TPs8chbxS2b8kzQKuBWbaiRum0uQ6ivAlYFXsV0OAVyUNoMieWQkEp5PuIhEkiTCWXWNmP8pbtRSYFZdnAX8otls+ZjbPzIaY2XDC8XvezK4nZZ4AZrYT2CZpTKy6EvgP6XN9E5goqSq+D64k/EaUNs8chbyWAjMkVUgaAYwGXk7A7zgKk2J9E5hqZvk5tVPjamZrzKy/mQ2P/aoWuCS+f4vraWaZeBBSWbwGbAbmJ+2T5/URwinfauDf8fEJoC/hyoyN8W+fpF3znCcDy+JyKj2B8YRM0auB3wO90+gK3AGsB9YCDwMVafAEHif8bnGU8AH1+ba8CEMcm4ENwJQUuG4ijLHn+tS9Sbu25tli/RtAvyQ8PcWE4zhOxsnK0JDjOI5TAA8EjuM4GccDgeM4TsbxQOA4jpNxPBA4juNkHA8ETqaIGR4X5JVvk3R7gkoFkXSDpLuT9nDOfjwQOFmjAfh0frpfx8k6HgicrNFEmBv21pYrJJ0raXnMYb9c0rBTNSbp65JWxH3uiHXDYy78xbF+Scwrg6QrYyK8NTE/fUWsv1TSi5JWSXpZUnV8ikGSno5zAHy/w46C4+ThgcDJIvcAMyX1bFF/N/CQhRz2jwI/basRSVcRbv2fQLiT+YOSLo+rxwALY1sHgC9JqiTkpJ9uZhcQkuN9MaY9+RUwx8wuIuQgOhzbGQ9MBy4Apsfc9Y7ToXggcDKHheyuDxEmhclnEvBYXH6YkP6jLa6Kj5XAq8BYQmAA2GZmf4/Lj8S2xhCSzL0W6xcT5k0YA+wwsxU5PzuRS3+5me03syOEfEnnvpv/1XFOh9KkBRwnIe4ifHgvamObU+VfEXCnmd13UmWYV6LlvkbrqYVz7RR6roa85WN4n3U6AT8jcDKJme0Ffk1IUJbjRUJmVYCZwN9O0cwzwI1xLgkkDZaUm6xlmKRJcfm62NZ6YLik98f6zwIvxPpBki6N7VTHGcscpyh4IHCyzAIg/+qhW4DZklYTPqTnQJhFStJ3Wu5sYTaxx4B/SFpDmPcg9yNvDTArttWHMEnOEWA28Ju4fTMhK2Yj4XeAn0laRZhvt7LD/1vHKYBnH3WcDiYODS2zMCG946QePyNwHMfJOH5G4DiOk3H8jMBxHCfjeCBwHMfJOB4IHMdxMo4HAsdxnIzjgcBxHCfj/A//NQ9z/lrceAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'][5:], label='loss (testing data)')\n",
    "plt.plot(hist.history['val_loss'][5:], label='loss (validation data)')\n",
    "# plt.title(label[i] + \" loss/epoch plot.\" + \" Opt: {}\".format(opt))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.ylim((0,3.5))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404255"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(hist1.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"hist_first150.pickle\", \"wb\") as f:\n",
    "    pickle.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
